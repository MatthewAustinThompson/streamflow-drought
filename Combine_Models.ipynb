{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import time\n",
    "from pandas.plotting import scatter_matrix\n",
    "from datetime import datetime as dt\n",
    "import rioxarray as rxr\n",
    "import xarray as xr\n",
    "\n",
    "# torch\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "\n",
    "# sklearn\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 14062 entries, 1981-10-01 to 2020-03-31\n",
      "Data columns (total 21 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   tmmx_mean             14062 non-null  float64\n",
      " 1   log_tmmx_var          14062 non-null  float64\n",
      " 2   tmmn_mean             14062 non-null  float64\n",
      " 3   log_tmmn_var          14062 non-null  float64\n",
      " 4   pr_mean               14062 non-null  float64\n",
      " 5   pr_var                14062 non-null  float64\n",
      " 6   pr_sum                14062 non-null  float64\n",
      " 7   SPEI_mean             14062 non-null  float64\n",
      " 8   SPEI_stdev            14062 non-null  float64\n",
      " 9   pet_mean              14062 non-null  float64\n",
      " 10  pet_var               14062 non-null  float64\n",
      " 11  pet_sum               14062 non-null  float64\n",
      " 12  SoilM_0_10cm_mean     14062 non-null  float64\n",
      " 13  SoilM_0_10cm_stdev    14062 non-null  float64\n",
      " 14  SoilM_10_40cm_mean    14062 non-null  float64\n",
      " 15  SoilM_10_40cm_stdev   14062 non-null  float64\n",
      " 16  SoilM_40_100cm_mean   14062 non-null  float64\n",
      " 17  SoilM_40_100cm_stdev  14062 non-null  float64\n",
      " 18  SWE_mean              14062 non-null  float64\n",
      " 19  SWE_stdev             14062 non-null  float64\n",
      " 20  weibull_jd_30d_avg    14062 non-null  float64\n",
      "dtypes: float64(21)\n",
      "memory usage: 2.4 MB\n"
     ]
    }
   ],
   "source": [
    "gauge_num = \"09037500\"\n",
    "df_lstm = pd.read_csv(\n",
    "    \"../Streamflow_Data/Streamflow_clean_\" + gauge_num + \".csv\", \n",
    "    index_col = \"Date\", \n",
    "    parse_dates=True\n",
    ")\n",
    "df_lstm.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tmmx_mean</th>\n",
       "      <th>log_tmmx_var</th>\n",
       "      <th>tmmn_mean</th>\n",
       "      <th>log_tmmn_var</th>\n",
       "      <th>pr_mean</th>\n",
       "      <th>pr_var</th>\n",
       "      <th>pr_sum</th>\n",
       "      <th>SPEI_mean</th>\n",
       "      <th>SPEI_stdev</th>\n",
       "      <th>pet_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>pet_sum</th>\n",
       "      <th>SoilM_0_10cm_mean</th>\n",
       "      <th>SoilM_0_10cm_stdev</th>\n",
       "      <th>SoilM_10_40cm_mean</th>\n",
       "      <th>SoilM_10_40cm_stdev</th>\n",
       "      <th>SoilM_40_100cm_mean</th>\n",
       "      <th>SoilM_40_100cm_stdev</th>\n",
       "      <th>SWE_mean</th>\n",
       "      <th>SWE_stdev</th>\n",
       "      <th>weibull_jd_30d_avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>14062.000000</td>\n",
       "      <td>14062.000000</td>\n",
       "      <td>14062.000000</td>\n",
       "      <td>14062.000000</td>\n",
       "      <td>14062.000000</td>\n",
       "      <td>14062.000000</td>\n",
       "      <td>14062.000000</td>\n",
       "      <td>14062.000000</td>\n",
       "      <td>14062.000000</td>\n",
       "      <td>14062.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>14062.000000</td>\n",
       "      <td>14062.000000</td>\n",
       "      <td>14062.000000</td>\n",
       "      <td>14062.000000</td>\n",
       "      <td>14062.000000</td>\n",
       "      <td>14062.000000</td>\n",
       "      <td>14062.000000</td>\n",
       "      <td>14062.000000</td>\n",
       "      <td>14062.000000</td>\n",
       "      <td>14062.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>39.233871</td>\n",
       "      <td>0.621345</td>\n",
       "      <td>36.804132</td>\n",
       "      <td>0.621345</td>\n",
       "      <td>1.844382</td>\n",
       "      <td>1.132257</td>\n",
       "      <td>53.623183</td>\n",
       "      <td>-0.018995</td>\n",
       "      <td>-0.018995</td>\n",
       "      <td>2.749324</td>\n",
       "      <td>...</td>\n",
       "      <td>79.240976</td>\n",
       "      <td>27.670399</td>\n",
       "      <td>3.293829</td>\n",
       "      <td>73.023107</td>\n",
       "      <td>8.471557</td>\n",
       "      <td>135.220614</td>\n",
       "      <td>10.934260</td>\n",
       "      <td>83.641148</td>\n",
       "      <td>40.522235</td>\n",
       "      <td>50.281539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.318694</td>\n",
       "      <td>0.250870</td>\n",
       "      <td>8.149847</td>\n",
       "      <td>0.250870</td>\n",
       "      <td>3.067052</td>\n",
       "      <td>4.054328</td>\n",
       "      <td>89.398747</td>\n",
       "      <td>0.901918</td>\n",
       "      <td>0.901918</td>\n",
       "      <td>1.598216</td>\n",
       "      <td>...</td>\n",
       "      <td>46.076612</td>\n",
       "      <td>6.548800</td>\n",
       "      <td>2.305301</td>\n",
       "      <td>12.628244</td>\n",
       "      <td>4.486704</td>\n",
       "      <td>16.024198</td>\n",
       "      <td>4.137096</td>\n",
       "      <td>93.135862</td>\n",
       "      <td>46.285350</td>\n",
       "      <td>28.134417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>10.700000</td>\n",
       "      <td>-0.522879</td>\n",
       "      <td>5.600000</td>\n",
       "      <td>-0.522879</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2.090000</td>\n",
       "      <td>-2.090000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>15.740000</td>\n",
       "      <td>0.460000</td>\n",
       "      <td>50.410000</td>\n",
       "      <td>1.530000</td>\n",
       "      <td>107.720000</td>\n",
       "      <td>4.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.080580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>31.600000</td>\n",
       "      <td>0.447158</td>\n",
       "      <td>30.500000</td>\n",
       "      <td>0.447158</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.646000</td>\n",
       "      <td>-0.646000</td>\n",
       "      <td>1.300000</td>\n",
       "      <td>...</td>\n",
       "      <td>37.200000</td>\n",
       "      <td>20.810000</td>\n",
       "      <td>1.430000</td>\n",
       "      <td>62.060000</td>\n",
       "      <td>4.460000</td>\n",
       "      <td>123.390000</td>\n",
       "      <td>7.910000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>26.449478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>38.800000</td>\n",
       "      <td>0.698970</td>\n",
       "      <td>37.200000</td>\n",
       "      <td>0.698970</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>17.500000</td>\n",
       "      <td>-0.032000</td>\n",
       "      <td>-0.032000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>72.650000</td>\n",
       "      <td>29.290000</td>\n",
       "      <td>2.740000</td>\n",
       "      <td>71.740000</td>\n",
       "      <td>7.380000</td>\n",
       "      <td>131.340000</td>\n",
       "      <td>10.110000</td>\n",
       "      <td>47.510000</td>\n",
       "      <td>25.510000</td>\n",
       "      <td>50.054819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>47.900000</td>\n",
       "      <td>0.826075</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>0.826075</td>\n",
       "      <td>2.300000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>67.500000</td>\n",
       "      <td>0.604000</td>\n",
       "      <td>0.604000</td>\n",
       "      <td>4.100000</td>\n",
       "      <td>...</td>\n",
       "      <td>117.475000</td>\n",
       "      <td>33.480000</td>\n",
       "      <td>4.550000</td>\n",
       "      <td>80.900000</td>\n",
       "      <td>12.030000</td>\n",
       "      <td>144.057500</td>\n",
       "      <td>13.097500</td>\n",
       "      <td>152.480000</td>\n",
       "      <td>63.600000</td>\n",
       "      <td>74.133763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>57.500000</td>\n",
       "      <td>1.262451</td>\n",
       "      <td>52.300000</td>\n",
       "      <td>1.262451</td>\n",
       "      <td>43.300000</td>\n",
       "      <td>164.600000</td>\n",
       "      <td>1257.500000</td>\n",
       "      <td>2.090000</td>\n",
       "      <td>2.090000</td>\n",
       "      <td>7.900000</td>\n",
       "      <td>...</td>\n",
       "      <td>228.000000</td>\n",
       "      <td>40.210000</td>\n",
       "      <td>12.510000</td>\n",
       "      <td>113.110000</td>\n",
       "      <td>22.620000</td>\n",
       "      <td>184.550000</td>\n",
       "      <td>28.440000</td>\n",
       "      <td>390.230000</td>\n",
       "      <td>230.680000</td>\n",
       "      <td>99.919420</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          tmmx_mean  log_tmmx_var     tmmn_mean  log_tmmn_var       pr_mean  \\\n",
       "count  14062.000000  14062.000000  14062.000000  14062.000000  14062.000000   \n",
       "mean      39.233871      0.621345     36.804132      0.621345      1.844382   \n",
       "std        9.318694      0.250870      8.149847      0.250870      3.067052   \n",
       "min       10.700000     -0.522879      5.600000     -0.522879      0.000000   \n",
       "25%       31.600000      0.447158     30.500000      0.447158      0.000000   \n",
       "50%       38.800000      0.698970     37.200000      0.698970      0.600000   \n",
       "75%       47.900000      0.826075     44.000000      0.826075      2.300000   \n",
       "max       57.500000      1.262451     52.300000      1.262451     43.300000   \n",
       "\n",
       "             pr_var        pr_sum     SPEI_mean    SPEI_stdev      pet_mean  \\\n",
       "count  14062.000000  14062.000000  14062.000000  14062.000000  14062.000000   \n",
       "mean       1.132257     53.623183     -0.018995     -0.018995      2.749324   \n",
       "std        4.054328     89.398747      0.901918      0.901918      1.598216   \n",
       "min        0.000000      0.000000     -2.090000     -2.090000      0.000000   \n",
       "25%        0.000000      0.000000     -0.646000     -0.646000      1.300000   \n",
       "50%        0.100000     17.500000     -0.032000     -0.032000      2.500000   \n",
       "75%        0.600000     67.500000      0.604000      0.604000      4.100000   \n",
       "max      164.600000   1257.500000      2.090000      2.090000      7.900000   \n",
       "\n",
       "       ...       pet_sum  SoilM_0_10cm_mean  SoilM_0_10cm_stdev  \\\n",
       "count  ...  14062.000000       14062.000000        14062.000000   \n",
       "mean   ...     79.240976          27.670399            3.293829   \n",
       "std    ...     46.076612           6.548800            2.305301   \n",
       "min    ...      1.000000          15.740000            0.460000   \n",
       "25%    ...     37.200000          20.810000            1.430000   \n",
       "50%    ...     72.650000          29.290000            2.740000   \n",
       "75%    ...    117.475000          33.480000            4.550000   \n",
       "max    ...    228.000000          40.210000           12.510000   \n",
       "\n",
       "       SoilM_10_40cm_mean  SoilM_10_40cm_stdev  SoilM_40_100cm_mean  \\\n",
       "count        14062.000000         14062.000000         14062.000000   \n",
       "mean            73.023107             8.471557           135.220614   \n",
       "std             12.628244             4.486704            16.024198   \n",
       "min             50.410000             1.530000           107.720000   \n",
       "25%             62.060000             4.460000           123.390000   \n",
       "50%             71.740000             7.380000           131.340000   \n",
       "75%             80.900000            12.030000           144.057500   \n",
       "max            113.110000            22.620000           184.550000   \n",
       "\n",
       "       SoilM_40_100cm_stdev      SWE_mean     SWE_stdev  weibull_jd_30d_avg  \n",
       "count          14062.000000  14062.000000  14062.000000        14062.000000  \n",
       "mean              10.934260     83.641148     40.522235           50.281539  \n",
       "std                4.137096     93.135862     46.285350           28.134417  \n",
       "min                4.100000      0.000000      0.000000            0.080580  \n",
       "25%                7.910000      0.000000      0.000000           26.449478  \n",
       "50%               10.110000     47.510000     25.510000           50.054819  \n",
       "75%               13.097500    152.480000     63.600000           74.133763  \n",
       "max               28.440000    390.230000    230.680000           99.919420  \n",
       "\n",
       "[8 rows x 21 columns]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lstm.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tmmx_mean</th>\n",
       "      <th>log_tmmx_var</th>\n",
       "      <th>tmmn_mean</th>\n",
       "      <th>log_tmmn_var</th>\n",
       "      <th>pr_mean</th>\n",
       "      <th>pr_var</th>\n",
       "      <th>pr_sum</th>\n",
       "      <th>SPEI_mean</th>\n",
       "      <th>SPEI_stdev</th>\n",
       "      <th>pet_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>pet_sum</th>\n",
       "      <th>SoilM_0_10cm_mean</th>\n",
       "      <th>SoilM_0_10cm_stdev</th>\n",
       "      <th>SoilM_10_40cm_mean</th>\n",
       "      <th>SoilM_10_40cm_stdev</th>\n",
       "      <th>SoilM_40_100cm_mean</th>\n",
       "      <th>SoilM_40_100cm_stdev</th>\n",
       "      <th>SWE_mean</th>\n",
       "      <th>SWE_stdev</th>\n",
       "      <th>weibull_jd_30d_avg</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1981-10-01</th>\n",
       "      <td>45.1</td>\n",
       "      <td>0.799341</td>\n",
       "      <td>41.1</td>\n",
       "      <td>0.799341</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.790</td>\n",
       "      <td>-0.790</td>\n",
       "      <td>2.9</td>\n",
       "      <td>...</td>\n",
       "      <td>83.1</td>\n",
       "      <td>19.99</td>\n",
       "      <td>1.01</td>\n",
       "      <td>57.65</td>\n",
       "      <td>3.02</td>\n",
       "      <td>122.61</td>\n",
       "      <td>6.58</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>33.521354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981-10-02</th>\n",
       "      <td>43.5</td>\n",
       "      <td>0.716003</td>\n",
       "      <td>43.4</td>\n",
       "      <td>0.716003</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38.6</td>\n",
       "      <td>-0.700</td>\n",
       "      <td>-0.700</td>\n",
       "      <td>2.3</td>\n",
       "      <td>...</td>\n",
       "      <td>67.7</td>\n",
       "      <td>20.12</td>\n",
       "      <td>0.97</td>\n",
       "      <td>57.36</td>\n",
       "      <td>3.00</td>\n",
       "      <td>122.43</td>\n",
       "      <td>6.54</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>29.814666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981-10-03</th>\n",
       "      <td>38.5</td>\n",
       "      <td>0.770852</td>\n",
       "      <td>41.1</td>\n",
       "      <td>0.770852</td>\n",
       "      <td>2.7</td>\n",
       "      <td>0.2</td>\n",
       "      <td>79.2</td>\n",
       "      <td>-0.602</td>\n",
       "      <td>-0.602</td>\n",
       "      <td>1.8</td>\n",
       "      <td>...</td>\n",
       "      <td>51.3</td>\n",
       "      <td>20.42</td>\n",
       "      <td>0.89</td>\n",
       "      <td>57.51</td>\n",
       "      <td>2.94</td>\n",
       "      <td>122.26</td>\n",
       "      <td>6.51</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>33.440774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981-10-04</th>\n",
       "      <td>40.9</td>\n",
       "      <td>0.707570</td>\n",
       "      <td>40.7</td>\n",
       "      <td>0.707570</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>86.8</td>\n",
       "      <td>-0.504</td>\n",
       "      <td>-0.504</td>\n",
       "      <td>2.2</td>\n",
       "      <td>...</td>\n",
       "      <td>62.4</td>\n",
       "      <td>20.81</td>\n",
       "      <td>0.95</td>\n",
       "      <td>57.62</td>\n",
       "      <td>3.03</td>\n",
       "      <td>122.11</td>\n",
       "      <td>6.48</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.12</td>\n",
       "      <td>46.655923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981-10-05</th>\n",
       "      <td>39.6</td>\n",
       "      <td>0.806180</td>\n",
       "      <td>41.2</td>\n",
       "      <td>0.806180</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.4</td>\n",
       "      <td>-0.406</td>\n",
       "      <td>-0.406</td>\n",
       "      <td>2.5</td>\n",
       "      <td>...</td>\n",
       "      <td>71.5</td>\n",
       "      <td>21.12</td>\n",
       "      <td>1.08</td>\n",
       "      <td>57.82</td>\n",
       "      <td>3.15</td>\n",
       "      <td>121.97</td>\n",
       "      <td>6.46</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.36</td>\n",
       "      <td>53.988719</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            tmmx_mean  log_tmmx_var  tmmn_mean  log_tmmn_var  pr_mean  pr_var  \\\n",
       "Date                                                                            \n",
       "1981-10-01       45.1      0.799341       41.1      0.799341      0.0     0.0   \n",
       "1981-10-02       43.5      0.716003       43.4      0.716003      1.3     0.0   \n",
       "1981-10-03       38.5      0.770852       41.1      0.770852      2.7     0.2   \n",
       "1981-10-04       40.9      0.707570       40.7      0.707570      3.0     0.2   \n",
       "1981-10-05       39.6      0.806180       41.2      0.806180      1.4     0.0   \n",
       "\n",
       "            pr_sum  SPEI_mean  SPEI_stdev  pet_mean  ...  pet_sum  \\\n",
       "Date                                                 ...            \n",
       "1981-10-01     0.0     -0.790      -0.790       2.9  ...     83.1   \n",
       "1981-10-02    38.6     -0.700      -0.700       2.3  ...     67.7   \n",
       "1981-10-03    79.2     -0.602      -0.602       1.8  ...     51.3   \n",
       "1981-10-04    86.8     -0.504      -0.504       2.2  ...     62.4   \n",
       "1981-10-05    40.4     -0.406      -0.406       2.5  ...     71.5   \n",
       "\n",
       "            SoilM_0_10cm_mean  SoilM_0_10cm_stdev  SoilM_10_40cm_mean  \\\n",
       "Date                                                                    \n",
       "1981-10-01              19.99                1.01               57.65   \n",
       "1981-10-02              20.12                0.97               57.36   \n",
       "1981-10-03              20.42                0.89               57.51   \n",
       "1981-10-04              20.81                0.95               57.62   \n",
       "1981-10-05              21.12                1.08               57.82   \n",
       "\n",
       "            SoilM_10_40cm_stdev  SoilM_40_100cm_mean  SoilM_40_100cm_stdev  \\\n",
       "Date                                                                         \n",
       "1981-10-01                 3.02               122.61                  6.58   \n",
       "1981-10-02                 3.00               122.43                  6.54   \n",
       "1981-10-03                 2.94               122.26                  6.51   \n",
       "1981-10-04                 3.03               122.11                  6.48   \n",
       "1981-10-05                 3.15               121.97                  6.46   \n",
       "\n",
       "            SWE_mean  SWE_stdev  weibull_jd_30d_avg  \n",
       "Date                                                 \n",
       "1981-10-01      0.00       0.00           33.521354  \n",
       "1981-10-02      0.00       0.00           29.814666  \n",
       "1981-10-03      0.00       0.00           33.440774  \n",
       "1981-10-04      0.01       0.12           46.655923  \n",
       "1981-10-05      0.07       0.36           53.988719  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lstm.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Files</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LT05_CU_011009_19840528_20190206_C01_V01_INWM.tif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LT05_CU_011009_19840613_20190604_C01_V01_INWM.tif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LT05_CU_011009_19840629_20190604_C01_V01_INWM.tif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LT05_CU_011009_19860603_20190603_C01_V01_INWM.tif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LT05_CU_011009_19860619_20190603_C01_V01_INWM.tif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>LC08_CU_011009_20210603_20210616_C01_V01_INWM.tif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>LC08_CU_011009_20210705_20210715_C01_V01_INWM.tif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>LC08_CU_011009_20210907_20210921_C01_V01_INWM.tif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>LC08_CU_011009_20210923_20211002_C01_V01_INWM.tif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>LC08_CU_011009_20211025_20211105_C01_V01_INWM.tif</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>155 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Files\n",
       "0    LT05_CU_011009_19840528_20190206_C01_V01_INWM.tif\n",
       "1    LT05_CU_011009_19840613_20190604_C01_V01_INWM.tif\n",
       "2    LT05_CU_011009_19840629_20190604_C01_V01_INWM.tif\n",
       "3    LT05_CU_011009_19860603_20190603_C01_V01_INWM.tif\n",
       "4    LT05_CU_011009_19860619_20190603_C01_V01_INWM.tif\n",
       "..                                                 ...\n",
       "150  LC08_CU_011009_20210603_20210616_C01_V01_INWM.tif\n",
       "151  LC08_CU_011009_20210705_20210715_C01_V01_INWM.tif\n",
       "152  LC08_CU_011009_20210907_20210921_C01_V01_INWM.tif\n",
       "153  LC08_CU_011009_20210923_20211002_C01_V01_INWM.tif\n",
       "154  LC08_CU_011009_20211025_20211105_C01_V01_INWM.tif\n",
       "\n",
       "[155 rows x 1 columns]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_tiles = pd.read_csv('../Landsat_Data/Clear_Tiles_Williams_Fork_Reservoir.csv', names=['Files'], dtype='string')\n",
    "clean_tiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 155 entries, 0 to 154\n",
      "Data columns (total 1 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   Files   155 non-null    string\n",
      "dtypes: string(1)\n",
      "memory usage: 1.3 KB\n"
     ]
    }
   ],
   "source": [
    "clean_tiles.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find If Tiles Are During Drought"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 107916 entries, 0 to 107915\n",
      "Data columns (total 17 columns):\n",
      " #   Column                                              Non-Null Count   Dtype  \n",
      "---  ------                                              --------------   -----  \n",
      " 0   drought_id                                          107916 non-null  int64  \n",
      " 1   severity                                            107916 non-null  float64\n",
      " 2   mean_intensity                                      107916 non-null  float64\n",
      " 3   max_intensity                                       107916 non-null  float64\n",
      " 4   duration                                            107916 non-null  int64  \n",
      " 5   start                                               107916 non-null  object \n",
      " 6   end                                                 107916 non-null  object \n",
      " 7   min_flow_cfs                                        107916 non-null  float64\n",
      " 8   mean_flow_cfs                                       107916 non-null  float64\n",
      " 9   max_flow_cfs                                        107916 non-null  float64\n",
      " 10  flow_deficit_cfs                                    107916 non-null  float64\n",
      " 11  threshold                                           107916 non-null  int64  \n",
      " 12  site                                                107916 non-null  object \n",
      " 13  dropped_zeros                                       107916 non-null  bool   \n",
      " 14  previous_end                                        106415 non-null  object \n",
      " 15  days_since_previous_drought                         106154 non-null  float64\n",
      " 16  has_the_potential_to_be_impacted_by_missing_values  107916 non-null  bool   \n",
      "dtypes: bool(2), float64(8), int64(3), object(4)\n",
      "memory usage: 12.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df_drought_events = pd.read_csv(\"../Streamflow_Data/Streamflow_Drought_Data_CRB/Streamflow_Drought_Events/weibull_jd_Drought_Properties.csv\")\n",
    "df_drought_events.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>drought_id</th>\n",
       "      <th>severity</th>\n",
       "      <th>mean_intensity</th>\n",
       "      <th>max_intensity</th>\n",
       "      <th>duration</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>min_flow_cfs</th>\n",
       "      <th>mean_flow_cfs</th>\n",
       "      <th>max_flow_cfs</th>\n",
       "      <th>flow_deficit_cfs</th>\n",
       "      <th>threshold</th>\n",
       "      <th>site</th>\n",
       "      <th>dropped_zeros</th>\n",
       "      <th>previous_end</th>\n",
       "      <th>days_since_previous_drought</th>\n",
       "      <th>has_the_potential_to_be_impacted_by_missing_values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>36559</th>\n",
       "      <td>1</td>\n",
       "      <td>33.292683</td>\n",
       "      <td>2.439024</td>\n",
       "      <td>2.439024</td>\n",
       "      <td>13</td>\n",
       "      <td>1980-04-07</td>\n",
       "      <td>1980-04-19</td>\n",
       "      <td>28.0000</td>\n",
       "      <td>29.043962</td>\n",
       "      <td>35.1429</td>\n",
       "      <td>80.704935</td>\n",
       "      <td>5</td>\n",
       "      <td>SW09037500</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36560</th>\n",
       "      <td>3</td>\n",
       "      <td>124.756098</td>\n",
       "      <td>3.019744</td>\n",
       "      <td>2.439024</td>\n",
       "      <td>63</td>\n",
       "      <td>1981-01-01</td>\n",
       "      <td>1981-03-04</td>\n",
       "      <td>19.2857</td>\n",
       "      <td>23.736962</td>\n",
       "      <td>28.8571</td>\n",
       "      <td>273.199645</td>\n",
       "      <td>5</td>\n",
       "      <td>SW09037500</td>\n",
       "      <td>False</td>\n",
       "      <td>1980-04-19</td>\n",
       "      <td>257.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36561</th>\n",
       "      <td>5</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>2.439024</td>\n",
       "      <td>40</td>\n",
       "      <td>1981-04-21</td>\n",
       "      <td>1981-05-30</td>\n",
       "      <td>10.1857</td>\n",
       "      <td>23.700360</td>\n",
       "      <td>100.2857</td>\n",
       "      <td>1316.015460</td>\n",
       "      <td>5</td>\n",
       "      <td>SW09037500</td>\n",
       "      <td>False</td>\n",
       "      <td>1981-03-04</td>\n",
       "      <td>48.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36562</th>\n",
       "      <td>7</td>\n",
       "      <td>0.975610</td>\n",
       "      <td>4.878049</td>\n",
       "      <td>4.878049</td>\n",
       "      <td>8</td>\n",
       "      <td>1981-11-26</td>\n",
       "      <td>1981-12-03</td>\n",
       "      <td>27.5714</td>\n",
       "      <td>28.357138</td>\n",
       "      <td>30.4286</td>\n",
       "      <td>13.381510</td>\n",
       "      <td>5</td>\n",
       "      <td>SW09037500</td>\n",
       "      <td>False</td>\n",
       "      <td>1981-05-30</td>\n",
       "      <td>180.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36563</th>\n",
       "      <td>8</td>\n",
       "      <td>23.658537</td>\n",
       "      <td>3.310105</td>\n",
       "      <td>2.439024</td>\n",
       "      <td>14</td>\n",
       "      <td>1981-12-10</td>\n",
       "      <td>1981-12-23</td>\n",
       "      <td>28.4286</td>\n",
       "      <td>29.142850</td>\n",
       "      <td>29.8571</td>\n",
       "      <td>18.522180</td>\n",
       "      <td>5</td>\n",
       "      <td>SW09037500</td>\n",
       "      <td>False</td>\n",
       "      <td>1981-12-03</td>\n",
       "      <td>7.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36822</th>\n",
       "      <td>134</td>\n",
       "      <td>170.000000</td>\n",
       "      <td>21.052632</td>\n",
       "      <td>14.634146</td>\n",
       "      <td>19</td>\n",
       "      <td>2018-03-05</td>\n",
       "      <td>2018-03-23</td>\n",
       "      <td>30.1857</td>\n",
       "      <td>31.512026</td>\n",
       "      <td>34.3429</td>\n",
       "      <td>23.548530</td>\n",
       "      <td>30</td>\n",
       "      <td>SW09037500</td>\n",
       "      <td>False</td>\n",
       "      <td>2017-10-03</td>\n",
       "      <td>153.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36823</th>\n",
       "      <td>135</td>\n",
       "      <td>5314.146341</td>\n",
       "      <td>12.046803</td>\n",
       "      <td>2.439024</td>\n",
       "      <td>296</td>\n",
       "      <td>2018-06-11</td>\n",
       "      <td>2019-04-07</td>\n",
       "      <td>10.0614</td>\n",
       "      <td>41.650366</td>\n",
       "      <td>405.8571</td>\n",
       "      <td>5280.580140</td>\n",
       "      <td>30</td>\n",
       "      <td>SW09037500</td>\n",
       "      <td>False</td>\n",
       "      <td>2018-03-23</td>\n",
       "      <td>80.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36824</th>\n",
       "      <td>136</td>\n",
       "      <td>19.512195</td>\n",
       "      <td>28.048780</td>\n",
       "      <td>26.829268</td>\n",
       "      <td>10</td>\n",
       "      <td>2019-05-27</td>\n",
       "      <td>2019-06-05</td>\n",
       "      <td>245.0000</td>\n",
       "      <td>260.885730</td>\n",
       "      <td>304.7143</td>\n",
       "      <td>321.614140</td>\n",
       "      <td>30</td>\n",
       "      <td>SW09037500</td>\n",
       "      <td>False</td>\n",
       "      <td>2019-04-07</td>\n",
       "      <td>50.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36825</th>\n",
       "      <td>137</td>\n",
       "      <td>143.170732</td>\n",
       "      <td>22.464698</td>\n",
       "      <td>12.195122</td>\n",
       "      <td>19</td>\n",
       "      <td>2019-09-23</td>\n",
       "      <td>2019-10-11</td>\n",
       "      <td>23.1857</td>\n",
       "      <td>25.721784</td>\n",
       "      <td>37.1714</td>\n",
       "      <td>172.986030</td>\n",
       "      <td>30</td>\n",
       "      <td>SW09037500</td>\n",
       "      <td>False</td>\n",
       "      <td>2019-06-05</td>\n",
       "      <td>110.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36826</th>\n",
       "      <td>138</td>\n",
       "      <td>152.195122</td>\n",
       "      <td>21.544715</td>\n",
       "      <td>14.634146</td>\n",
       "      <td>18</td>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>2020-01-19</td>\n",
       "      <td>30.6143</td>\n",
       "      <td>31.626983</td>\n",
       "      <td>34.2857</td>\n",
       "      <td>38.644340</td>\n",
       "      <td>30</td>\n",
       "      <td>SW09037500</td>\n",
       "      <td>False</td>\n",
       "      <td>2019-10-11</td>\n",
       "      <td>83.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>268 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       drought_id     severity  mean_intensity  max_intensity  duration  \\\n",
       "36559           1    33.292683        2.439024       2.439024        13   \n",
       "36560           3   124.756098        3.019744       2.439024        63   \n",
       "36561           5   100.000000        2.500000       2.439024        40   \n",
       "36562           7     0.975610        4.878049       4.878049         8   \n",
       "36563           8    23.658537        3.310105       2.439024        14   \n",
       "...           ...          ...             ...            ...       ...   \n",
       "36822         134   170.000000       21.052632      14.634146        19   \n",
       "36823         135  5314.146341       12.046803       2.439024       296   \n",
       "36824         136    19.512195       28.048780      26.829268        10   \n",
       "36825         137   143.170732       22.464698      12.195122        19   \n",
       "36826         138   152.195122       21.544715      14.634146        18   \n",
       "\n",
       "            start         end  min_flow_cfs  mean_flow_cfs  max_flow_cfs  \\\n",
       "36559  1980-04-07  1980-04-19       28.0000      29.043962       35.1429   \n",
       "36560  1981-01-01  1981-03-04       19.2857      23.736962       28.8571   \n",
       "36561  1981-04-21  1981-05-30       10.1857      23.700360      100.2857   \n",
       "36562  1981-11-26  1981-12-03       27.5714      28.357138       30.4286   \n",
       "36563  1981-12-10  1981-12-23       28.4286      29.142850       29.8571   \n",
       "...           ...         ...           ...            ...           ...   \n",
       "36822  2018-03-05  2018-03-23       30.1857      31.512026       34.3429   \n",
       "36823  2018-06-11  2019-04-07       10.0614      41.650366      405.8571   \n",
       "36824  2019-05-27  2019-06-05      245.0000     260.885730      304.7143   \n",
       "36825  2019-09-23  2019-10-11       23.1857      25.721784       37.1714   \n",
       "36826  2020-01-02  2020-01-19       30.6143      31.626983       34.2857   \n",
       "\n",
       "       flow_deficit_cfs  threshold        site  dropped_zeros previous_end  \\\n",
       "36559         80.704935          5  SW09037500          False          NaN   \n",
       "36560        273.199645          5  SW09037500          False   1980-04-19   \n",
       "36561       1316.015460          5  SW09037500          False   1981-03-04   \n",
       "36562         13.381510          5  SW09037500          False   1981-05-30   \n",
       "36563         18.522180          5  SW09037500          False   1981-12-03   \n",
       "...                 ...        ...         ...            ...          ...   \n",
       "36822         23.548530         30  SW09037500          False   2017-10-03   \n",
       "36823       5280.580140         30  SW09037500          False   2018-03-23   \n",
       "36824        321.614140         30  SW09037500          False   2019-04-07   \n",
       "36825        172.986030         30  SW09037500          False   2019-06-05   \n",
       "36826         38.644340         30  SW09037500          False   2019-10-11   \n",
       "\n",
       "       days_since_previous_drought  \\\n",
       "36559                          NaN   \n",
       "36560                        257.0   \n",
       "36561                         48.0   \n",
       "36562                        180.0   \n",
       "36563                          7.0   \n",
       "...                            ...   \n",
       "36822                        153.0   \n",
       "36823                         80.0   \n",
       "36824                         50.0   \n",
       "36825                        110.0   \n",
       "36826                         83.0   \n",
       "\n",
       "       has_the_potential_to_be_impacted_by_missing_values  \n",
       "36559                                              False   \n",
       "36560                                              False   \n",
       "36561                                              False   \n",
       "36562                                              False   \n",
       "36563                                              False   \n",
       "...                                                  ...   \n",
       "36822                                              False   \n",
       "36823                                              False   \n",
       "36824                                              False   \n",
       "36825                                              False   \n",
       "36826                                              False   \n",
       "\n",
       "[268 rows x 17 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gauge = '09037500'\n",
    "df_site = df_drought_events.loc[df_drought_events['site'] == 'SW' + gauge]\n",
    "df_site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Timestamp('1980-04-07 00:00:00'),\n",
       " Timestamp('1981-01-01 00:00:00'),\n",
       " Timestamp('1981-04-21 00:00:00'),\n",
       " Timestamp('1981-11-26 00:00:00'),\n",
       " Timestamp('1981-12-10 00:00:00'),\n",
       " Timestamp('1982-04-02 00:00:00'),\n",
       " Timestamp('1982-05-20 00:00:00'),\n",
       " Timestamp('1983-04-12 00:00:00'),\n",
       " Timestamp('1987-11-18 00:00:00'),\n",
       " Timestamp('1988-08-05 00:00:00'),\n",
       " Timestamp('1988-10-24 00:00:00'),\n",
       " Timestamp('1989-09-05 00:00:00'),\n",
       " Timestamp('1990-02-21 00:00:00'),\n",
       " Timestamp('1994-12-20 00:00:00'),\n",
       " Timestamp('2000-07-29 00:00:00'),\n",
       " Timestamp('2002-03-25 00:00:00'),\n",
       " Timestamp('2002-04-27 00:00:00'),\n",
       " Timestamp('2002-05-27 00:00:00'),\n",
       " Timestamp('2002-06-08 00:00:00'),\n",
       " Timestamp('2002-10-10 00:00:00'),\n",
       " Timestamp('2002-11-01 00:00:00'),\n",
       " Timestamp('2010-10-02 00:00:00'),\n",
       " Timestamp('2010-10-17 00:00:00'),\n",
       " Timestamp('2012-05-30 00:00:00'),\n",
       " Timestamp('2012-10-06 00:00:00'),\n",
       " Timestamp('2013-04-20 00:00:00'),\n",
       " Timestamp('2017-09-11 00:00:00'),\n",
       " Timestamp('2018-08-15 00:00:00'),\n",
       " Timestamp('2018-11-09 00:00:00'),\n",
       " Timestamp('2018-12-08 00:00:00'),\n",
       " Timestamp('2019-03-05 00:00:00'),\n",
       " Timestamp('1980-04-07 00:00:00'),\n",
       " Timestamp('1980-11-18 00:00:00'),\n",
       " Timestamp('1980-12-31 00:00:00'),\n",
       " Timestamp('1981-03-21 00:00:00'),\n",
       " Timestamp('1981-04-03 00:00:00'),\n",
       " Timestamp('1981-04-19 00:00:00'),\n",
       " Timestamp('1981-06-20 00:00:00'),\n",
       " Timestamp('1981-10-29 00:00:00'),\n",
       " Timestamp('1982-03-31 00:00:00'),\n",
       " Timestamp('1982-05-03 00:00:00'),\n",
       " Timestamp('1983-04-11 00:00:00'),\n",
       " Timestamp('1984-03-13 00:00:00'),\n",
       " Timestamp('1987-01-22 00:00:00'),\n",
       " Timestamp('1987-05-30 00:00:00'),\n",
       " Timestamp('1987-06-27 00:00:00'),\n",
       " Timestamp('1987-07-08 00:00:00'),\n",
       " Timestamp('1987-11-15 00:00:00'),\n",
       " Timestamp('1988-01-07 00:00:00'),\n",
       " Timestamp('1988-02-25 00:00:00'),\n",
       " Timestamp('1988-07-26 00:00:00'),\n",
       " Timestamp('1988-10-17 00:00:00'),\n",
       " Timestamp('1989-06-06 00:00:00'),\n",
       " Timestamp('1989-09-03 00:00:00'),\n",
       " Timestamp('1989-11-27 00:00:00'),\n",
       " Timestamp('1990-04-28 00:00:00'),\n",
       " Timestamp('1991-03-22 00:00:00'),\n",
       " Timestamp('1994-04-02 00:00:00'),\n",
       " Timestamp('1994-12-17 00:00:00'),\n",
       " Timestamp('1995-04-22 00:00:00'),\n",
       " Timestamp('1998-06-12 00:00:00'),\n",
       " Timestamp('1998-09-22 00:00:00'),\n",
       " Timestamp('2000-07-25 00:00:00'),\n",
       " Timestamp('2000-08-23 00:00:00'),\n",
       " Timestamp('2002-01-25 00:00:00'),\n",
       " Timestamp('2002-03-06 00:00:00'),\n",
       " Timestamp('2002-04-25 00:00:00'),\n",
       " Timestamp('2002-10-07 00:00:00'),\n",
       " Timestamp('2003-03-29 00:00:00'),\n",
       " Timestamp('2004-06-01 00:00:00'),\n",
       " Timestamp('2004-06-16 00:00:00'),\n",
       " Timestamp('2004-08-04 00:00:00'),\n",
       " Timestamp('2004-08-31 00:00:00'),\n",
       " Timestamp('2006-10-13 00:00:00'),\n",
       " Timestamp('2010-10-01 00:00:00'),\n",
       " Timestamp('2012-05-18 00:00:00'),\n",
       " Timestamp('2012-09-17 00:00:00'),\n",
       " Timestamp('2012-10-03 00:00:00'),\n",
       " Timestamp('2013-04-15 00:00:00'),\n",
       " Timestamp('2017-09-10 00:00:00'),\n",
       " Timestamp('2018-07-03 00:00:00'),\n",
       " Timestamp('2018-08-14 00:00:00'),\n",
       " Timestamp('2018-11-08 00:00:00'),\n",
       " Timestamp('2018-12-01 00:00:00'),\n",
       " Timestamp('2019-03-04 00:00:00'),\n",
       " Timestamp('1980-04-07 00:00:00'),\n",
       " Timestamp('1980-07-22 00:00:00'),\n",
       " Timestamp('1980-11-15 00:00:00'),\n",
       " Timestamp('1981-06-17 00:00:00'),\n",
       " Timestamp('1981-08-10 00:00:00'),\n",
       " Timestamp('1981-10-23 00:00:00'),\n",
       " Timestamp('1982-03-07 00:00:00'),\n",
       " Timestamp('1983-04-02 00:00:00'),\n",
       " Timestamp('1983-05-19 00:00:00'),\n",
       " Timestamp('1984-03-11 00:00:00'),\n",
       " Timestamp('1984-04-30 00:00:00'),\n",
       " Timestamp('1986-12-30 00:00:00'),\n",
       " Timestamp('1987-01-17 00:00:00'),\n",
       " Timestamp('1987-05-27 00:00:00'),\n",
       " Timestamp('1987-08-16 00:00:00'),\n",
       " Timestamp('1987-10-24 00:00:00'),\n",
       " Timestamp('1987-11-07 00:00:00'),\n",
       " Timestamp('1988-01-05 00:00:00'),\n",
       " Timestamp('1988-05-09 00:00:00'),\n",
       " Timestamp('1988-07-21 00:00:00'),\n",
       " Timestamp('1988-10-07 00:00:00'),\n",
       " Timestamp('1989-05-18 00:00:00'),\n",
       " Timestamp('1989-07-09 00:00:00'),\n",
       " Timestamp('1989-08-29 00:00:00'),\n",
       " Timestamp('1989-10-13 00:00:00'),\n",
       " Timestamp('1990-07-16 00:00:00'),\n",
       " Timestamp('1990-08-09 00:00:00'),\n",
       " Timestamp('1990-08-30 00:00:00'),\n",
       " Timestamp('1990-09-11 00:00:00'),\n",
       " Timestamp('1991-02-06 00:00:00'),\n",
       " Timestamp('1991-04-28 00:00:00'),\n",
       " Timestamp('1991-10-14 00:00:00'),\n",
       " Timestamp('1992-06-07 00:00:00'),\n",
       " Timestamp('1992-08-04 00:00:00'),\n",
       " Timestamp('1993-04-07 00:00:00'),\n",
       " Timestamp('1993-12-05 00:00:00'),\n",
       " Timestamp('1994-03-15 00:00:00'),\n",
       " Timestamp('1994-06-12 00:00:00'),\n",
       " Timestamp('1994-06-29 00:00:00'),\n",
       " Timestamp('1994-11-04 00:00:00'),\n",
       " Timestamp('1994-11-27 00:00:00'),\n",
       " Timestamp('1994-12-11 00:00:00'),\n",
       " Timestamp('1995-04-03 00:00:00'),\n",
       " Timestamp('1995-04-16 00:00:00'),\n",
       " Timestamp('1995-05-29 00:00:00'),\n",
       " Timestamp('1996-08-14 00:00:00'),\n",
       " Timestamp('1998-04-19 00:00:00'),\n",
       " Timestamp('1998-06-09 00:00:00'),\n",
       " Timestamp('1998-09-12 00:00:00'),\n",
       " Timestamp('1999-05-09 00:00:00'),\n",
       " Timestamp('2000-07-08 00:00:00'),\n",
       " Timestamp('2000-07-24 00:00:00'),\n",
       " Timestamp('2001-07-03 00:00:00'),\n",
       " Timestamp('2001-07-27 00:00:00'),\n",
       " Timestamp('2001-09-25 00:00:00'),\n",
       " Timestamp('2002-01-14 00:00:00'),\n",
       " Timestamp('2002-04-24 00:00:00'),\n",
       " Timestamp('2003-03-23 00:00:00'),\n",
       " Timestamp('2003-07-21 00:00:00'),\n",
       " Timestamp('2003-10-30 00:00:00'),\n",
       " Timestamp('2004-05-23 00:00:00'),\n",
       " Timestamp('2004-08-02 00:00:00'),\n",
       " Timestamp('2004-08-30 00:00:00'),\n",
       " Timestamp('2006-07-02 00:00:00'),\n",
       " Timestamp('2006-10-11 00:00:00'),\n",
       " Timestamp('2007-08-27 00:00:00'),\n",
       " Timestamp('2009-10-05 00:00:00'),\n",
       " Timestamp('2010-09-16 00:00:00'),\n",
       " Timestamp('2010-09-30 00:00:00'),\n",
       " Timestamp('2012-05-11 00:00:00'),\n",
       " Timestamp('2013-01-19 00:00:00'),\n",
       " Timestamp('2013-03-24 00:00:00'),\n",
       " Timestamp('2013-04-12 00:00:00'),\n",
       " Timestamp('2013-08-22 00:00:00'),\n",
       " Timestamp('2015-10-15 00:00:00'),\n",
       " Timestamp('2016-09-19 00:00:00'),\n",
       " Timestamp('2017-09-09 00:00:00'),\n",
       " Timestamp('2018-03-09 00:00:00'),\n",
       " Timestamp('2018-06-21 00:00:00'),\n",
       " Timestamp('2018-07-29 00:00:00'),\n",
       " Timestamp('2018-10-27 00:00:00'),\n",
       " Timestamp('2019-02-19 00:00:00'),\n",
       " Timestamp('2019-10-04 00:00:00'),\n",
       " Timestamp('2020-01-04 00:00:00'),\n",
       " Timestamp('1980-04-07 00:00:00'),\n",
       " Timestamp('1980-05-16 00:00:00'),\n",
       " Timestamp('1980-05-30 00:00:00'),\n",
       " Timestamp('1980-07-21 00:00:00'),\n",
       " Timestamp('1980-10-10 00:00:00'),\n",
       " Timestamp('1980-11-09 00:00:00'),\n",
       " Timestamp('1981-03-17 00:00:00'),\n",
       " Timestamp('1981-08-09 00:00:00'),\n",
       " Timestamp('1981-10-18 00:00:00'),\n",
       " Timestamp('1982-12-07 00:00:00'),\n",
       " Timestamp('1983-03-24 00:00:00'),\n",
       " Timestamp('1983-12-15 00:00:00'),\n",
       " Timestamp('1984-01-20 00:00:00'),\n",
       " Timestamp('1984-02-23 00:00:00'),\n",
       " Timestamp('1984-03-10 00:00:00'),\n",
       " Timestamp('1984-04-27 00:00:00'),\n",
       " Timestamp('1985-07-03 00:00:00'),\n",
       " Timestamp('1986-08-18 00:00:00'),\n",
       " Timestamp('1986-12-26 00:00:00'),\n",
       " Timestamp('1987-04-05 00:00:00'),\n",
       " Timestamp('1987-05-26 00:00:00'),\n",
       " Timestamp('1987-10-04 00:00:00'),\n",
       " Timestamp('1988-04-29 00:00:00'),\n",
       " Timestamp('1988-07-13 00:00:00'),\n",
       " Timestamp('1988-10-04 00:00:00'),\n",
       " Timestamp('1989-05-17 00:00:00'),\n",
       " Timestamp('1989-08-27 00:00:00'),\n",
       " Timestamp('1989-10-02 00:00:00'),\n",
       " Timestamp('1990-08-08 00:00:00'),\n",
       " Timestamp('1990-08-29 00:00:00'),\n",
       " Timestamp('1990-10-15 00:00:00'),\n",
       " Timestamp('1990-12-02 00:00:00'),\n",
       " Timestamp('1991-02-02 00:00:00'),\n",
       " Timestamp('1991-04-14 00:00:00'),\n",
       " Timestamp('1991-10-12 00:00:00'),\n",
       " Timestamp('1992-06-05 00:00:00'),\n",
       " Timestamp('1992-07-13 00:00:00'),\n",
       " Timestamp('1992-08-02 00:00:00'),\n",
       " Timestamp('1993-01-27 00:00:00'),\n",
       " Timestamp('1993-02-10 00:00:00'),\n",
       " Timestamp('1993-03-25 00:00:00'),\n",
       " Timestamp('1993-11-09 00:00:00'),\n",
       " Timestamp('1994-05-04 00:00:00'),\n",
       " Timestamp('1994-06-09 00:00:00'),\n",
       " Timestamp('1994-10-26 00:00:00'),\n",
       " Timestamp('1995-03-31 00:00:00'),\n",
       " Timestamp('1996-08-09 00:00:00'),\n",
       " Timestamp('1996-11-11 00:00:00'),\n",
       " Timestamp('1998-04-18 00:00:00'),\n",
       " Timestamp('1998-05-11 00:00:00'),\n",
       " Timestamp('1998-06-07 00:00:00'),\n",
       " Timestamp('1998-09-09 00:00:00'),\n",
       " Timestamp('1999-04-26 00:00:00'),\n",
       " Timestamp('1999-06-06 00:00:00'),\n",
       " Timestamp('1999-11-03 00:00:00'),\n",
       " Timestamp('1999-11-24 00:00:00'),\n",
       " Timestamp('2000-06-15 00:00:00'),\n",
       " Timestamp('2000-10-18 00:00:00'),\n",
       " Timestamp('2001-02-25 00:00:00'),\n",
       " Timestamp('2001-03-09 00:00:00'),\n",
       " Timestamp('2001-06-19 00:00:00'),\n",
       " Timestamp('2001-07-25 00:00:00'),\n",
       " Timestamp('2001-09-19 00:00:00'),\n",
       " Timestamp('2001-12-28 00:00:00'),\n",
       " Timestamp('2002-04-22 00:00:00'),\n",
       " Timestamp('2003-07-15 00:00:00'),\n",
       " Timestamp('2003-10-14 00:00:00'),\n",
       " Timestamp('2003-10-28 00:00:00'),\n",
       " Timestamp('2004-04-27 00:00:00'),\n",
       " Timestamp('2004-05-17 00:00:00'),\n",
       " Timestamp('2004-07-24 00:00:00'),\n",
       " Timestamp('2004-08-30 00:00:00'),\n",
       " Timestamp('2005-10-27 00:00:00'),\n",
       " Timestamp('2006-06-24 00:00:00'),\n",
       " Timestamp('2006-10-08 00:00:00'),\n",
       " Timestamp('2007-07-31 00:00:00'),\n",
       " Timestamp('2007-08-23 00:00:00'),\n",
       " Timestamp('2008-04-10 00:00:00'),\n",
       " Timestamp('2009-09-21 00:00:00'),\n",
       " Timestamp('2010-03-18 00:00:00'),\n",
       " Timestamp('2010-07-08 00:00:00'),\n",
       " Timestamp('2010-09-11 00:00:00'),\n",
       " Timestamp('2011-02-23 00:00:00'),\n",
       " Timestamp('2012-04-22 00:00:00'),\n",
       " Timestamp('2012-05-03 00:00:00'),\n",
       " Timestamp('2013-06-27 00:00:00'),\n",
       " Timestamp('2013-07-30 00:00:00'),\n",
       " Timestamp('2013-08-16 00:00:00'),\n",
       " Timestamp('2015-10-12 00:00:00'),\n",
       " Timestamp('2015-11-07 00:00:00'),\n",
       " Timestamp('2016-09-16 00:00:00'),\n",
       " Timestamp('2016-11-20 00:00:00'),\n",
       " Timestamp('2017-05-24 00:00:00'),\n",
       " Timestamp('2017-09-07 00:00:00'),\n",
       " Timestamp('2018-03-05 00:00:00'),\n",
       " Timestamp('2018-06-11 00:00:00'),\n",
       " Timestamp('2019-05-27 00:00:00'),\n",
       " Timestamp('2019-09-23 00:00:00'),\n",
       " Timestamp('2020-01-02 00:00:00')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = pd.to_datetime(df_site['start']).to_list()\n",
    "start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Timestamp('1980-04-19 00:00:00'),\n",
       " Timestamp('1981-03-04 00:00:00'),\n",
       " Timestamp('1981-05-30 00:00:00'),\n",
       " Timestamp('1981-12-03 00:00:00'),\n",
       " Timestamp('1981-12-23 00:00:00'),\n",
       " Timestamp('1982-04-11 00:00:00'),\n",
       " Timestamp('1982-05-26 00:00:00'),\n",
       " Timestamp('1983-04-19 00:00:00'),\n",
       " Timestamp('1987-12-10 00:00:00'),\n",
       " Timestamp('1988-08-29 00:00:00'),\n",
       " Timestamp('1988-11-19 00:00:00'),\n",
       " Timestamp('1989-09-11 00:00:00'),\n",
       " Timestamp('1990-04-07 00:00:00'),\n",
       " Timestamp('1995-02-20 00:00:00'),\n",
       " Timestamp('2000-08-05 00:00:00'),\n",
       " Timestamp('2002-04-01 00:00:00'),\n",
       " Timestamp('2002-05-19 00:00:00'),\n",
       " Timestamp('2002-06-02 00:00:00'),\n",
       " Timestamp('2002-08-07 00:00:00'),\n",
       " Timestamp('2002-10-16 00:00:00'),\n",
       " Timestamp('2002-11-08 00:00:00'),\n",
       " Timestamp('2010-10-06 00:00:00'),\n",
       " Timestamp('2010-10-24 00:00:00'),\n",
       " Timestamp('2012-07-24 00:00:00'),\n",
       " Timestamp('2012-10-30 00:00:00'),\n",
       " Timestamp('2013-04-26 00:00:00'),\n",
       " Timestamp('2017-09-28 00:00:00'),\n",
       " Timestamp('2018-10-09 00:00:00'),\n",
       " Timestamp('2018-11-16 00:00:00'),\n",
       " Timestamp('2018-12-31 00:00:00'),\n",
       " Timestamp('2019-03-20 00:00:00'),\n",
       " Timestamp('1980-04-20 00:00:00'),\n",
       " Timestamp('1980-11-29 00:00:00'),\n",
       " Timestamp('1981-03-05 00:00:00'),\n",
       " Timestamp('1981-03-28 00:00:00'),\n",
       " Timestamp('1981-04-10 00:00:00'),\n",
       " Timestamp('1981-06-01 00:00:00'),\n",
       " Timestamp('1981-07-05 00:00:00'),\n",
       " Timestamp('1982-01-02 00:00:00'),\n",
       " Timestamp('1982-04-13 00:00:00'),\n",
       " Timestamp('1982-05-29 00:00:00'),\n",
       " Timestamp('1983-04-24 00:00:00'),\n",
       " Timestamp('1984-03-19 00:00:00'),\n",
       " Timestamp('1987-01-26 00:00:00'),\n",
       " Timestamp('1987-06-05 00:00:00'),\n",
       " Timestamp('1987-07-02 00:00:00'),\n",
       " Timestamp('1987-08-01 00:00:00'),\n",
       " Timestamp('1987-12-12 00:00:00'),\n",
       " Timestamp('1988-01-26 00:00:00'),\n",
       " Timestamp('1988-03-11 00:00:00'),\n",
       " Timestamp('1988-08-30 00:00:00'),\n",
       " Timestamp('1988-11-22 00:00:00'),\n",
       " Timestamp('1989-06-16 00:00:00'),\n",
       " Timestamp('1989-09-12 00:00:00'),\n",
       " Timestamp('1990-04-14 00:00:00'),\n",
       " Timestamp('1990-05-24 00:00:00'),\n",
       " Timestamp('1991-03-31 00:00:00'),\n",
       " Timestamp('1994-04-16 00:00:00'),\n",
       " Timestamp('1995-03-01 00:00:00'),\n",
       " Timestamp('1995-05-05 00:00:00'),\n",
       " Timestamp('1998-06-19 00:00:00'),\n",
       " Timestamp('1998-10-01 00:00:00'),\n",
       " Timestamp('2000-08-11 00:00:00'),\n",
       " Timestamp('2000-08-27 00:00:00'),\n",
       " Timestamp('2002-02-24 00:00:00'),\n",
       " Timestamp('2002-04-01 00:00:00'),\n",
       " Timestamp('2002-09-30 00:00:00'),\n",
       " Timestamp('2002-11-12 00:00:00'),\n",
       " Timestamp('2003-04-02 00:00:00'),\n",
       " Timestamp('2004-06-10 00:00:00'),\n",
       " Timestamp('2004-06-25 00:00:00'),\n",
       " Timestamp('2004-08-18 00:00:00'),\n",
       " Timestamp('2004-09-08 00:00:00'),\n",
       " Timestamp('2006-10-17 00:00:00'),\n",
       " Timestamp('2010-10-25 00:00:00'),\n",
       " Timestamp('2012-07-25 00:00:00'),\n",
       " Timestamp('2012-09-25 00:00:00'),\n",
       " Timestamp('2012-11-13 00:00:00'),\n",
       " Timestamp('2013-04-27 00:00:00'),\n",
       " Timestamp('2017-09-30 00:00:00'),\n",
       " Timestamp('2018-07-09 00:00:00'),\n",
       " Timestamp('2018-10-12 00:00:00'),\n",
       " Timestamp('2018-11-18 00:00:00'),\n",
       " Timestamp('2019-01-16 00:00:00'),\n",
       " Timestamp('2019-03-21 00:00:00'),\n",
       " Timestamp('1980-04-22 00:00:00'),\n",
       " Timestamp('1980-07-28 00:00:00'),\n",
       " Timestamp('1981-06-07 00:00:00'),\n",
       " Timestamp('1981-07-09 00:00:00'),\n",
       " Timestamp('1981-08-14 00:00:00'),\n",
       " Timestamp('1982-02-10 00:00:00'),\n",
       " Timestamp('1982-06-09 00:00:00'),\n",
       " Timestamp('1983-05-08 00:00:00'),\n",
       " Timestamp('1983-05-25 00:00:00'),\n",
       " Timestamp('1984-03-21 00:00:00'),\n",
       " Timestamp('1984-05-10 00:00:00'),\n",
       " Timestamp('1987-01-04 00:00:00'),\n",
       " Timestamp('1987-02-09 00:00:00'),\n",
       " Timestamp('1987-08-04 00:00:00'),\n",
       " Timestamp('1987-09-14 00:00:00'),\n",
       " Timestamp('1987-10-29 00:00:00'),\n",
       " Timestamp('1987-12-19 00:00:00'),\n",
       " Timestamp('1988-03-14 00:00:00'),\n",
       " Timestamp('1988-05-15 00:00:00'),\n",
       " Timestamp('1988-08-31 00:00:00'),\n",
       " Timestamp('1988-12-09 00:00:00'),\n",
       " Timestamp('1989-07-03 00:00:00'),\n",
       " Timestamp('1989-07-28 00:00:00'),\n",
       " Timestamp('1989-09-13 00:00:00'),\n",
       " Timestamp('1990-06-08 00:00:00'),\n",
       " Timestamp('1990-07-21 00:00:00'),\n",
       " Timestamp('1990-08-15 00:00:00'),\n",
       " Timestamp('1990-09-04 00:00:00'),\n",
       " Timestamp('1990-09-15 00:00:00'),\n",
       " Timestamp('1991-04-03 00:00:00'),\n",
       " Timestamp('1991-05-09 00:00:00'),\n",
       " Timestamp('1991-11-02 00:00:00'),\n",
       " Timestamp('1992-06-15 00:00:00'),\n",
       " Timestamp('1992-08-08 00:00:00'),\n",
       " Timestamp('1993-04-30 00:00:00'),\n",
       " Timestamp('1994-01-03 00:00:00'),\n",
       " Timestamp('1994-04-17 00:00:00'),\n",
       " Timestamp('1994-06-23 00:00:00'),\n",
       " Timestamp('1994-07-22 00:00:00'),\n",
       " Timestamp('1994-11-11 00:00:00'),\n",
       " Timestamp('1994-12-04 00:00:00'),\n",
       " Timestamp('1995-03-04 00:00:00'),\n",
       " Timestamp('1995-04-08 00:00:00'),\n",
       " Timestamp('1995-05-26 00:00:00'),\n",
       " Timestamp('1995-06-02 00:00:00'),\n",
       " Timestamp('1996-08-27 00:00:00'),\n",
       " Timestamp('1998-04-23 00:00:00'),\n",
       " Timestamp('1998-06-24 00:00:00'),\n",
       " Timestamp('1998-10-03 00:00:00'),\n",
       " Timestamp('1999-05-19 00:00:00'),\n",
       " Timestamp('2000-07-18 00:00:00'),\n",
       " Timestamp('2000-08-29 00:00:00'),\n",
       " Timestamp('2001-07-13 00:00:00'),\n",
       " Timestamp('2001-08-06 00:00:00'),\n",
       " Timestamp('2001-10-07 00:00:00'),\n",
       " Timestamp('2002-04-02 00:00:00'),\n",
       " Timestamp('2003-03-11 00:00:00'),\n",
       " Timestamp('2003-04-11 00:00:00'),\n",
       " Timestamp('2003-08-08 00:00:00'),\n",
       " Timestamp('2003-11-06 00:00:00'),\n",
       " Timestamp('2004-06-30 00:00:00'),\n",
       " Timestamp('2004-08-20 00:00:00'),\n",
       " Timestamp('2004-10-09 00:00:00'),\n",
       " Timestamp('2006-07-08 00:00:00'),\n",
       " Timestamp('2006-10-23 00:00:00'),\n",
       " Timestamp('2007-09-16 00:00:00'),\n",
       " Timestamp('2009-10-10 00:00:00'),\n",
       " Timestamp('2010-09-24 00:00:00'),\n",
       " Timestamp('2010-10-26 00:00:00'),\n",
       " Timestamp('2012-12-31 00:00:00'),\n",
       " Timestamp('2013-01-28 00:00:00'),\n",
       " Timestamp('2013-04-06 00:00:00'),\n",
       " Timestamp('2013-04-29 00:00:00'),\n",
       " Timestamp('2013-08-26 00:00:00'),\n",
       " Timestamp('2015-10-22 00:00:00'),\n",
       " Timestamp('2016-10-03 00:00:00'),\n",
       " Timestamp('2017-09-30 00:00:00'),\n",
       " Timestamp('2018-03-17 00:00:00'),\n",
       " Timestamp('2018-07-24 00:00:00'),\n",
       " Timestamp('2018-10-13 00:00:00'),\n",
       " Timestamp('2019-02-05 00:00:00'),\n",
       " Timestamp('2019-03-27 00:00:00'),\n",
       " Timestamp('2019-10-10 00:00:00'),\n",
       " Timestamp('2020-01-13 00:00:00'),\n",
       " Timestamp('1980-04-26 00:00:00'),\n",
       " Timestamp('1980-05-24 00:00:00'),\n",
       " Timestamp('1980-06-08 00:00:00'),\n",
       " Timestamp('1980-07-28 00:00:00'),\n",
       " Timestamp('1980-10-14 00:00:00'),\n",
       " Timestamp('1981-03-13 00:00:00'),\n",
       " Timestamp('1981-07-12 00:00:00'),\n",
       " Timestamp('1981-08-15 00:00:00'),\n",
       " Timestamp('1982-06-15 00:00:00'),\n",
       " Timestamp('1982-12-12 00:00:00'),\n",
       " Timestamp('1983-05-26 00:00:00'),\n",
       " Timestamp('1983-12-24 00:00:00'),\n",
       " Timestamp('1984-01-26 00:00:00'),\n",
       " Timestamp('1984-02-27 00:00:00'),\n",
       " Timestamp('1984-03-24 00:00:00'),\n",
       " Timestamp('1984-05-12 00:00:00'),\n",
       " Timestamp('1985-07-13 00:00:00'),\n",
       " Timestamp('1986-08-26 00:00:00'),\n",
       " Timestamp('1987-02-09 00:00:00'),\n",
       " Timestamp('1987-04-16 00:00:00'),\n",
       " Timestamp('1987-09-15 00:00:00'),\n",
       " Timestamp('1988-03-16 00:00:00'),\n",
       " Timestamp('1988-05-16 00:00:00'),\n",
       " Timestamp('1988-09-02 00:00:00'),\n",
       " Timestamp('1988-12-31 00:00:00'),\n",
       " Timestamp('1989-07-29 00:00:00'),\n",
       " Timestamp('1989-09-13 00:00:00'),\n",
       " Timestamp('1990-07-30 00:00:00'),\n",
       " Timestamp('1990-08-15 00:00:00'),\n",
       " Timestamp('1990-09-16 00:00:00'),\n",
       " Timestamp('1990-10-19 00:00:00'),\n",
       " Timestamp('1991-01-01 00:00:00'),\n",
       " Timestamp('1991-04-05 00:00:00'),\n",
       " Timestamp('1991-05-10 00:00:00'),\n",
       " Timestamp('1991-11-08 00:00:00'),\n",
       " Timestamp('1992-06-22 00:00:00'),\n",
       " Timestamp('1992-07-20 00:00:00'),\n",
       " Timestamp('1992-08-24 00:00:00'),\n",
       " Timestamp('1993-02-02 00:00:00'),\n",
       " Timestamp('1993-03-01 00:00:00'),\n",
       " Timestamp('1993-05-03 00:00:00'),\n",
       " Timestamp('1994-04-18 00:00:00'),\n",
       " Timestamp('1994-05-08 00:00:00'),\n",
       " Timestamp('1994-09-30 00:00:00'),\n",
       " Timestamp('1995-03-06 00:00:00'),\n",
       " Timestamp('1995-06-05 00:00:00'),\n",
       " Timestamp('1996-09-19 00:00:00'),\n",
       " Timestamp('1996-11-19 00:00:00'),\n",
       " Timestamp('1998-04-25 00:00:00'),\n",
       " Timestamp('1998-05-30 00:00:00'),\n",
       " Timestamp('1998-06-26 00:00:00'),\n",
       " Timestamp('1998-10-04 00:00:00'),\n",
       " Timestamp('1999-05-23 00:00:00'),\n",
       " Timestamp('1999-06-18 00:00:00'),\n",
       " Timestamp('1999-11-15 00:00:00'),\n",
       " Timestamp('1999-12-10 00:00:00'),\n",
       " Timestamp('2000-09-21 00:00:00'),\n",
       " Timestamp('2000-11-05 00:00:00'),\n",
       " Timestamp('2001-03-07 00:00:00'),\n",
       " Timestamp('2001-03-19 00:00:00'),\n",
       " Timestamp('2001-07-13 00:00:00'),\n",
       " Timestamp('2001-08-09 00:00:00'),\n",
       " Timestamp('2001-10-08 00:00:00'),\n",
       " Timestamp('2002-04-03 00:00:00'),\n",
       " Timestamp('2003-05-16 00:00:00'),\n",
       " Timestamp('2003-08-17 00:00:00'),\n",
       " Timestamp('2003-10-18 00:00:00'),\n",
       " Timestamp('2003-11-07 00:00:00'),\n",
       " Timestamp('2004-05-02 00:00:00'),\n",
       " Timestamp('2004-07-14 00:00:00'),\n",
       " Timestamp('2004-08-21 00:00:00'),\n",
       " Timestamp('2004-10-10 00:00:00'),\n",
       " Timestamp('2005-11-05 00:00:00'),\n",
       " Timestamp('2006-07-10 00:00:00'),\n",
       " Timestamp('2006-10-25 00:00:00'),\n",
       " Timestamp('2007-08-05 00:00:00'),\n",
       " Timestamp('2007-09-18 00:00:00'),\n",
       " Timestamp('2008-04-19 00:00:00'),\n",
       " Timestamp('2009-10-10 00:00:00'),\n",
       " Timestamp('2010-03-30 00:00:00'),\n",
       " Timestamp('2010-07-14 00:00:00'),\n",
       " Timestamp('2010-10-27 00:00:00'),\n",
       " Timestamp('2011-03-03 00:00:00'),\n",
       " Timestamp('2012-04-26 00:00:00'),\n",
       " Timestamp('2013-04-30 00:00:00'),\n",
       " Timestamp('2013-07-07 00:00:00'),\n",
       " Timestamp('2013-08-08 00:00:00'),\n",
       " Timestamp('2013-09-09 00:00:00'),\n",
       " Timestamp('2015-10-23 00:00:00'),\n",
       " Timestamp('2015-11-18 00:00:00'),\n",
       " Timestamp('2016-10-06 00:00:00'),\n",
       " Timestamp('2016-11-30 00:00:00'),\n",
       " Timestamp('2017-06-06 00:00:00'),\n",
       " Timestamp('2017-10-03 00:00:00'),\n",
       " Timestamp('2018-03-23 00:00:00'),\n",
       " Timestamp('2019-04-07 00:00:00'),\n",
       " Timestamp('2019-06-05 00:00:00'),\n",
       " Timestamp('2019-10-11 00:00:00'),\n",
       " Timestamp('2020-01-19 00:00:00')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "end = pd.to_datetime(df_site['end']).to_list()\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[datetime.datetime(1984, 5, 28, 0, 0),\n",
       " datetime.datetime(1984, 6, 13, 0, 0),\n",
       " datetime.datetime(1984, 6, 29, 0, 0),\n",
       " datetime.datetime(1986, 6, 3, 0, 0),\n",
       " datetime.datetime(1986, 6, 19, 0, 0),\n",
       " datetime.datetime(1986, 7, 21, 0, 0),\n",
       " datetime.datetime(1986, 8, 6, 0, 0),\n",
       " datetime.datetime(1986, 10, 9, 0, 0),\n",
       " datetime.datetime(1987, 6, 22, 0, 0),\n",
       " datetime.datetime(1987, 7, 8, 0, 0),\n",
       " datetime.datetime(1987, 7, 24, 0, 0),\n",
       " datetime.datetime(1987, 9, 10, 0, 0),\n",
       " datetime.datetime(1987, 9, 26, 0, 0),\n",
       " datetime.datetime(1988, 5, 23, 0, 0),\n",
       " datetime.datetime(1988, 6, 8, 0, 0),\n",
       " datetime.datetime(1988, 6, 24, 0, 0),\n",
       " datetime.datetime(1988, 7, 10, 0, 0),\n",
       " datetime.datetime(1988, 8, 11, 0, 0),\n",
       " datetime.datetime(1988, 8, 27, 0, 0),\n",
       " datetime.datetime(1989, 7, 13, 0, 0),\n",
       " datetime.datetime(1989, 9, 15, 0, 0),\n",
       " datetime.datetime(1989, 10, 1, 0, 0),\n",
       " datetime.datetime(1990, 9, 2, 0, 0),\n",
       " datetime.datetime(1990, 10, 4, 0, 0),\n",
       " datetime.datetime(1991, 6, 17, 0, 0),\n",
       " datetime.datetime(1991, 7, 3, 0, 0),\n",
       " datetime.datetime(1991, 10, 7, 0, 0),\n",
       " datetime.datetime(1992, 5, 2, 0, 0),\n",
       " datetime.datetime(1992, 6, 19, 0, 0),\n",
       " datetime.datetime(1992, 7, 5, 0, 0),\n",
       " datetime.datetime(1992, 7, 21, 0, 0),\n",
       " datetime.datetime(1992, 9, 7, 0, 0),\n",
       " datetime.datetime(1992, 9, 23, 0, 0),\n",
       " datetime.datetime(1993, 6, 6, 0, 0),\n",
       " datetime.datetime(1993, 8, 25, 0, 0),\n",
       " datetime.datetime(1993, 9, 10, 0, 0),\n",
       " datetime.datetime(1993, 9, 26, 0, 0),\n",
       " datetime.datetime(1994, 5, 8, 0, 0),\n",
       " datetime.datetime(1994, 5, 24, 0, 0),\n",
       " datetime.datetime(1994, 6, 9, 0, 0),\n",
       " datetime.datetime(1994, 6, 25, 0, 0),\n",
       " datetime.datetime(1994, 7, 11, 0, 0),\n",
       " datetime.datetime(1994, 8, 12, 0, 0),\n",
       " datetime.datetime(1995, 6, 12, 0, 0),\n",
       " datetime.datetime(1995, 8, 15, 0, 0),\n",
       " datetime.datetime(1995, 8, 31, 0, 0),\n",
       " datetime.datetime(1995, 9, 16, 0, 0),\n",
       " datetime.datetime(1995, 10, 18, 0, 0),\n",
       " datetime.datetime(1996, 5, 29, 0, 0),\n",
       " datetime.datetime(1996, 6, 30, 0, 0),\n",
       " datetime.datetime(1996, 8, 17, 0, 0),\n",
       " datetime.datetime(1997, 5, 16, 0, 0),\n",
       " datetime.datetime(1997, 7, 3, 0, 0),\n",
       " datetime.datetime(1997, 8, 20, 0, 0),\n",
       " datetime.datetime(1998, 8, 7, 0, 0),\n",
       " datetime.datetime(1998, 9, 8, 0, 0),\n",
       " datetime.datetime(1999, 5, 22, 0, 0),\n",
       " datetime.datetime(1999, 8, 26, 0, 0),\n",
       " datetime.datetime(1999, 9, 27, 0, 0),\n",
       " datetime.datetime(1999, 10, 13, 0, 0),\n",
       " datetime.datetime(2000, 9, 13, 0, 0),\n",
       " datetime.datetime(2000, 10, 15, 0, 0),\n",
       " datetime.datetime(2001, 5, 11, 0, 0),\n",
       " datetime.datetime(2001, 6, 28, 0, 0),\n",
       " datetime.datetime(2001, 10, 2, 0, 0),\n",
       " datetime.datetime(2002, 7, 1, 0, 0),\n",
       " datetime.datetime(2002, 7, 17, 0, 0),\n",
       " datetime.datetime(2002, 10, 21, 0, 0),\n",
       " datetime.datetime(2003, 6, 2, 0, 0),\n",
       " datetime.datetime(2003, 7, 4, 0, 0),\n",
       " datetime.datetime(2003, 7, 20, 0, 0),\n",
       " datetime.datetime(2003, 9, 22, 0, 0),\n",
       " datetime.datetime(2003, 10, 8, 0, 0),\n",
       " datetime.datetime(2003, 10, 24, 0, 0),\n",
       " datetime.datetime(2004, 5, 3, 0, 0),\n",
       " datetime.datetime(2004, 6, 20, 0, 0),\n",
       " datetime.datetime(2004, 7, 6, 0, 0),\n",
       " datetime.datetime(2004, 9, 8, 0, 0),\n",
       " datetime.datetime(2004, 10, 10, 0, 0),\n",
       " datetime.datetime(2004, 10, 26, 0, 0),\n",
       " datetime.datetime(2005, 5, 22, 0, 0),\n",
       " datetime.datetime(2005, 7, 9, 0, 0),\n",
       " datetime.datetime(2005, 8, 26, 0, 0),\n",
       " datetime.datetime(2005, 9, 11, 0, 0),\n",
       " datetime.datetime(2006, 5, 25, 0, 0),\n",
       " datetime.datetime(2006, 6, 26, 0, 0),\n",
       " datetime.datetime(2006, 7, 28, 0, 0),\n",
       " datetime.datetime(2006, 8, 13, 0, 0),\n",
       " datetime.datetime(2006, 8, 29, 0, 0),\n",
       " datetime.datetime(2006, 9, 14, 0, 0),\n",
       " datetime.datetime(2006, 9, 30, 0, 0),\n",
       " datetime.datetime(2007, 6, 13, 0, 0),\n",
       " datetime.datetime(2007, 6, 29, 0, 0),\n",
       " datetime.datetime(2007, 7, 15, 0, 0),\n",
       " datetime.datetime(2007, 7, 31, 0, 0),\n",
       " datetime.datetime(2007, 8, 16, 0, 0),\n",
       " datetime.datetime(2007, 9, 1, 0, 0),\n",
       " datetime.datetime(2007, 9, 17, 0, 0),\n",
       " datetime.datetime(2007, 10, 3, 0, 0),\n",
       " datetime.datetime(2008, 6, 15, 0, 0),\n",
       " datetime.datetime(2008, 7, 1, 0, 0),\n",
       " datetime.datetime(2008, 8, 2, 0, 0),\n",
       " datetime.datetime(2008, 8, 18, 0, 0),\n",
       " datetime.datetime(2009, 5, 17, 0, 0),\n",
       " datetime.datetime(2009, 8, 5, 0, 0),\n",
       " datetime.datetime(2009, 8, 21, 0, 0),\n",
       " datetime.datetime(2010, 7, 7, 0, 0),\n",
       " datetime.datetime(2010, 8, 24, 0, 0),\n",
       " datetime.datetime(2010, 9, 25, 0, 0),\n",
       " datetime.datetime(2011, 6, 8, 0, 0),\n",
       " datetime.datetime(2011, 6, 24, 0, 0),\n",
       " datetime.datetime(2011, 8, 11, 0, 0),\n",
       " datetime.datetime(2011, 8, 27, 0, 0),\n",
       " datetime.datetime(2011, 9, 28, 0, 0),\n",
       " datetime.datetime(2013, 6, 29, 0, 0),\n",
       " datetime.datetime(2013, 8, 16, 0, 0),\n",
       " datetime.datetime(2014, 5, 31, 0, 0),\n",
       " datetime.datetime(2014, 7, 2, 0, 0),\n",
       " datetime.datetime(2014, 8, 3, 0, 0),\n",
       " datetime.datetime(2014, 9, 20, 0, 0),\n",
       " datetime.datetime(2015, 5, 2, 0, 0),\n",
       " datetime.datetime(2015, 6, 3, 0, 0),\n",
       " datetime.datetime(2015, 6, 19, 0, 0),\n",
       " datetime.datetime(2016, 6, 5, 0, 0),\n",
       " datetime.datetime(2016, 6, 21, 0, 0),\n",
       " datetime.datetime(2016, 7, 23, 0, 0),\n",
       " datetime.datetime(2016, 9, 9, 0, 0),\n",
       " datetime.datetime(2016, 10, 27, 0, 0),\n",
       " datetime.datetime(2016, 11, 12, 0, 0),\n",
       " datetime.datetime(2017, 6, 8, 0, 0),\n",
       " datetime.datetime(2017, 6, 24, 0, 0),\n",
       " datetime.datetime(2017, 9, 12, 0, 0),\n",
       " datetime.datetime(2018, 5, 10, 0, 0),\n",
       " datetime.datetime(2018, 5, 26, 0, 0),\n",
       " datetime.datetime(2018, 6, 11, 0, 0),\n",
       " datetime.datetime(2018, 6, 27, 0, 0),\n",
       " datetime.datetime(2018, 7, 13, 0, 0),\n",
       " datetime.datetime(2018, 7, 29, 0, 0),\n",
       " datetime.datetime(2018, 8, 14, 0, 0),\n",
       " datetime.datetime(2018, 8, 30, 0, 0),\n",
       " datetime.datetime(2018, 9, 15, 0, 0),\n",
       " datetime.datetime(2019, 8, 17, 0, 0),\n",
       " datetime.datetime(2019, 9, 2, 0, 0),\n",
       " datetime.datetime(2020, 7, 2, 0, 0),\n",
       " datetime.datetime(2020, 8, 3, 0, 0),\n",
       " datetime.datetime(2020, 8, 19, 0, 0),\n",
       " datetime.datetime(2020, 9, 4, 0, 0),\n",
       " datetime.datetime(2020, 10, 6, 0, 0),\n",
       " datetime.datetime(2020, 10, 22, 0, 0),\n",
       " datetime.datetime(2021, 5, 18, 0, 0),\n",
       " datetime.datetime(2021, 6, 3, 0, 0),\n",
       " datetime.datetime(2021, 7, 5, 0, 0),\n",
       " datetime.datetime(2021, 9, 7, 0, 0),\n",
       " datetime.datetime(2021, 9, 23, 0, 0),\n",
       " datetime.datetime(2021, 10, 25, 0, 0)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dates = []\n",
    "for tile in clean_tiles['Files']:\n",
    "    string_date = tile.split('_')[3]\n",
    "    date = dt.strptime(string_date, '%Y%m%d')\n",
    "    dates.append(date)\n",
    "dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_drought = []\n",
    "for i in range(0, len(dates)):\n",
    "    for j in range(0, len(start)):\n",
    "        if (dates[i] > start[j]) and (dates[i] < end[j]):\n",
    "            in_drought.append(dates[i])\n",
    "            break;\n",
    "len(in_drought)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[datetime.datetime(1987, 6, 22, 0, 0),\n",
       " datetime.datetime(1987, 7, 8, 0, 0),\n",
       " datetime.datetime(1987, 7, 24, 0, 0),\n",
       " datetime.datetime(1987, 9, 10, 0, 0),\n",
       " datetime.datetime(1988, 8, 11, 0, 0),\n",
       " datetime.datetime(1988, 8, 27, 0, 0),\n",
       " datetime.datetime(1989, 7, 13, 0, 0),\n",
       " datetime.datetime(1990, 9, 2, 0, 0),\n",
       " datetime.datetime(1992, 6, 19, 0, 0),\n",
       " datetime.datetime(1994, 6, 25, 0, 0),\n",
       " datetime.datetime(1994, 7, 11, 0, 0),\n",
       " datetime.datetime(1994, 8, 12, 0, 0),\n",
       " datetime.datetime(1996, 8, 17, 0, 0),\n",
       " datetime.datetime(1999, 5, 22, 0, 0),\n",
       " datetime.datetime(2000, 9, 13, 0, 0),\n",
       " datetime.datetime(2001, 6, 28, 0, 0),\n",
       " datetime.datetime(2001, 10, 2, 0, 0),\n",
       " datetime.datetime(2002, 7, 1, 0, 0),\n",
       " datetime.datetime(2002, 7, 17, 0, 0),\n",
       " datetime.datetime(2002, 10, 21, 0, 0),\n",
       " datetime.datetime(2003, 7, 20, 0, 0),\n",
       " datetime.datetime(2004, 6, 20, 0, 0),\n",
       " datetime.datetime(2004, 7, 6, 0, 0),\n",
       " datetime.datetime(2004, 9, 8, 0, 0),\n",
       " datetime.datetime(2006, 6, 26, 0, 0),\n",
       " datetime.datetime(2007, 9, 1, 0, 0),\n",
       " datetime.datetime(2007, 9, 17, 0, 0),\n",
       " datetime.datetime(2010, 9, 25, 0, 0),\n",
       " datetime.datetime(2013, 6, 29, 0, 0),\n",
       " datetime.datetime(2017, 9, 12, 0, 0),\n",
       " datetime.datetime(2018, 6, 27, 0, 0),\n",
       " datetime.datetime(2018, 7, 13, 0, 0),\n",
       " datetime.datetime(2018, 7, 29, 0, 0),\n",
       " datetime.datetime(2018, 8, 14, 0, 0),\n",
       " datetime.datetime(2018, 8, 30, 0, 0),\n",
       " datetime.datetime(2018, 9, 15, 0, 0)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_drought"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "36 of the landsat observations are from within a drought. That means our target variable split is 36/155."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtain Data for CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = '../Landsat_Data/DSWE_CRB/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "155"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tiles = []\n",
    "dates = []\n",
    "for tile in clean_tiles['Files']:\n",
    "    tif_file = rxr.open_rasterio(directory + tile)\n",
    "    tif_file_sliced = tif_file.sel(x=slice(-864520, -854520), y=slice(1937400, 1927395))\n",
    "    \n",
    "    # Find date within tile filename\n",
    "    tile_date = tile.split('_')[3]\n",
    "    tile_date = [dt(int(tile_date[:4]), int(tile_date[4:6]), int(tile_date[6:8])).date()]\n",
    "        \n",
    "    # Add date as a dimension to tile DataArray\n",
    "    time_da = xr.DataArray(tile_date, [('time', tile_date[0:1])])\n",
    "    tif_file = tif_file_sliced.expand_dims(time=time_da)\n",
    "    \n",
    "    dates.append(tile_date)\n",
    "    tiles.append(tif_file)\n",
    "len(tiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.date(1984, 5, 28)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tiles[0].time.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 334, 334)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tiles[0].values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2, 3, 4], dtype=uint8),\n",
       " array([104999,   4566,     33,    250,   1708]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(tiles[0][0][0])\n",
    "np.unique(tiles[0][0][0].values, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess Data for CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 14062 entries, 1981-10-01 to 2020-03-31\n",
      "Data columns (total 21 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   tmmx_mean             14062 non-null  float64\n",
      " 1   log_tmmx_var          14062 non-null  float64\n",
      " 2   tmmn_mean             14062 non-null  float64\n",
      " 3   log_tmmn_var          14062 non-null  float64\n",
      " 4   pr_mean               14062 non-null  float64\n",
      " 5   pr_var                14062 non-null  float64\n",
      " 6   pr_sum                14062 non-null  float64\n",
      " 7   SPEI_mean             14062 non-null  float64\n",
      " 8   SPEI_stdev            14062 non-null  float64\n",
      " 9   pet_mean              14062 non-null  float64\n",
      " 10  pet_var               14062 non-null  float64\n",
      " 11  pet_sum               14062 non-null  float64\n",
      " 12  SoilM_0_10cm_mean     14062 non-null  float64\n",
      " 13  SoilM_0_10cm_stdev    14062 non-null  float64\n",
      " 14  SoilM_10_40cm_mean    14062 non-null  float64\n",
      " 15  SoilM_10_40cm_stdev   14062 non-null  float64\n",
      " 16  SoilM_40_100cm_mean   14062 non-null  float64\n",
      " 17  SoilM_40_100cm_stdev  14062 non-null  float64\n",
      " 18  SWE_mean              14062 non-null  float64\n",
      " 19  SWE_stdev             14062 non-null  float64\n",
      " 20  weibull_jd_30d_avg    14062 non-null  float64\n",
      "dtypes: float64(21)\n",
      "memory usage: 2.4 MB\n"
     ]
    }
   ],
   "source": [
    "gauge_num = \"09037500\"\n",
    "df_cnn = pd.read_csv(\n",
    "    \"../Streamflow_Data/Streamflow_clean_\" + gauge_num + \".csv\", \n",
    "    index_col = \"Date\", \n",
    "    parse_dates=True\n",
    ")\n",
    "df_cnn.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tmmx_mean</th>\n",
       "      <th>log_tmmx_var</th>\n",
       "      <th>tmmn_mean</th>\n",
       "      <th>log_tmmn_var</th>\n",
       "      <th>pr_mean</th>\n",
       "      <th>pr_var</th>\n",
       "      <th>pr_sum</th>\n",
       "      <th>SPEI_mean</th>\n",
       "      <th>SPEI_stdev</th>\n",
       "      <th>pet_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>pet_sum</th>\n",
       "      <th>SoilM_0_10cm_mean</th>\n",
       "      <th>SoilM_0_10cm_stdev</th>\n",
       "      <th>SoilM_10_40cm_mean</th>\n",
       "      <th>SoilM_10_40cm_stdev</th>\n",
       "      <th>SoilM_40_100cm_mean</th>\n",
       "      <th>SoilM_40_100cm_stdev</th>\n",
       "      <th>SWE_mean</th>\n",
       "      <th>SWE_stdev</th>\n",
       "      <th>weibull_jd_30d_avg_1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-03-22</th>\n",
       "      <td>31.0</td>\n",
       "      <td>0.397940</td>\n",
       "      <td>32.7</td>\n",
       "      <td>0.397940</td>\n",
       "      <td>4.9</td>\n",
       "      <td>2.9</td>\n",
       "      <td>145.0</td>\n",
       "      <td>-0.312</td>\n",
       "      <td>-0.312</td>\n",
       "      <td>1.6</td>\n",
       "      <td>...</td>\n",
       "      <td>46.4</td>\n",
       "      <td>34.28</td>\n",
       "      <td>4.66</td>\n",
       "      <td>80.41</td>\n",
       "      <td>16.68</td>\n",
       "      <td>129.98</td>\n",
       "      <td>8.38</td>\n",
       "      <td>268.25</td>\n",
       "      <td>80.41</td>\n",
       "      <td>41.176471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-23</th>\n",
       "      <td>33.9</td>\n",
       "      <td>0.380211</td>\n",
       "      <td>31.6</td>\n",
       "      <td>0.380211</td>\n",
       "      <td>5.1</td>\n",
       "      <td>4.3</td>\n",
       "      <td>149.3</td>\n",
       "      <td>-0.208</td>\n",
       "      <td>-0.208</td>\n",
       "      <td>1.9</td>\n",
       "      <td>...</td>\n",
       "      <td>55.8</td>\n",
       "      <td>34.26</td>\n",
       "      <td>4.65</td>\n",
       "      <td>80.47</td>\n",
       "      <td>16.55</td>\n",
       "      <td>130.10</td>\n",
       "      <td>8.41</td>\n",
       "      <td>271.24</td>\n",
       "      <td>81.83</td>\n",
       "      <td>52.135375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-24</th>\n",
       "      <td>36.0</td>\n",
       "      <td>0.602060</td>\n",
       "      <td>36.5</td>\n",
       "      <td>0.602060</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>13.9</td>\n",
       "      <td>-0.104</td>\n",
       "      <td>-0.104</td>\n",
       "      <td>2.6</td>\n",
       "      <td>...</td>\n",
       "      <td>75.0</td>\n",
       "      <td>34.30</td>\n",
       "      <td>4.69</td>\n",
       "      <td>80.58</td>\n",
       "      <td>16.52</td>\n",
       "      <td>130.21</td>\n",
       "      <td>8.43</td>\n",
       "      <td>275.16</td>\n",
       "      <td>83.41</td>\n",
       "      <td>56.325544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-25</th>\n",
       "      <td>36.4</td>\n",
       "      <td>0.556303</td>\n",
       "      <td>38.5</td>\n",
       "      <td>0.556303</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>86.8</td>\n",
       "      <td>34.32</td>\n",
       "      <td>4.72</td>\n",
       "      <td>80.67</td>\n",
       "      <td>16.46</td>\n",
       "      <td>130.34</td>\n",
       "      <td>8.46</td>\n",
       "      <td>276.11</td>\n",
       "      <td>85.02</td>\n",
       "      <td>56.728445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-26</th>\n",
       "      <td>38.6</td>\n",
       "      <td>0.491362</td>\n",
       "      <td>35.3</td>\n",
       "      <td>0.491362</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.108</td>\n",
       "      <td>0.108</td>\n",
       "      <td>3.1</td>\n",
       "      <td>...</td>\n",
       "      <td>90.8</td>\n",
       "      <td>34.36</td>\n",
       "      <td>4.81</td>\n",
       "      <td>80.81</td>\n",
       "      <td>16.46</td>\n",
       "      <td>130.46</td>\n",
       "      <td>8.49</td>\n",
       "      <td>276.18</td>\n",
       "      <td>86.85</td>\n",
       "      <td>55.358582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-27</th>\n",
       "      <td>31.2</td>\n",
       "      <td>0.505150</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.505150</td>\n",
       "      <td>7.5</td>\n",
       "      <td>6.3</td>\n",
       "      <td>222.3</td>\n",
       "      <td>0.216</td>\n",
       "      <td>0.216</td>\n",
       "      <td>1.6</td>\n",
       "      <td>...</td>\n",
       "      <td>46.1</td>\n",
       "      <td>34.38</td>\n",
       "      <td>4.90</td>\n",
       "      <td>80.98</td>\n",
       "      <td>16.50</td>\n",
       "      <td>130.60</td>\n",
       "      <td>8.54</td>\n",
       "      <td>276.10</td>\n",
       "      <td>87.40</td>\n",
       "      <td>45.527800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-28</th>\n",
       "      <td>27.3</td>\n",
       "      <td>0.643453</td>\n",
       "      <td>27.5</td>\n",
       "      <td>0.643453</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>7.1</td>\n",
       "      <td>0.324</td>\n",
       "      <td>0.324</td>\n",
       "      <td>1.3</td>\n",
       "      <td>...</td>\n",
       "      <td>36.6</td>\n",
       "      <td>34.31</td>\n",
       "      <td>4.85</td>\n",
       "      <td>81.06</td>\n",
       "      <td>16.38</td>\n",
       "      <td>130.74</td>\n",
       "      <td>8.58</td>\n",
       "      <td>280.59</td>\n",
       "      <td>89.11</td>\n",
       "      <td>40.290089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-29</th>\n",
       "      <td>32.1</td>\n",
       "      <td>0.707570</td>\n",
       "      <td>28.6</td>\n",
       "      <td>0.707570</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.9</td>\n",
       "      <td>24.1</td>\n",
       "      <td>0.432</td>\n",
       "      <td>0.432</td>\n",
       "      <td>1.8</td>\n",
       "      <td>...</td>\n",
       "      <td>50.2</td>\n",
       "      <td>34.26</td>\n",
       "      <td>4.81</td>\n",
       "      <td>81.09</td>\n",
       "      <td>16.20</td>\n",
       "      <td>130.85</td>\n",
       "      <td>8.60</td>\n",
       "      <td>281.15</td>\n",
       "      <td>89.42</td>\n",
       "      <td>41.821112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-30</th>\n",
       "      <td>34.1</td>\n",
       "      <td>0.447158</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.447158</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>8.9</td>\n",
       "      <td>0.540</td>\n",
       "      <td>0.540</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>58.3</td>\n",
       "      <td>34.23</td>\n",
       "      <td>4.81</td>\n",
       "      <td>81.18</td>\n",
       "      <td>16.15</td>\n",
       "      <td>130.97</td>\n",
       "      <td>8.61</td>\n",
       "      <td>282.60</td>\n",
       "      <td>89.21</td>\n",
       "      <td>44.883159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-31</th>\n",
       "      <td>38.4</td>\n",
       "      <td>0.653213</td>\n",
       "      <td>36.4</td>\n",
       "      <td>0.653213</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>7.2</td>\n",
       "      <td>0.334</td>\n",
       "      <td>0.334</td>\n",
       "      <td>3.1</td>\n",
       "      <td>...</td>\n",
       "      <td>89.7</td>\n",
       "      <td>34.22</td>\n",
       "      <td>4.86</td>\n",
       "      <td>81.28</td>\n",
       "      <td>16.10</td>\n",
       "      <td>131.09</td>\n",
       "      <td>8.64</td>\n",
       "      <td>282.96</td>\n",
       "      <td>89.57</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            tmmx_mean  log_tmmx_var  tmmn_mean  log_tmmn_var  pr_mean  pr_var  \\\n",
       "Date                                                                            \n",
       "2020-03-22       31.0      0.397940       32.7      0.397940      4.9     2.9   \n",
       "2020-03-23       33.9      0.380211       31.6      0.380211      5.1     4.3   \n",
       "2020-03-24       36.0      0.602060       36.5      0.602060      0.5     0.6   \n",
       "2020-03-25       36.4      0.556303       38.5      0.556303      0.0     0.0   \n",
       "2020-03-26       38.6      0.491362       35.3      0.491362      0.0     0.0   \n",
       "2020-03-27       31.2      0.505150       30.0      0.505150      7.5     6.3   \n",
       "2020-03-28       27.3      0.643453       27.5      0.643453      0.3     0.2   \n",
       "2020-03-29       32.1      0.707570       28.6      0.707570      0.8     0.9   \n",
       "2020-03-30       34.1      0.447158       33.6      0.447158      0.4     0.3   \n",
       "2020-03-31       38.4      0.653213       36.4      0.653213      0.3     0.3   \n",
       "\n",
       "            pr_sum  SPEI_mean  SPEI_stdev  pet_mean  ...  pet_sum  \\\n",
       "Date                                                 ...            \n",
       "2020-03-22   145.0     -0.312      -0.312       1.6  ...     46.4   \n",
       "2020-03-23   149.3     -0.208      -0.208       1.9  ...     55.8   \n",
       "2020-03-24    13.9     -0.104      -0.104       2.6  ...     75.0   \n",
       "2020-03-25     0.0      0.000       0.000       3.0  ...     86.8   \n",
       "2020-03-26     0.0      0.108       0.108       3.1  ...     90.8   \n",
       "2020-03-27   222.3      0.216       0.216       1.6  ...     46.1   \n",
       "2020-03-28     7.1      0.324       0.324       1.3  ...     36.6   \n",
       "2020-03-29    24.1      0.432       0.432       1.8  ...     50.2   \n",
       "2020-03-30     8.9      0.540       0.540       2.0  ...     58.3   \n",
       "2020-03-31     7.2      0.334       0.334       3.1  ...     89.7   \n",
       "\n",
       "            SoilM_0_10cm_mean  SoilM_0_10cm_stdev  SoilM_10_40cm_mean  \\\n",
       "Date                                                                    \n",
       "2020-03-22              34.28                4.66               80.41   \n",
       "2020-03-23              34.26                4.65               80.47   \n",
       "2020-03-24              34.30                4.69               80.58   \n",
       "2020-03-25              34.32                4.72               80.67   \n",
       "2020-03-26              34.36                4.81               80.81   \n",
       "2020-03-27              34.38                4.90               80.98   \n",
       "2020-03-28              34.31                4.85               81.06   \n",
       "2020-03-29              34.26                4.81               81.09   \n",
       "2020-03-30              34.23                4.81               81.18   \n",
       "2020-03-31              34.22                4.86               81.28   \n",
       "\n",
       "            SoilM_10_40cm_stdev  SoilM_40_100cm_mean  SoilM_40_100cm_stdev  \\\n",
       "Date                                                                         \n",
       "2020-03-22                16.68               129.98                  8.38   \n",
       "2020-03-23                16.55               130.10                  8.41   \n",
       "2020-03-24                16.52               130.21                  8.43   \n",
       "2020-03-25                16.46               130.34                  8.46   \n",
       "2020-03-26                16.46               130.46                  8.49   \n",
       "2020-03-27                16.50               130.60                  8.54   \n",
       "2020-03-28                16.38               130.74                  8.58   \n",
       "2020-03-29                16.20               130.85                  8.60   \n",
       "2020-03-30                16.15               130.97                  8.61   \n",
       "2020-03-31                16.10               131.09                  8.64   \n",
       "\n",
       "            SWE_mean  SWE_stdev  weibull_jd_30d_avg_1  \n",
       "Date                                                   \n",
       "2020-03-22    268.25      80.41             41.176471  \n",
       "2020-03-23    271.24      81.83             52.135375  \n",
       "2020-03-24    275.16      83.41             56.325544  \n",
       "2020-03-25    276.11      85.02             56.728445  \n",
       "2020-03-26    276.18      86.85             55.358582  \n",
       "2020-03-27    276.10      87.40             45.527800  \n",
       "2020-03-28    280.59      89.11             40.290089  \n",
       "2020-03-29    281.15      89.42             41.821112  \n",
       "2020-03-30    282.60      89.21             44.883159  \n",
       "2020-03-31    282.96      89.57                   NaN  \n",
       "\n",
       "[10 rows x 21 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "periods = -3\n",
    "df_cnn[\"weibull_jd_30d_avg_\" + str(periods)[1:]] = df_cnn[\"weibull_jd_30d_avg\"].shift(periods=periods)\n",
    "df_cnn = df_cnn.drop(\"weibull_jd_30d_avg\", axis=1)\n",
    "df_cnn.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tmmx_mean</th>\n",
       "      <th>log_tmmx_var</th>\n",
       "      <th>tmmn_mean</th>\n",
       "      <th>log_tmmn_var</th>\n",
       "      <th>pr_mean</th>\n",
       "      <th>pr_var</th>\n",
       "      <th>pr_sum</th>\n",
       "      <th>SPEI_mean</th>\n",
       "      <th>SPEI_stdev</th>\n",
       "      <th>pet_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>pet_sum</th>\n",
       "      <th>SoilM_0_10cm_mean</th>\n",
       "      <th>SoilM_0_10cm_stdev</th>\n",
       "      <th>SoilM_10_40cm_mean</th>\n",
       "      <th>SoilM_10_40cm_stdev</th>\n",
       "      <th>SoilM_40_100cm_mean</th>\n",
       "      <th>SoilM_40_100cm_stdev</th>\n",
       "      <th>SWE_mean</th>\n",
       "      <th>SWE_stdev</th>\n",
       "      <th>weibull_jd_30d_avg_1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-03-21</th>\n",
       "      <td>33.8</td>\n",
       "      <td>0.591065</td>\n",
       "      <td>30.9</td>\n",
       "      <td>0.591065</td>\n",
       "      <td>2.7</td>\n",
       "      <td>0.7</td>\n",
       "      <td>79.0</td>\n",
       "      <td>-0.416</td>\n",
       "      <td>-0.416</td>\n",
       "      <td>1.8</td>\n",
       "      <td>...</td>\n",
       "      <td>53.3</td>\n",
       "      <td>34.32</td>\n",
       "      <td>4.67</td>\n",
       "      <td>80.33</td>\n",
       "      <td>16.76</td>\n",
       "      <td>129.86</td>\n",
       "      <td>8.36</td>\n",
       "      <td>265.15</td>\n",
       "      <td>79.78</td>\n",
       "      <td>55.761483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-22</th>\n",
       "      <td>31.0</td>\n",
       "      <td>0.397940</td>\n",
       "      <td>32.7</td>\n",
       "      <td>0.397940</td>\n",
       "      <td>4.9</td>\n",
       "      <td>2.9</td>\n",
       "      <td>145.0</td>\n",
       "      <td>-0.312</td>\n",
       "      <td>-0.312</td>\n",
       "      <td>1.6</td>\n",
       "      <td>...</td>\n",
       "      <td>46.4</td>\n",
       "      <td>34.28</td>\n",
       "      <td>4.66</td>\n",
       "      <td>80.41</td>\n",
       "      <td>16.68</td>\n",
       "      <td>129.98</td>\n",
       "      <td>8.38</td>\n",
       "      <td>268.25</td>\n",
       "      <td>80.41</td>\n",
       "      <td>41.176471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-23</th>\n",
       "      <td>33.9</td>\n",
       "      <td>0.380211</td>\n",
       "      <td>31.6</td>\n",
       "      <td>0.380211</td>\n",
       "      <td>5.1</td>\n",
       "      <td>4.3</td>\n",
       "      <td>149.3</td>\n",
       "      <td>-0.208</td>\n",
       "      <td>-0.208</td>\n",
       "      <td>1.9</td>\n",
       "      <td>...</td>\n",
       "      <td>55.8</td>\n",
       "      <td>34.26</td>\n",
       "      <td>4.65</td>\n",
       "      <td>80.47</td>\n",
       "      <td>16.55</td>\n",
       "      <td>130.10</td>\n",
       "      <td>8.41</td>\n",
       "      <td>271.24</td>\n",
       "      <td>81.83</td>\n",
       "      <td>52.135375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-24</th>\n",
       "      <td>36.0</td>\n",
       "      <td>0.602060</td>\n",
       "      <td>36.5</td>\n",
       "      <td>0.602060</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>13.9</td>\n",
       "      <td>-0.104</td>\n",
       "      <td>-0.104</td>\n",
       "      <td>2.6</td>\n",
       "      <td>...</td>\n",
       "      <td>75.0</td>\n",
       "      <td>34.30</td>\n",
       "      <td>4.69</td>\n",
       "      <td>80.58</td>\n",
       "      <td>16.52</td>\n",
       "      <td>130.21</td>\n",
       "      <td>8.43</td>\n",
       "      <td>275.16</td>\n",
       "      <td>83.41</td>\n",
       "      <td>56.325544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-25</th>\n",
       "      <td>36.4</td>\n",
       "      <td>0.556303</td>\n",
       "      <td>38.5</td>\n",
       "      <td>0.556303</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>86.8</td>\n",
       "      <td>34.32</td>\n",
       "      <td>4.72</td>\n",
       "      <td>80.67</td>\n",
       "      <td>16.46</td>\n",
       "      <td>130.34</td>\n",
       "      <td>8.46</td>\n",
       "      <td>276.11</td>\n",
       "      <td>85.02</td>\n",
       "      <td>56.728445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-26</th>\n",
       "      <td>38.6</td>\n",
       "      <td>0.491362</td>\n",
       "      <td>35.3</td>\n",
       "      <td>0.491362</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.108</td>\n",
       "      <td>0.108</td>\n",
       "      <td>3.1</td>\n",
       "      <td>...</td>\n",
       "      <td>90.8</td>\n",
       "      <td>34.36</td>\n",
       "      <td>4.81</td>\n",
       "      <td>80.81</td>\n",
       "      <td>16.46</td>\n",
       "      <td>130.46</td>\n",
       "      <td>8.49</td>\n",
       "      <td>276.18</td>\n",
       "      <td>86.85</td>\n",
       "      <td>55.358582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-27</th>\n",
       "      <td>31.2</td>\n",
       "      <td>0.505150</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.505150</td>\n",
       "      <td>7.5</td>\n",
       "      <td>6.3</td>\n",
       "      <td>222.3</td>\n",
       "      <td>0.216</td>\n",
       "      <td>0.216</td>\n",
       "      <td>1.6</td>\n",
       "      <td>...</td>\n",
       "      <td>46.1</td>\n",
       "      <td>34.38</td>\n",
       "      <td>4.90</td>\n",
       "      <td>80.98</td>\n",
       "      <td>16.50</td>\n",
       "      <td>130.60</td>\n",
       "      <td>8.54</td>\n",
       "      <td>276.10</td>\n",
       "      <td>87.40</td>\n",
       "      <td>45.527800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-28</th>\n",
       "      <td>27.3</td>\n",
       "      <td>0.643453</td>\n",
       "      <td>27.5</td>\n",
       "      <td>0.643453</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>7.1</td>\n",
       "      <td>0.324</td>\n",
       "      <td>0.324</td>\n",
       "      <td>1.3</td>\n",
       "      <td>...</td>\n",
       "      <td>36.6</td>\n",
       "      <td>34.31</td>\n",
       "      <td>4.85</td>\n",
       "      <td>81.06</td>\n",
       "      <td>16.38</td>\n",
       "      <td>130.74</td>\n",
       "      <td>8.58</td>\n",
       "      <td>280.59</td>\n",
       "      <td>89.11</td>\n",
       "      <td>40.290089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-29</th>\n",
       "      <td>32.1</td>\n",
       "      <td>0.707570</td>\n",
       "      <td>28.6</td>\n",
       "      <td>0.707570</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.9</td>\n",
       "      <td>24.1</td>\n",
       "      <td>0.432</td>\n",
       "      <td>0.432</td>\n",
       "      <td>1.8</td>\n",
       "      <td>...</td>\n",
       "      <td>50.2</td>\n",
       "      <td>34.26</td>\n",
       "      <td>4.81</td>\n",
       "      <td>81.09</td>\n",
       "      <td>16.20</td>\n",
       "      <td>130.85</td>\n",
       "      <td>8.60</td>\n",
       "      <td>281.15</td>\n",
       "      <td>89.42</td>\n",
       "      <td>41.821112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-30</th>\n",
       "      <td>34.1</td>\n",
       "      <td>0.447158</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.447158</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>8.9</td>\n",
       "      <td>0.540</td>\n",
       "      <td>0.540</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>58.3</td>\n",
       "      <td>34.23</td>\n",
       "      <td>4.81</td>\n",
       "      <td>81.18</td>\n",
       "      <td>16.15</td>\n",
       "      <td>130.97</td>\n",
       "      <td>8.61</td>\n",
       "      <td>282.60</td>\n",
       "      <td>89.21</td>\n",
       "      <td>44.883159</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            tmmx_mean  log_tmmx_var  tmmn_mean  log_tmmn_var  pr_mean  pr_var  \\\n",
       "Date                                                                            \n",
       "2020-03-21       33.8      0.591065       30.9      0.591065      2.7     0.7   \n",
       "2020-03-22       31.0      0.397940       32.7      0.397940      4.9     2.9   \n",
       "2020-03-23       33.9      0.380211       31.6      0.380211      5.1     4.3   \n",
       "2020-03-24       36.0      0.602060       36.5      0.602060      0.5     0.6   \n",
       "2020-03-25       36.4      0.556303       38.5      0.556303      0.0     0.0   \n",
       "2020-03-26       38.6      0.491362       35.3      0.491362      0.0     0.0   \n",
       "2020-03-27       31.2      0.505150       30.0      0.505150      7.5     6.3   \n",
       "2020-03-28       27.3      0.643453       27.5      0.643453      0.3     0.2   \n",
       "2020-03-29       32.1      0.707570       28.6      0.707570      0.8     0.9   \n",
       "2020-03-30       34.1      0.447158       33.6      0.447158      0.4     0.3   \n",
       "\n",
       "            pr_sum  SPEI_mean  SPEI_stdev  pet_mean  ...  pet_sum  \\\n",
       "Date                                                 ...            \n",
       "2020-03-21    79.0     -0.416      -0.416       1.8  ...     53.3   \n",
       "2020-03-22   145.0     -0.312      -0.312       1.6  ...     46.4   \n",
       "2020-03-23   149.3     -0.208      -0.208       1.9  ...     55.8   \n",
       "2020-03-24    13.9     -0.104      -0.104       2.6  ...     75.0   \n",
       "2020-03-25     0.0      0.000       0.000       3.0  ...     86.8   \n",
       "2020-03-26     0.0      0.108       0.108       3.1  ...     90.8   \n",
       "2020-03-27   222.3      0.216       0.216       1.6  ...     46.1   \n",
       "2020-03-28     7.1      0.324       0.324       1.3  ...     36.6   \n",
       "2020-03-29    24.1      0.432       0.432       1.8  ...     50.2   \n",
       "2020-03-30     8.9      0.540       0.540       2.0  ...     58.3   \n",
       "\n",
       "            SoilM_0_10cm_mean  SoilM_0_10cm_stdev  SoilM_10_40cm_mean  \\\n",
       "Date                                                                    \n",
       "2020-03-21              34.32                4.67               80.33   \n",
       "2020-03-22              34.28                4.66               80.41   \n",
       "2020-03-23              34.26                4.65               80.47   \n",
       "2020-03-24              34.30                4.69               80.58   \n",
       "2020-03-25              34.32                4.72               80.67   \n",
       "2020-03-26              34.36                4.81               80.81   \n",
       "2020-03-27              34.38                4.90               80.98   \n",
       "2020-03-28              34.31                4.85               81.06   \n",
       "2020-03-29              34.26                4.81               81.09   \n",
       "2020-03-30              34.23                4.81               81.18   \n",
       "\n",
       "            SoilM_10_40cm_stdev  SoilM_40_100cm_mean  SoilM_40_100cm_stdev  \\\n",
       "Date                                                                         \n",
       "2020-03-21                16.76               129.86                  8.36   \n",
       "2020-03-22                16.68               129.98                  8.38   \n",
       "2020-03-23                16.55               130.10                  8.41   \n",
       "2020-03-24                16.52               130.21                  8.43   \n",
       "2020-03-25                16.46               130.34                  8.46   \n",
       "2020-03-26                16.46               130.46                  8.49   \n",
       "2020-03-27                16.50               130.60                  8.54   \n",
       "2020-03-28                16.38               130.74                  8.58   \n",
       "2020-03-29                16.20               130.85                  8.60   \n",
       "2020-03-30                16.15               130.97                  8.61   \n",
       "\n",
       "            SWE_mean  SWE_stdev  weibull_jd_30d_avg_1  \n",
       "Date                                                   \n",
       "2020-03-21    265.15      79.78             55.761483  \n",
       "2020-03-22    268.25      80.41             41.176471  \n",
       "2020-03-23    271.24      81.83             52.135375  \n",
       "2020-03-24    275.16      83.41             56.325544  \n",
       "2020-03-25    276.11      85.02             56.728445  \n",
       "2020-03-26    276.18      86.85             55.358582  \n",
       "2020-03-27    276.10      87.40             45.527800  \n",
       "2020-03-28    280.59      89.11             40.290089  \n",
       "2020-03-29    281.15      89.42             41.821112  \n",
       "2020-03-30    282.60      89.21             44.883159  \n",
       "\n",
       "[10 rows x 21 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cnn = df_cnn[df_cnn[\"weibull_jd_30d_avg_\" + str(periods)[1:]].notnull()]\n",
    "df_cnn.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Shifting for Forecasting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"shift\" function allows us to easily take our target variable column and shift it a certain number of rows in order to offset them for use as prediction values. This means that the model will be attempting to use historical data to predict a future value. The \"periods\" variable can be adjusted to change the number of days out you are forecasting for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tmmx_mean</th>\n",
       "      <th>log_tmmx_var</th>\n",
       "      <th>tmmn_mean</th>\n",
       "      <th>log_tmmn_var</th>\n",
       "      <th>pr_mean</th>\n",
       "      <th>pr_var</th>\n",
       "      <th>pr_sum</th>\n",
       "      <th>SPEI_mean</th>\n",
       "      <th>SPEI_stdev</th>\n",
       "      <th>pet_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>SoilM_0_10cm_mean</th>\n",
       "      <th>SoilM_0_10cm_stdev</th>\n",
       "      <th>SoilM_10_40cm_mean</th>\n",
       "      <th>SoilM_10_40cm_stdev</th>\n",
       "      <th>SoilM_40_100cm_mean</th>\n",
       "      <th>SoilM_40_100cm_stdev</th>\n",
       "      <th>SWE_mean</th>\n",
       "      <th>SWE_stdev</th>\n",
       "      <th>weibull_jd_30d_avg</th>\n",
       "      <th>weibull_jd_30d_avg_3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-03-22</th>\n",
       "      <td>31.0</td>\n",
       "      <td>0.397940</td>\n",
       "      <td>32.7</td>\n",
       "      <td>0.397940</td>\n",
       "      <td>4.9</td>\n",
       "      <td>2.9</td>\n",
       "      <td>145.0</td>\n",
       "      <td>-0.312</td>\n",
       "      <td>-0.312</td>\n",
       "      <td>1.6</td>\n",
       "      <td>...</td>\n",
       "      <td>34.28</td>\n",
       "      <td>4.66</td>\n",
       "      <td>80.41</td>\n",
       "      <td>16.68</td>\n",
       "      <td>129.98</td>\n",
       "      <td>8.38</td>\n",
       "      <td>268.25</td>\n",
       "      <td>80.41</td>\n",
       "      <td>55.761483</td>\n",
       "      <td>56.325544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-23</th>\n",
       "      <td>33.9</td>\n",
       "      <td>0.380211</td>\n",
       "      <td>31.6</td>\n",
       "      <td>0.380211</td>\n",
       "      <td>5.1</td>\n",
       "      <td>4.3</td>\n",
       "      <td>149.3</td>\n",
       "      <td>-0.208</td>\n",
       "      <td>-0.208</td>\n",
       "      <td>1.9</td>\n",
       "      <td>...</td>\n",
       "      <td>34.26</td>\n",
       "      <td>4.65</td>\n",
       "      <td>80.47</td>\n",
       "      <td>16.55</td>\n",
       "      <td>130.10</td>\n",
       "      <td>8.41</td>\n",
       "      <td>271.24</td>\n",
       "      <td>81.83</td>\n",
       "      <td>41.176471</td>\n",
       "      <td>56.728445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-24</th>\n",
       "      <td>36.0</td>\n",
       "      <td>0.602060</td>\n",
       "      <td>36.5</td>\n",
       "      <td>0.602060</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>13.9</td>\n",
       "      <td>-0.104</td>\n",
       "      <td>-0.104</td>\n",
       "      <td>2.6</td>\n",
       "      <td>...</td>\n",
       "      <td>34.30</td>\n",
       "      <td>4.69</td>\n",
       "      <td>80.58</td>\n",
       "      <td>16.52</td>\n",
       "      <td>130.21</td>\n",
       "      <td>8.43</td>\n",
       "      <td>275.16</td>\n",
       "      <td>83.41</td>\n",
       "      <td>52.135375</td>\n",
       "      <td>55.358582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-25</th>\n",
       "      <td>36.4</td>\n",
       "      <td>0.556303</td>\n",
       "      <td>38.5</td>\n",
       "      <td>0.556303</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>34.32</td>\n",
       "      <td>4.72</td>\n",
       "      <td>80.67</td>\n",
       "      <td>16.46</td>\n",
       "      <td>130.34</td>\n",
       "      <td>8.46</td>\n",
       "      <td>276.11</td>\n",
       "      <td>85.02</td>\n",
       "      <td>56.325544</td>\n",
       "      <td>45.527800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-26</th>\n",
       "      <td>38.6</td>\n",
       "      <td>0.491362</td>\n",
       "      <td>35.3</td>\n",
       "      <td>0.491362</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.108</td>\n",
       "      <td>0.108</td>\n",
       "      <td>3.1</td>\n",
       "      <td>...</td>\n",
       "      <td>34.36</td>\n",
       "      <td>4.81</td>\n",
       "      <td>80.81</td>\n",
       "      <td>16.46</td>\n",
       "      <td>130.46</td>\n",
       "      <td>8.49</td>\n",
       "      <td>276.18</td>\n",
       "      <td>86.85</td>\n",
       "      <td>56.728445</td>\n",
       "      <td>40.290089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-27</th>\n",
       "      <td>31.2</td>\n",
       "      <td>0.505150</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.505150</td>\n",
       "      <td>7.5</td>\n",
       "      <td>6.3</td>\n",
       "      <td>222.3</td>\n",
       "      <td>0.216</td>\n",
       "      <td>0.216</td>\n",
       "      <td>1.6</td>\n",
       "      <td>...</td>\n",
       "      <td>34.38</td>\n",
       "      <td>4.90</td>\n",
       "      <td>80.98</td>\n",
       "      <td>16.50</td>\n",
       "      <td>130.60</td>\n",
       "      <td>8.54</td>\n",
       "      <td>276.10</td>\n",
       "      <td>87.40</td>\n",
       "      <td>55.358582</td>\n",
       "      <td>41.821112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-28</th>\n",
       "      <td>27.3</td>\n",
       "      <td>0.643453</td>\n",
       "      <td>27.5</td>\n",
       "      <td>0.643453</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>7.1</td>\n",
       "      <td>0.324</td>\n",
       "      <td>0.324</td>\n",
       "      <td>1.3</td>\n",
       "      <td>...</td>\n",
       "      <td>34.31</td>\n",
       "      <td>4.85</td>\n",
       "      <td>81.06</td>\n",
       "      <td>16.38</td>\n",
       "      <td>130.74</td>\n",
       "      <td>8.58</td>\n",
       "      <td>280.59</td>\n",
       "      <td>89.11</td>\n",
       "      <td>45.527800</td>\n",
       "      <td>44.883159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-29</th>\n",
       "      <td>32.1</td>\n",
       "      <td>0.707570</td>\n",
       "      <td>28.6</td>\n",
       "      <td>0.707570</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.9</td>\n",
       "      <td>24.1</td>\n",
       "      <td>0.432</td>\n",
       "      <td>0.432</td>\n",
       "      <td>1.8</td>\n",
       "      <td>...</td>\n",
       "      <td>34.26</td>\n",
       "      <td>4.81</td>\n",
       "      <td>81.09</td>\n",
       "      <td>16.20</td>\n",
       "      <td>130.85</td>\n",
       "      <td>8.60</td>\n",
       "      <td>281.15</td>\n",
       "      <td>89.42</td>\n",
       "      <td>40.290089</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-30</th>\n",
       "      <td>34.1</td>\n",
       "      <td>0.447158</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.447158</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>8.9</td>\n",
       "      <td>0.540</td>\n",
       "      <td>0.540</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>34.23</td>\n",
       "      <td>4.81</td>\n",
       "      <td>81.18</td>\n",
       "      <td>16.15</td>\n",
       "      <td>130.97</td>\n",
       "      <td>8.61</td>\n",
       "      <td>282.60</td>\n",
       "      <td>89.21</td>\n",
       "      <td>41.821112</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-31</th>\n",
       "      <td>38.4</td>\n",
       "      <td>0.653213</td>\n",
       "      <td>36.4</td>\n",
       "      <td>0.653213</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>7.2</td>\n",
       "      <td>0.334</td>\n",
       "      <td>0.334</td>\n",
       "      <td>3.1</td>\n",
       "      <td>...</td>\n",
       "      <td>34.22</td>\n",
       "      <td>4.86</td>\n",
       "      <td>81.28</td>\n",
       "      <td>16.10</td>\n",
       "      <td>131.09</td>\n",
       "      <td>8.64</td>\n",
       "      <td>282.96</td>\n",
       "      <td>89.57</td>\n",
       "      <td>44.883159</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            tmmx_mean  log_tmmx_var  tmmn_mean  log_tmmn_var  pr_mean  pr_var  \\\n",
       "Date                                                                            \n",
       "2020-03-22       31.0      0.397940       32.7      0.397940      4.9     2.9   \n",
       "2020-03-23       33.9      0.380211       31.6      0.380211      5.1     4.3   \n",
       "2020-03-24       36.0      0.602060       36.5      0.602060      0.5     0.6   \n",
       "2020-03-25       36.4      0.556303       38.5      0.556303      0.0     0.0   \n",
       "2020-03-26       38.6      0.491362       35.3      0.491362      0.0     0.0   \n",
       "2020-03-27       31.2      0.505150       30.0      0.505150      7.5     6.3   \n",
       "2020-03-28       27.3      0.643453       27.5      0.643453      0.3     0.2   \n",
       "2020-03-29       32.1      0.707570       28.6      0.707570      0.8     0.9   \n",
       "2020-03-30       34.1      0.447158       33.6      0.447158      0.4     0.3   \n",
       "2020-03-31       38.4      0.653213       36.4      0.653213      0.3     0.3   \n",
       "\n",
       "            pr_sum  SPEI_mean  SPEI_stdev  pet_mean  ...  SoilM_0_10cm_mean  \\\n",
       "Date                                                 ...                      \n",
       "2020-03-22   145.0     -0.312      -0.312       1.6  ...              34.28   \n",
       "2020-03-23   149.3     -0.208      -0.208       1.9  ...              34.26   \n",
       "2020-03-24    13.9     -0.104      -0.104       2.6  ...              34.30   \n",
       "2020-03-25     0.0      0.000       0.000       3.0  ...              34.32   \n",
       "2020-03-26     0.0      0.108       0.108       3.1  ...              34.36   \n",
       "2020-03-27   222.3      0.216       0.216       1.6  ...              34.38   \n",
       "2020-03-28     7.1      0.324       0.324       1.3  ...              34.31   \n",
       "2020-03-29    24.1      0.432       0.432       1.8  ...              34.26   \n",
       "2020-03-30     8.9      0.540       0.540       2.0  ...              34.23   \n",
       "2020-03-31     7.2      0.334       0.334       3.1  ...              34.22   \n",
       "\n",
       "            SoilM_0_10cm_stdev  SoilM_10_40cm_mean  SoilM_10_40cm_stdev  \\\n",
       "Date                                                                      \n",
       "2020-03-22                4.66               80.41                16.68   \n",
       "2020-03-23                4.65               80.47                16.55   \n",
       "2020-03-24                4.69               80.58                16.52   \n",
       "2020-03-25                4.72               80.67                16.46   \n",
       "2020-03-26                4.81               80.81                16.46   \n",
       "2020-03-27                4.90               80.98                16.50   \n",
       "2020-03-28                4.85               81.06                16.38   \n",
       "2020-03-29                4.81               81.09                16.20   \n",
       "2020-03-30                4.81               81.18                16.15   \n",
       "2020-03-31                4.86               81.28                16.10   \n",
       "\n",
       "            SoilM_40_100cm_mean  SoilM_40_100cm_stdev  SWE_mean  SWE_stdev  \\\n",
       "Date                                                                         \n",
       "2020-03-22               129.98                  8.38    268.25      80.41   \n",
       "2020-03-23               130.10                  8.41    271.24      81.83   \n",
       "2020-03-24               130.21                  8.43    275.16      83.41   \n",
       "2020-03-25               130.34                  8.46    276.11      85.02   \n",
       "2020-03-26               130.46                  8.49    276.18      86.85   \n",
       "2020-03-27               130.60                  8.54    276.10      87.40   \n",
       "2020-03-28               130.74                  8.58    280.59      89.11   \n",
       "2020-03-29               130.85                  8.60    281.15      89.42   \n",
       "2020-03-30               130.97                  8.61    282.60      89.21   \n",
       "2020-03-31               131.09                  8.64    282.96      89.57   \n",
       "\n",
       "            weibull_jd_30d_avg  weibull_jd_30d_avg_3  \n",
       "Date                                                  \n",
       "2020-03-22           55.761483             56.325544  \n",
       "2020-03-23           41.176471             56.728445  \n",
       "2020-03-24           52.135375             55.358582  \n",
       "2020-03-25           56.325544             45.527800  \n",
       "2020-03-26           56.728445             40.290089  \n",
       "2020-03-27           55.358582             41.821112  \n",
       "2020-03-28           45.527800             44.883159  \n",
       "2020-03-29           40.290089                   NaN  \n",
       "2020-03-30           41.821112                   NaN  \n",
       "2020-03-31           44.883159                   NaN  \n",
       "\n",
       "[10 rows x 22 columns]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "periods = -3\n",
    "df_lstm[\"weibull_jd_30d_avg_\" + str(periods)[1:]] = df_lstm[\"weibull_jd_30d_avg\"].shift(periods=periods)\n",
    "# df_lstm = df_lstm.drop(\"weibull_jd_30d_avg\", axis=1)\n",
    "df_lstm.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lstm = df_lstm[df_lstm[\"weibull_jd_30d_avg_\" + str(periods)[1:]].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tmmx_mean</th>\n",
       "      <th>log_tmmx_var</th>\n",
       "      <th>tmmn_mean</th>\n",
       "      <th>log_tmmn_var</th>\n",
       "      <th>pr_mean</th>\n",
       "      <th>pr_var</th>\n",
       "      <th>pr_sum</th>\n",
       "      <th>SPEI_mean</th>\n",
       "      <th>SPEI_stdev</th>\n",
       "      <th>pet_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>SoilM_0_10cm_mean</th>\n",
       "      <th>SoilM_0_10cm_stdev</th>\n",
       "      <th>SoilM_10_40cm_mean</th>\n",
       "      <th>SoilM_10_40cm_stdev</th>\n",
       "      <th>SoilM_40_100cm_mean</th>\n",
       "      <th>SoilM_40_100cm_stdev</th>\n",
       "      <th>SWE_mean</th>\n",
       "      <th>SWE_stdev</th>\n",
       "      <th>weibull_jd_30d_avg</th>\n",
       "      <th>weibull_jd_30d_avg_3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-03-19</th>\n",
       "      <td>29.9</td>\n",
       "      <td>0.477121</td>\n",
       "      <td>32.9</td>\n",
       "      <td>0.477121</td>\n",
       "      <td>11.0</td>\n",
       "      <td>12.5</td>\n",
       "      <td>321.5</td>\n",
       "      <td>-0.818</td>\n",
       "      <td>-0.818</td>\n",
       "      <td>1.3</td>\n",
       "      <td>...</td>\n",
       "      <td>34.30</td>\n",
       "      <td>4.56</td>\n",
       "      <td>80.08</td>\n",
       "      <td>16.83</td>\n",
       "      <td>129.59</td>\n",
       "      <td>8.26</td>\n",
       "      <td>254.70</td>\n",
       "      <td>75.69</td>\n",
       "      <td>68.331990</td>\n",
       "      <td>55.761483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-20</th>\n",
       "      <td>31.1</td>\n",
       "      <td>0.397940</td>\n",
       "      <td>30.6</td>\n",
       "      <td>0.397940</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.2</td>\n",
       "      <td>104.7</td>\n",
       "      <td>-0.520</td>\n",
       "      <td>-0.520</td>\n",
       "      <td>1.4</td>\n",
       "      <td>...</td>\n",
       "      <td>34.35</td>\n",
       "      <td>4.68</td>\n",
       "      <td>80.26</td>\n",
       "      <td>16.89</td>\n",
       "      <td>129.73</td>\n",
       "      <td>8.31</td>\n",
       "      <td>261.96</td>\n",
       "      <td>78.34</td>\n",
       "      <td>60.112812</td>\n",
       "      <td>41.176471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-21</th>\n",
       "      <td>33.8</td>\n",
       "      <td>0.591065</td>\n",
       "      <td>30.9</td>\n",
       "      <td>0.591065</td>\n",
       "      <td>2.7</td>\n",
       "      <td>0.7</td>\n",
       "      <td>79.0</td>\n",
       "      <td>-0.416</td>\n",
       "      <td>-0.416</td>\n",
       "      <td>1.8</td>\n",
       "      <td>...</td>\n",
       "      <td>34.32</td>\n",
       "      <td>4.67</td>\n",
       "      <td>80.33</td>\n",
       "      <td>16.76</td>\n",
       "      <td>129.86</td>\n",
       "      <td>8.36</td>\n",
       "      <td>265.15</td>\n",
       "      <td>79.78</td>\n",
       "      <td>57.937147</td>\n",
       "      <td>52.135375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-22</th>\n",
       "      <td>31.0</td>\n",
       "      <td>0.397940</td>\n",
       "      <td>32.7</td>\n",
       "      <td>0.397940</td>\n",
       "      <td>4.9</td>\n",
       "      <td>2.9</td>\n",
       "      <td>145.0</td>\n",
       "      <td>-0.312</td>\n",
       "      <td>-0.312</td>\n",
       "      <td>1.6</td>\n",
       "      <td>...</td>\n",
       "      <td>34.28</td>\n",
       "      <td>4.66</td>\n",
       "      <td>80.41</td>\n",
       "      <td>16.68</td>\n",
       "      <td>129.98</td>\n",
       "      <td>8.38</td>\n",
       "      <td>268.25</td>\n",
       "      <td>80.41</td>\n",
       "      <td>55.761483</td>\n",
       "      <td>56.325544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-23</th>\n",
       "      <td>33.9</td>\n",
       "      <td>0.380211</td>\n",
       "      <td>31.6</td>\n",
       "      <td>0.380211</td>\n",
       "      <td>5.1</td>\n",
       "      <td>4.3</td>\n",
       "      <td>149.3</td>\n",
       "      <td>-0.208</td>\n",
       "      <td>-0.208</td>\n",
       "      <td>1.9</td>\n",
       "      <td>...</td>\n",
       "      <td>34.26</td>\n",
       "      <td>4.65</td>\n",
       "      <td>80.47</td>\n",
       "      <td>16.55</td>\n",
       "      <td>130.10</td>\n",
       "      <td>8.41</td>\n",
       "      <td>271.24</td>\n",
       "      <td>81.83</td>\n",
       "      <td>41.176471</td>\n",
       "      <td>56.728445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-24</th>\n",
       "      <td>36.0</td>\n",
       "      <td>0.602060</td>\n",
       "      <td>36.5</td>\n",
       "      <td>0.602060</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>13.9</td>\n",
       "      <td>-0.104</td>\n",
       "      <td>-0.104</td>\n",
       "      <td>2.6</td>\n",
       "      <td>...</td>\n",
       "      <td>34.30</td>\n",
       "      <td>4.69</td>\n",
       "      <td>80.58</td>\n",
       "      <td>16.52</td>\n",
       "      <td>130.21</td>\n",
       "      <td>8.43</td>\n",
       "      <td>275.16</td>\n",
       "      <td>83.41</td>\n",
       "      <td>52.135375</td>\n",
       "      <td>55.358582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-25</th>\n",
       "      <td>36.4</td>\n",
       "      <td>0.556303</td>\n",
       "      <td>38.5</td>\n",
       "      <td>0.556303</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>34.32</td>\n",
       "      <td>4.72</td>\n",
       "      <td>80.67</td>\n",
       "      <td>16.46</td>\n",
       "      <td>130.34</td>\n",
       "      <td>8.46</td>\n",
       "      <td>276.11</td>\n",
       "      <td>85.02</td>\n",
       "      <td>56.325544</td>\n",
       "      <td>45.527800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-26</th>\n",
       "      <td>38.6</td>\n",
       "      <td>0.491362</td>\n",
       "      <td>35.3</td>\n",
       "      <td>0.491362</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.108</td>\n",
       "      <td>0.108</td>\n",
       "      <td>3.1</td>\n",
       "      <td>...</td>\n",
       "      <td>34.36</td>\n",
       "      <td>4.81</td>\n",
       "      <td>80.81</td>\n",
       "      <td>16.46</td>\n",
       "      <td>130.46</td>\n",
       "      <td>8.49</td>\n",
       "      <td>276.18</td>\n",
       "      <td>86.85</td>\n",
       "      <td>56.728445</td>\n",
       "      <td>40.290089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-27</th>\n",
       "      <td>31.2</td>\n",
       "      <td>0.505150</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.505150</td>\n",
       "      <td>7.5</td>\n",
       "      <td>6.3</td>\n",
       "      <td>222.3</td>\n",
       "      <td>0.216</td>\n",
       "      <td>0.216</td>\n",
       "      <td>1.6</td>\n",
       "      <td>...</td>\n",
       "      <td>34.38</td>\n",
       "      <td>4.90</td>\n",
       "      <td>80.98</td>\n",
       "      <td>16.50</td>\n",
       "      <td>130.60</td>\n",
       "      <td>8.54</td>\n",
       "      <td>276.10</td>\n",
       "      <td>87.40</td>\n",
       "      <td>55.358582</td>\n",
       "      <td>41.821112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-28</th>\n",
       "      <td>27.3</td>\n",
       "      <td>0.643453</td>\n",
       "      <td>27.5</td>\n",
       "      <td>0.643453</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>7.1</td>\n",
       "      <td>0.324</td>\n",
       "      <td>0.324</td>\n",
       "      <td>1.3</td>\n",
       "      <td>...</td>\n",
       "      <td>34.31</td>\n",
       "      <td>4.85</td>\n",
       "      <td>81.06</td>\n",
       "      <td>16.38</td>\n",
       "      <td>130.74</td>\n",
       "      <td>8.58</td>\n",
       "      <td>280.59</td>\n",
       "      <td>89.11</td>\n",
       "      <td>45.527800</td>\n",
       "      <td>44.883159</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            tmmx_mean  log_tmmx_var  tmmn_mean  log_tmmn_var  pr_mean  pr_var  \\\n",
       "Date                                                                            \n",
       "2020-03-19       29.9      0.477121       32.9      0.477121     11.0    12.5   \n",
       "2020-03-20       31.1      0.397940       30.6      0.397940      3.5     3.2   \n",
       "2020-03-21       33.8      0.591065       30.9      0.591065      2.7     0.7   \n",
       "2020-03-22       31.0      0.397940       32.7      0.397940      4.9     2.9   \n",
       "2020-03-23       33.9      0.380211       31.6      0.380211      5.1     4.3   \n",
       "2020-03-24       36.0      0.602060       36.5      0.602060      0.5     0.6   \n",
       "2020-03-25       36.4      0.556303       38.5      0.556303      0.0     0.0   \n",
       "2020-03-26       38.6      0.491362       35.3      0.491362      0.0     0.0   \n",
       "2020-03-27       31.2      0.505150       30.0      0.505150      7.5     6.3   \n",
       "2020-03-28       27.3      0.643453       27.5      0.643453      0.3     0.2   \n",
       "\n",
       "            pr_sum  SPEI_mean  SPEI_stdev  pet_mean  ...  SoilM_0_10cm_mean  \\\n",
       "Date                                                 ...                      \n",
       "2020-03-19   321.5     -0.818      -0.818       1.3  ...              34.30   \n",
       "2020-03-20   104.7     -0.520      -0.520       1.4  ...              34.35   \n",
       "2020-03-21    79.0     -0.416      -0.416       1.8  ...              34.32   \n",
       "2020-03-22   145.0     -0.312      -0.312       1.6  ...              34.28   \n",
       "2020-03-23   149.3     -0.208      -0.208       1.9  ...              34.26   \n",
       "2020-03-24    13.9     -0.104      -0.104       2.6  ...              34.30   \n",
       "2020-03-25     0.0      0.000       0.000       3.0  ...              34.32   \n",
       "2020-03-26     0.0      0.108       0.108       3.1  ...              34.36   \n",
       "2020-03-27   222.3      0.216       0.216       1.6  ...              34.38   \n",
       "2020-03-28     7.1      0.324       0.324       1.3  ...              34.31   \n",
       "\n",
       "            SoilM_0_10cm_stdev  SoilM_10_40cm_mean  SoilM_10_40cm_stdev  \\\n",
       "Date                                                                      \n",
       "2020-03-19                4.56               80.08                16.83   \n",
       "2020-03-20                4.68               80.26                16.89   \n",
       "2020-03-21                4.67               80.33                16.76   \n",
       "2020-03-22                4.66               80.41                16.68   \n",
       "2020-03-23                4.65               80.47                16.55   \n",
       "2020-03-24                4.69               80.58                16.52   \n",
       "2020-03-25                4.72               80.67                16.46   \n",
       "2020-03-26                4.81               80.81                16.46   \n",
       "2020-03-27                4.90               80.98                16.50   \n",
       "2020-03-28                4.85               81.06                16.38   \n",
       "\n",
       "            SoilM_40_100cm_mean  SoilM_40_100cm_stdev  SWE_mean  SWE_stdev  \\\n",
       "Date                                                                         \n",
       "2020-03-19               129.59                  8.26    254.70      75.69   \n",
       "2020-03-20               129.73                  8.31    261.96      78.34   \n",
       "2020-03-21               129.86                  8.36    265.15      79.78   \n",
       "2020-03-22               129.98                  8.38    268.25      80.41   \n",
       "2020-03-23               130.10                  8.41    271.24      81.83   \n",
       "2020-03-24               130.21                  8.43    275.16      83.41   \n",
       "2020-03-25               130.34                  8.46    276.11      85.02   \n",
       "2020-03-26               130.46                  8.49    276.18      86.85   \n",
       "2020-03-27               130.60                  8.54    276.10      87.40   \n",
       "2020-03-28               130.74                  8.58    280.59      89.11   \n",
       "\n",
       "            weibull_jd_30d_avg  weibull_jd_30d_avg_3  \n",
       "Date                                                  \n",
       "2020-03-19           68.331990             55.761483  \n",
       "2020-03-20           60.112812             41.176471  \n",
       "2020-03-21           57.937147             52.135375  \n",
       "2020-03-22           55.761483             56.325544  \n",
       "2020-03-23           41.176471             56.728445  \n",
       "2020-03-24           52.135375             55.358582  \n",
       "2020-03-25           56.325544             45.527800  \n",
       "2020-03-26           56.728445             40.290089  \n",
       "2020-03-27           55.358582             41.821112  \n",
       "2020-03-28           45.527800             44.883159  \n",
       "\n",
       "[10 rows x 22 columns]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lstm.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 14059 entries, 1981-10-01 to 2020-03-28\n",
      "Data columns (total 22 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   tmmx_mean             14059 non-null  float64\n",
      " 1   log_tmmx_var          14059 non-null  float64\n",
      " 2   tmmn_mean             14059 non-null  float64\n",
      " 3   log_tmmn_var          14059 non-null  float64\n",
      " 4   pr_mean               14059 non-null  float64\n",
      " 5   pr_var                14059 non-null  float64\n",
      " 6   pr_sum                14059 non-null  float64\n",
      " 7   SPEI_mean             14059 non-null  float64\n",
      " 8   SPEI_stdev            14059 non-null  float64\n",
      " 9   pet_mean              14059 non-null  float64\n",
      " 10  pet_var               14059 non-null  float64\n",
      " 11  pet_sum               14059 non-null  float64\n",
      " 12  SoilM_0_10cm_mean     14059 non-null  float64\n",
      " 13  SoilM_0_10cm_stdev    14059 non-null  float64\n",
      " 14  SoilM_10_40cm_mean    14059 non-null  float64\n",
      " 15  SoilM_10_40cm_stdev   14059 non-null  float64\n",
      " 16  SoilM_40_100cm_mean   14059 non-null  float64\n",
      " 17  SoilM_40_100cm_stdev  14059 non-null  float64\n",
      " 18  SWE_mean              14059 non-null  float64\n",
      " 19  SWE_stdev             14059 non-null  float64\n",
      " 20  weibull_jd_30d_avg    14059 non-null  float64\n",
      " 21  weibull_jd_30d_avg_3  14059 non-null  float64\n",
      "dtypes: float64(22)\n",
      "memory usage: 2.5 MB\n"
     ]
    }
   ],
   "source": [
    "df_lstm.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Pre-Processing\n",
    "\n",
    "The following pre-processing, model building, and model training steps were inspired by the approaches taken by Ahmad Anis in their article \"How to apply LSTM using PyTorch\", and Kaan Kuguoglu in their article \"Building RNN, LSTM, and GRU for time series using PyTorch\". \n",
    "\n",
    "Ahmad Anis: https://cnvrg.io/pytorch-lstm/\n",
    "\n",
    "Kaan Kuguoglu: https://towardsdatascience.com/building-rnn-lstm-and-gru-for-time-series-using-pytorch-a46e5b094e7b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split data into feature variables and target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14059, 21)\n",
      "(14059,)\n"
     ]
    }
   ],
   "source": [
    "x_lstm = df_lstm.iloc[:, :-1]\n",
    "y_lstm = df_lstm.iloc[:, -1]\n",
    "\n",
    "print(x_lstm.shape)\n",
    "print(y_lstm.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "stand_scaler = StandardScaler()\n",
    "x_scaled = stand_scaler.fit_transform(x_lstm)\n",
    "\n",
    "min_max = MinMaxScaler()\n",
    "y = y_lstm.to_numpy().reshape(-1, 1)  # MinMaxScaler expects 2D argument\n",
    "y_scaled = min_max.fit_transform(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split data into training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train_init shape = (11247, 21)\n",
      "y_train_init shape = (11247, 1)\n",
      "x_test_init shape = (2812, 21)\n",
      "y_test_init shape = (2812, 1)\n"
     ]
    }
   ],
   "source": [
    "train_ind = int(x_scaled.shape[0]*0.8)\n",
    "x_train_init = x_scaled[:train_ind]\n",
    "x_test_init = x_scaled[train_ind:]\n",
    "y_train_init = y_scaled[:train_ind]\n",
    "y_test_init = y_scaled[train_ind:]\n",
    "\n",
    "print(\"x_train_init shape = \" + str(x_train_init.shape))\n",
    "print(\"y_train_init shape = \" + str(y_train_init.shape))\n",
    "print(\"x_test_init shape = \" + str(x_test_init.shape))\n",
    "print(\"y_test_init shape = \" + str(y_test_init.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert numpy arrays to tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape = torch.Size([11247, 21])\n",
      "y_train shape = torch.Size([11247, 1])\n",
      "x_test shape = torch.Size([2812, 21])\n",
      "y_test shape = torch.Size([2812, 1])\n"
     ]
    }
   ],
   "source": [
    "x_train = Variable(torch.Tensor(x_train_init))\n",
    "x_test = Variable(torch.Tensor(x_test_init))\n",
    "\n",
    "y_train = Variable(torch.Tensor(y_train_init))\n",
    "y_test = Variable(torch.Tensor(y_test_init))\n",
    "\n",
    "print(\"x_train shape = \" + str(x_train.shape))\n",
    "print(\"y_train shape = \" + str(y_train.shape))\n",
    "print(\"x_test shape = \" + str(x_test.shape))\n",
    "print(\"y_test shape = \" + str(y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reshape tensors because LSTM cannot handle simple 2D data as input. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape = torch.Size([11247, 1, 21])\n",
      "y_train shape = torch.Size([11247, 1])\n",
      "x_test shape = torch.Size([2812, 1, 21])\n",
      "y_test shape = torch.Size([2812, 1])\n"
     ]
    }
   ],
   "source": [
    "x_train = torch.reshape(x_train, (x_train.shape[0], 1, x_train.shape[1]))\n",
    "x_test = torch.reshape(x_test, (x_test.shape[0], 1, x_test.shape[1]))\n",
    "\n",
    "print(\"x_train shape = \" + str(x_train.shape))\n",
    "print(\"y_train shape = \" + str(y_train.shape))\n",
    "print(\"x_test shape = \" + str(x_test.shape))\n",
    "print(\"y_test shape = \" + str(y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use torch tensor datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = TensorDataset(x_train, y_train)\n",
    "test_data = TensorDataset(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get data loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 124\n",
    "train_loader_lstm = DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
    "test_loader_lstm = DataLoader(test_data, shuffle=False, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN Drought Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_cnn = []\n",
    "for tile in tiles:\n",
    "    if dt.combine(tile.time.values[0], dt.min.time()) in in_drought:\n",
    "        y_cnn.append(1)\n",
    "    else:\n",
    "        y_cnn.append(0)\n",
    "y_cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_cnn = np.array(y_cnn).astype('long')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[[0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0]]]],\n",
       "\n",
       "\n",
       "\n",
       "       [[[[0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0]]]],\n",
       "\n",
       "\n",
       "\n",
       "       [[[[0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0]]]],\n",
       "\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "\n",
       "       [[[[0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0]]]],\n",
       "\n",
       "\n",
       "\n",
       "       [[[[0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0]]]],\n",
       "\n",
       "\n",
       "\n",
       "       [[[[0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0]]]]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_cnn = np.array(tiles).astype('long')\n",
    "X_cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[[0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0]]]],\n",
       "\n",
       "\n",
       "\n",
       "       [[[[0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0]]]],\n",
       "\n",
       "\n",
       "\n",
       "       [[[[0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0]]]],\n",
       "\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "\n",
       "       [[[[0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0]]]],\n",
       "\n",
       "\n",
       "\n",
       "       [[[[0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0]]]],\n",
       "\n",
       "\n",
       "\n",
       "       [[[[0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0]]]]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for image in range(0, len(X_cnn)):\n",
    "    X_cnn[image] = np.where(X_cnn[image] != 0, 1, X_cnn[image])\n",
    "X_cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(X_cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(124, 1, 1, 334, 334)\n",
      "(31, 1, 1, 334, 334)\n",
      "(124,)\n",
      "(31,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_cnn, y_cnn, test_size=0.2, random_state=1)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([124, 1, 1, 334, 334])\n",
      "torch.Size([31, 1, 1, 334, 334])\n",
      "torch.Size([124])\n",
      "torch.Size([31])\n"
     ]
    }
   ],
   "source": [
    "X_train = torch.from_numpy(X_train).type(torch.FloatTensor)\n",
    "X_test = torch.from_numpy(X_test).type(torch.FloatTensor)\n",
    "y_train = torch.from_numpy(y_train).type(torch.FloatTensor)\n",
    "y_test = torch.from_numpy(y_test).type(torch.FloatTensor)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([124, 1, 334, 334])\n",
      "torch.Size([31, 1, 334, 334])\n",
      "torch.Size([124])\n",
      "torch.Size([31])\n"
     ]
    }
   ],
   "source": [
    "X_train = torch.reshape(X_train, (X_train.shape[0], X_train.shape[1], X_train.shape[3], X_train.shape[4]))\n",
    "X_test = torch.reshape(X_test, (X_test.shape[0], X_test.shape[1], X_test.shape[3], X_test.shape[4]))\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = TensorDataset(X_train, y_train)\n",
    "test_data = TensorDataset(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "train_loader_cnn = DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
    "test_loader_cnn = DataLoader(test_data, shuffle=False, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StandardBlock(nn.Module):\n",
    "    def __init__(self, in_depth, out_depth, stride=1):\n",
    "        super(StandardBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels=in_depth, \n",
    "            out_channels=out_depth, \n",
    "            kernel_size=(3,3),\n",
    "            stride=stride,\n",
    "            padding=1\n",
    "        )\n",
    "        self.batch_norm = nn.BatchNorm2d(out_depth)\n",
    "        self.act_fn = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.batch_norm(x)\n",
    "        out = self.act_fn(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StandardNetClassifier(nn.Module):\n",
    "    def __init__(self, num_classes=2):\n",
    "        super(StandardNetClassifier, self).__init__()\n",
    "        self.standard1 = StandardBlock(in_depth=1, out_depth=32, stride=1)\n",
    "        self.standard2 = StandardBlock(in_depth=32, out_depth=64, stride=1)\n",
    "        self.standard3 = StandardBlock(in_depth=64, out_depth=64, stride=1)\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(output_size=(1,1))\n",
    "        self.linear = nn.Linear(in_features=64, out_features=2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.standard1(x)\n",
    "        print(x.shape)\n",
    "        x = self.standard2(x)\n",
    "        print(x.shape)\n",
    "        x = self.standard3(x)\n",
    "        print(x.shape)\n",
    "        x = self.avg_pool(x)\n",
    "        x = x.view([x.shape[0], 64])\n",
    "        out = self.linear(x)\n",
    "        print(x.shape)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StandardNetClassifier(\n",
      "  (standard1): StandardBlock(\n",
      "    (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (batch_norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (act_fn): ReLU()\n",
      "  )\n",
      "  (standard2): StandardBlock(\n",
      "    (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (batch_norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (act_fn): ReLU()\n",
      "  )\n",
      "  (standard3): StandardBlock(\n",
      "    (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (batch_norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (act_fn): ReLU()\n",
      "  )\n",
      "  (avg_pool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (linear): Linear(in_features=64, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = StandardNetClassifier()\n",
    "print(model)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[-0.1270,  0.0487]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 1 Minibatch:     1 loss: 0.785\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[-0.1101,  0.0279]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 1 Minibatch:     2 loss: 0.626\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[-0.1171,  0.0226]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 1 Minibatch:     3 loss: 0.765\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[-0.0911,  0.0099]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 1 Minibatch:     4 loss: 0.644\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[-0.1046,  0.0108]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 1 Minibatch:     5 loss: 0.637\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[-0.1081,  0.0148]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 1 Minibatch:     6 loss: 0.756\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[-0.1123,  0.0217]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 1 Minibatch:     7 loss: 0.762\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[-0.1106,  0.0141]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 1 Minibatch:     8 loss: 0.633\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[-0.1368,  0.0201]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 1 Minibatch:     9 loss: 0.618\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[-0.1192,  0.0172]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 1 Minibatch:    10 loss: 0.764\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[-0.1101,  0.0192]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 1 Minibatch:    11 loss: 0.760\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[-0.1129,  0.0104]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 1 Minibatch:    12 loss: 0.757\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[-0.0970,  0.0040]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 1 Minibatch:    13 loss: 0.644\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[-0.0954,  0.0029]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 1 Minibatch:    14 loss: 0.743\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[-0.0984, -0.0028]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 1 Minibatch:    15 loss: 0.742\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[-0.0841, -0.0091]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 1 Minibatch:    16 loss: 0.731\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[-0.0797, -0.0181]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 1 Minibatch:    17 loss: 0.724\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[-0.0708, -0.0154]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 1 Minibatch:    18 loss: 0.721\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[-0.0650, -0.0284]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 1 Minibatch:    19 loss: 0.712\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[-0.0458, -0.0314]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 1 Minibatch:    20 loss: 0.700\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[-0.0378, -0.0328]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 1 Minibatch:    21 loss: 0.696\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[-0.0408, -0.0558]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 1 Minibatch:    22 loss: 0.686\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[-0.0263, -0.0652]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 1 Minibatch:    23 loss: 0.674\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[-0.0193, -0.0705]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 1 Minibatch:    24 loss: 0.668\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[-0.0209, -0.0632]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 1 Minibatch:    25 loss: 0.672\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[-0.0031, -0.0779]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 1 Minibatch:    26 loss: 0.731\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[-0.0087, -0.0693]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 1 Minibatch:    27 loss: 0.663\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[-0.0078, -0.0750]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 1 Minibatch:    28 loss: 0.660\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[-0.0044, -0.0743]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 1 Minibatch:    29 loss: 0.659\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[-0.0017, -0.0910]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 1 Minibatch:    30 loss: 0.649\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.0198, -0.0915]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 1 Minibatch:    31 loss: 0.639\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.0264, -0.0791]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 1 Minibatch:    32 loss: 0.642\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.0242, -0.0996]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 1 Minibatch:    33 loss: 0.633\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.0493, -0.1097]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 1 Minibatch:    34 loss: 0.617\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.0319, -0.1050]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 1 Minibatch:    35 loss: 0.627\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.0507, -0.1253]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 1 Minibatch:    36 loss: 0.785\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.0597, -0.1330]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 1 Minibatch:    37 loss: 0.601\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.0595, -0.1353]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 1 Minibatch:    38 loss: 0.795\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.0551, -0.1249]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 1 Minibatch:    39 loss: 0.607\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.0598, -0.1237]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 1 Minibatch:    40 loss: 0.606\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.0619, -0.1270]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Minibatch:    41 loss: 0.603\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.0705, -0.1352]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 1 Minibatch:    42 loss: 0.596\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.0681, -0.1435]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 1 Minibatch:    43 loss: 0.593\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.0675, -0.1465]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 1 Minibatch:    44 loss: 0.592\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.0722, -0.1449]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 1 Minibatch:    45 loss: 0.590\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.0631, -0.1305]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 1 Minibatch:    46 loss: 0.601\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.0865, -0.1546]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 1 Minibatch:    47 loss: 0.580\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.1000, -0.1539]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 1 Minibatch:    48 loss: 0.574\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.0831, -0.1505]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 1 Minibatch:    49 loss: 0.583\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.0969, -0.1630]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 1 Minibatch:    50 loss: 0.832\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.0880, -0.1577]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 1 Minibatch:    51 loss: 0.578\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.0844, -0.1700]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 1 Minibatch:    52 loss: 0.828\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.0685, -0.1431]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 1 Minibatch:    53 loss: 0.593\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.0719, -0.1455]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 1 Minibatch:    54 loss: 0.808\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.0726, -0.1437]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 1 Minibatch:    55 loss: 0.807\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.0654, -0.1413]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 1 Minibatch:    56 loss: 0.802\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.0438, -0.1334]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 1 Minibatch:    57 loss: 0.608\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.0447, -0.1314]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 1 Minibatch:    58 loss: 0.609\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.0339, -0.1345]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 1 Minibatch:    59 loss: 0.613\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.0408, -0.1211]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 1 Minibatch:    60 loss: 0.777\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.0166, -0.0980]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 1 Minibatch:    61 loss: 0.752\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.0250, -0.0920]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 1 Minibatch:    62 loss: 0.636\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.0218, -0.1009]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 1 Minibatch:    63 loss: 0.634\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.0144, -0.0847]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 1 Minibatch:    64 loss: 0.645\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.0266, -0.1118]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 1 Minibatch:    65 loss: 0.626\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.0270, -0.1120]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 1 Minibatch:    66 loss: 0.626\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.0240, -0.0992]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 1 Minibatch:    67 loss: 0.633\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.0398, -0.1092]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 1 Minibatch:    68 loss: 0.621\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.0509, -0.1363]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 1 Minibatch:    69 loss: 0.604\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.0616, -0.1409]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 1 Minibatch:    70 loss: 0.597\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.0632, -0.1435]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 1 Minibatch:    71 loss: 0.595\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.0707, -0.1474]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 1 Minibatch:    72 loss: 0.808\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.0766, -0.1569]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 1 Minibatch:    73 loss: 0.583\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.0781, -0.1716]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 1 Minibatch:    74 loss: 0.576\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.0875, -0.1655]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 1 Minibatch:    75 loss: 0.575\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.0919, -0.1785]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 1 Minibatch:    76 loss: 0.567\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.1006, -0.1712]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 1 Minibatch:    77 loss: 0.566\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.1107, -0.1835]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 1 Minibatch:    78 loss: 0.557\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.1114, -0.1821]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 1 Minibatch:    79 loss: 0.557\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.1247, -0.2000]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 1 Minibatch:    80 loss: 0.544\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.1106, -0.1740]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 1 Minibatch:    81 loss: 0.561\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.1082, -0.1798]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 1 Minibatch:    82 loss: 0.559\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.1068, -0.1728]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 1 Minibatch:    83 loss: 0.563\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.1194, -0.1906]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 1 Minibatch:    84 loss: 0.860\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.1316, -0.2135]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 1 Minibatch:    85 loss: 0.535\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.1149, -0.2008]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 1 Minibatch:    86 loss: 0.548\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.1124, -0.2014]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 1 Minibatch:    87 loss: 0.862\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.1055, -0.1895]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 1 Minibatch:    88 loss: 0.556\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.1233, -0.2157]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 1 Minibatch:    89 loss: 0.538\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.1064, -0.2000]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 1 Minibatch:    90 loss: 0.552\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.1255, -0.2154]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 1 Minibatch:    91 loss: 0.537\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.1209, -0.2035]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 1 Minibatch:    92 loss: 0.544\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.1376, -0.2242]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 1 Minibatch:    93 loss: 0.890\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.1344, -0.2220]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 1 Minibatch:    94 loss: 0.531\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.1197, -0.2100]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 1 Minibatch:    95 loss: 0.542\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.1414, -0.2213]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 1 Minibatch:    96 loss: 0.528\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.1450, -0.2237]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 1 Minibatch:    97 loss: 0.526\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.1475, -0.2368]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 1 Minibatch:    98 loss: 0.904\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.1468, -0.2261]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 1 Minibatch:    99 loss: 0.524\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.1510, -0.2334]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 1 Minibatch:   100 loss: 0.904\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.1379, -0.2353]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 1 Minibatch:   101 loss: 0.524\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.1493, -0.2464]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 1 Minibatch:   102 loss: 0.515\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.1417, -0.2351]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 1 Minibatch:   103 loss: 0.899\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.1206, -0.2019]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 1 Minibatch:   104 loss: 0.545\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.1274, -0.2073]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 1 Minibatch:   105 loss: 0.540\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.1392, -0.2406]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 1 Minibatch:   106 loss: 0.901\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.1423, -0.2418]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 1 Minibatch:   107 loss: 0.904\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.1329, -0.2360]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 1 Minibatch:   108 loss: 0.526\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.1386, -0.2391]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 1 Minibatch:   109 loss: 0.522\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.1306, -0.2395]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 1 Minibatch:   110 loss: 0.525\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.1372, -0.2372]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 1 Minibatch:   111 loss: 0.523\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.1375, -0.2366]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 1 Minibatch:   112 loss: 0.898\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.1405, -0.2280]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 1 Minibatch:   113 loss: 0.526\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.1318, -0.2118]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 1 Minibatch:   114 loss: 0.536\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.1305, -0.2209]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 1 Minibatch:   115 loss: 0.884\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.1456, -0.2457]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 1 Minibatch:   116 loss: 0.517\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.1344, -0.2375]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 1 Minibatch:   117 loss: 0.524\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.1246, -0.2104]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 1 Minibatch:   118 loss: 0.875\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.1206, -0.2069]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 1 Minibatch:   119 loss: 0.870\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.1422, -0.2344]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 1 Minibatch:   120 loss: 0.899\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.1346, -0.2154]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 1 Minibatch:   121 loss: 0.533\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.1468, -0.2412]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Minibatch:   122 loss: 0.518\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.1419, -0.2338]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 1 Minibatch:   123 loss: 0.523\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.1436, -0.2303]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 1 Minibatch:   124 loss: 0.524\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.1383, -0.2304]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 2 Minibatch:     1 loss: 0.526\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.1583, -0.2482]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 2 Minibatch:     2 loss: 0.510\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.1241, -0.2072]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 2 Minibatch:     3 loss: 0.872\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.1616, -0.2543]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 2 Minibatch:     4 loss: 0.507\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.1407, -0.2266]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 2 Minibatch:     5 loss: 0.526\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.1456, -0.2255]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 2 Minibatch:     6 loss: 0.525\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.1543, -0.2360]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 2 Minibatch:     7 loss: 0.517\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.1641, -0.2496]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 2 Minibatch:     8 loss: 0.508\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.1662, -0.2453]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 2 Minibatch:     9 loss: 0.508\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.1645, -0.2452]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 2 Minibatch:    10 loss: 0.509\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.1737, -0.2525]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 2 Minibatch:    11 loss: 0.503\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.1678, -0.2443]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 2 Minibatch:    12 loss: 0.920\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.1790, -0.2632]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 2 Minibatch:    13 loss: 0.496\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.1493, -0.2217]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 2 Minibatch:    14 loss: 0.525\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.1708, -0.2557]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 2 Minibatch:    15 loss: 0.502\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.1708, -0.2594]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 2 Minibatch:    16 loss: 0.931\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.1671, -0.2717]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 2 Minibatch:    17 loss: 0.498\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.1481, -0.2260]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 2 Minibatch:    18 loss: 0.524\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.1673, -0.2739]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 2 Minibatch:    19 loss: 0.497\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.1706, -0.2799]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 2 Minibatch:    20 loss: 0.493\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.1568, -0.2420]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 2 Minibatch:    21 loss: 0.514\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.1726, -0.2523]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 2 Minibatch:    22 loss: 0.928\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.1857, -0.2784]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 2 Minibatch:    23 loss: 0.488\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.1767, -0.2538]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 2 Minibatch:    24 loss: 0.501\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.1842, -0.2648]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 2 Minibatch:    25 loss: 0.494\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.1748, -0.2719]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 2 Minibatch:    26 loss: 0.495\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.1801, -0.2510]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 2 Minibatch:    27 loss: 0.501\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.1911, -0.2833]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 2 Minibatch:    28 loss: 0.484\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.1966, -0.2864]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 2 Minibatch:    29 loss: 0.481\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.1789, -0.2584]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 2 Minibatch:    30 loss: 0.498\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.2009, -0.2803]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 2 Minibatch:    31 loss: 0.481\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.2081, -0.2979]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 2 Minibatch:    32 loss: 0.472\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.2100, -0.2927]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 2 Minibatch:    33 loss: 0.473\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.1762, -0.2517]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 2 Minibatch:    34 loss: 0.502\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.2006, -0.2840]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 2 Minibatch:    35 loss: 0.964\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.1996, -0.2808]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 2 Minibatch:    36 loss: 0.482\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.1990, -0.2855]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 2 Minibatch:    37 loss: 0.480\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.1893, -0.2706]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 2 Minibatch:    38 loss: 0.489\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.1991, -0.2766]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 2 Minibatch:    39 loss: 0.483\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.2129, -0.3003]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 2 Minibatch:    40 loss: 0.982\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.2081, -0.2928]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 2 Minibatch:    41 loss: 0.474\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.1866, -0.2628]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 2 Minibatch:    42 loss: 0.493\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.2004, -0.2889]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 2 Minibatch:    43 loss: 0.478\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.2096, -0.2943]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 2 Minibatch:    44 loss: 0.976\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.2053, -0.2970]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 2 Minibatch:    45 loss: 0.473\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.2008, -0.2836]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 2 Minibatch:    46 loss: 0.964\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.1992, -0.2915]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 2 Minibatch:    47 loss: 0.478\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.1928, -0.2834]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 2 Minibatch:    48 loss: 0.483\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.2007, -0.2955]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 2 Minibatch:    49 loss: 0.476\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.2014, -0.2957]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 2 Minibatch:    50 loss: 0.972\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.1970, -0.2912]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 2 Minibatch:    51 loss: 0.479\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.2000, -0.2921]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 2 Minibatch:    52 loss: 0.477\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.2012, -0.2979]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 2 Minibatch:    53 loss: 0.974\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.2006, -0.2928]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 2 Minibatch:    54 loss: 0.477\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.1934, -0.2881]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 2 Minibatch:    55 loss: 0.481\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.1926, -0.2836]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 2 Minibatch:    56 loss: 0.483\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.2049, -0.2916]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 2 Minibatch:    57 loss: 0.475\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.2113, -0.2963]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 2 Minibatch:    58 loss: 0.471\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.1923, -0.2698]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 2 Minibatch:    59 loss: 0.489\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.2275, -0.3140]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 2 Minibatch:    60 loss: 1.000\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.2274, -0.3190]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 2 Minibatch:    61 loss: 1.003\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.2166, -0.3077]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 2 Minibatch:    62 loss: 0.989\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.2101, -0.3046]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 2 Minibatch:    63 loss: 0.469\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.1736, -0.2590]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 2 Minibatch:    64 loss: 0.933\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.1984, -0.3011]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 2 Minibatch:    65 loss: 0.474\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.1823, -0.2795]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 2 Minibatch:    66 loss: 0.489\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.1900, -0.2969]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 2 Minibatch:    67 loss: 0.479\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.1845, -0.2852]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 2 Minibatch:    68 loss: 0.486\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.1884, -0.2930]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 2 Minibatch:    69 loss: 0.481\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.1828, -0.2785]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 2 Minibatch:    70 loss: 0.489\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.1927, -0.2931]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 2 Minibatch:    71 loss: 0.965\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.1903, -0.2889]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 2 Minibatch:    72 loss: 0.961\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.1914, -0.2917]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 2 Minibatch:    73 loss: 0.480\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.1836, -0.2846]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 2 Minibatch:    74 loss: 0.486\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.1750, -0.2669]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 2 Minibatch:    75 loss: 0.496\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.1878, -0.2835]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 2 Minibatch:    76 loss: 0.485\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.2099, -0.3218]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 2 Minibatch:    77 loss: 0.462\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.1855, -0.2771]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 2 Minibatch:    78 loss: 0.488\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.1945, -0.2861]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 Minibatch:    79 loss: 0.962\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.2047, -0.3009]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 2 Minibatch:    80 loss: 0.978\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.2057, -0.2955]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 2 Minibatch:    81 loss: 0.975\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.1844, -0.2747]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 2 Minibatch:    82 loss: 0.949\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.2062, -0.3120]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 2 Minibatch:    83 loss: 0.467\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.1931, -0.2903]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 2 Minibatch:    84 loss: 0.964\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.1880, -0.2870]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 2 Minibatch:    85 loss: 0.484\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.1840, -0.2802]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 2 Minibatch:    86 loss: 0.488\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.1599, -0.2439]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 2 Minibatch:    87 loss: 0.915\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.1668, -0.2617]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 2 Minibatch:    88 loss: 0.502\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.1700, -0.2683]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 2 Minibatch:    89 loss: 0.936\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.1489, -0.2341]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 2 Minibatch:    90 loss: 0.520\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.1184, -0.2099]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 2 Minibatch:    91 loss: 0.871\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.1698, -0.2777]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 2 Minibatch:    92 loss: 0.942\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.1427, -0.2413]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 2 Minibatch:    93 loss: 0.519\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.1404, -0.2379]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 2 Minibatch:    94 loss: 0.900\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.1571, -0.2939]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 2 Minibatch:    95 loss: 0.944\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.1313, -0.2469]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 2 Minibatch:    96 loss: 0.522\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.1235, -0.2330]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 2 Minibatch:    97 loss: 0.531\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.1121, -0.2146]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 2 Minibatch:    98 loss: 0.543\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.1270, -0.2413]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 2 Minibatch:    99 loss: 0.526\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.1142, -0.2262]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 2 Minibatch:   100 loss: 0.537\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.0954, -0.1923]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 2 Minibatch:   101 loss: 0.560\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.0963, -0.1878]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 2 Minibatch:   102 loss: 0.561\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.1402, -0.2557]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 2 Minibatch:   103 loss: 0.515\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.1347, -0.2496]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 2 Minibatch:   104 loss: 0.519\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.1331, -0.2326]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 2 Minibatch:   105 loss: 0.893\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.1585, -0.2673]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 2 Minibatch:   106 loss: 0.503\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.1345, -0.2308]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 2 Minibatch:   107 loss: 0.527\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.1241, -0.2109]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 2 Minibatch:   108 loss: 0.540\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.1737, -0.2782]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 2 Minibatch:   109 loss: 0.493\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.1595, -0.2492]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 2 Minibatch:   110 loss: 0.510\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.1672, -0.2576]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 2 Minibatch:   111 loss: 0.503\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.1552, -0.2325]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 2 Minibatch:   112 loss: 0.518\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.1737, -0.2527]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 2 Minibatch:   113 loss: 0.502\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.2158, -0.3263]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 2 Minibatch:   114 loss: 0.458\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.2090, -0.2990]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 2 Minibatch:   115 loss: 0.471\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.2143, -0.3102]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 2 Minibatch:   116 loss: 0.989\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.2135, -0.3097]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 2 Minibatch:   117 loss: 0.989\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.2071, -0.3052]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 2 Minibatch:   118 loss: 0.469\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.2049, -0.3020]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 2 Minibatch:   119 loss: 0.471\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.1970, -0.2944]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 2 Minibatch:   120 loss: 0.477\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.2130, -0.3159]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 2 Minibatch:   121 loss: 0.463\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.2037, -0.3040]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 2 Minibatch:   122 loss: 0.471\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.1939, -0.2821]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 2 Minibatch:   123 loss: 0.483\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.2047, -0.2921]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 2 Minibatch:   124 loss: 0.475\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.2035, -0.2838]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 3 Minibatch:     1 loss: 0.479\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.2312, -0.3181]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 3 Minibatch:     2 loss: 0.456\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.2258, -0.3222]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 3 Minibatch:     3 loss: 0.456\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.2334, -0.3171]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 3 Minibatch:     4 loss: 0.455\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.2411, -0.3348]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 3 Minibatch:     5 loss: 0.446\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.2343, -0.3290]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 3 Minibatch:     6 loss: 1.014\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.2271, -0.3223]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 3 Minibatch:     7 loss: 0.456\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.2384, -0.3414]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 3 Minibatch:     8 loss: 0.445\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.2417, -0.3460]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 3 Minibatch:     9 loss: 0.442\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.2363, -0.3371]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 3 Minibatch:    10 loss: 0.447\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.2471, -0.3486]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 3 Minibatch:    11 loss: 0.439\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.2334, -0.3267]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 3 Minibatch:    12 loss: 0.452\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.2507, -0.3478]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 3 Minibatch:    13 loss: 0.438\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.2544, -0.3477]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 3 Minibatch:    14 loss: 1.039\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.2279, -0.3100]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 3 Minibatch:    15 loss: 0.460\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.2596, -0.3482]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 3 Minibatch:    16 loss: 1.043\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.2596, -0.3459]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 3 Minibatch:    17 loss: 0.436\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.2464, -0.3235]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 3 Minibatch:    18 loss: 0.448\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.2117, -0.2800]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 3 Minibatch:    19 loss: 0.477\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.2707, -0.3650]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 3 Minibatch:    20 loss: 0.425\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.2688, -0.3557]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 3 Minibatch:    21 loss: 1.053\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.2599, -0.3442]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 3 Minibatch:    22 loss: 0.436\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.2553, -0.3318]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 3 Minibatch:    23 loss: 1.029\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.2468, -0.3226]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 3 Minibatch:    24 loss: 1.018\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.2565, -0.3356]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 3 Minibatch:    25 loss: 0.440\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.2531, -0.3372]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 3 Minibatch:    26 loss: 1.031\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.2406, -0.3227]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 3 Minibatch:    27 loss: 1.014\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.2530, -0.3411]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 3 Minibatch:    28 loss: 0.440\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.2024, -0.2642]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 3 Minibatch:    29 loss: 0.487\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.2354, -0.3150]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 3 Minibatch:    30 loss: 0.455\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.2464, -0.3407]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 3 Minibatch:    31 loss: 0.442\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.2475, -0.3347]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 3 Minibatch:    32 loss: 0.444\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.2281, -0.2983]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 3 Minibatch:    33 loss: 0.991\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.2256, -0.2973]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 3 Minibatch:    34 loss: 0.465\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.2389, -0.3173]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 3 Minibatch:    35 loss: 1.009\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.2136, -0.2790]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 Minibatch:    36 loss: 0.969\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.2073, -0.2736]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 3 Minibatch:    37 loss: 0.481\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.2219, -0.2955]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 3 Minibatch:    38 loss: 0.468\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.2165, -0.2874]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 3 Minibatch:    39 loss: 0.473\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.2175, -0.2861]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 3 Minibatch:    40 loss: 0.473\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.1883, -0.2488]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 3 Minibatch:    41 loss: 0.498\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.2377, -0.3181]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 3 Minibatch:    42 loss: 0.453\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.2375, -0.3182]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 3 Minibatch:    43 loss: 0.453\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.2490, -0.3344]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 3 Minibatch:    44 loss: 0.443\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.2620, -0.3513]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 3 Minibatch:    45 loss: 0.433\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.2521, -0.3338]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 3 Minibatch:    46 loss: 1.028\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.2688, -0.3590]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 3 Minibatch:    47 loss: 0.428\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.2810, -0.3879]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 3 Minibatch:    48 loss: 0.414\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.2585, -0.3466]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 3 Minibatch:    49 loss: 0.436\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.2406, -0.3219]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 3 Minibatch:    50 loss: 0.451\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.2540, -0.3403]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 3 Minibatch:    51 loss: 1.034\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.2434, -0.3261]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 3 Minibatch:    52 loss: 0.448\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.2881, -0.4008]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 3 Minibatch:    53 loss: 1.096\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.2537, -0.3409]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 3 Minibatch:    54 loss: 0.439\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.2596, -0.3513]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 3 Minibatch:    55 loss: 0.434\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.2603, -0.3516]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 3 Minibatch:    56 loss: 1.045\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.2338, -0.3173]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 3 Minibatch:    57 loss: 1.006\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.2422, -0.3346]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 3 Minibatch:    58 loss: 0.446\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.2064, -0.2906]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 3 Minibatch:    59 loss: 0.475\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.2053, -0.2908]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 3 Minibatch:    60 loss: 0.476\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.2293, -0.3238]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 3 Minibatch:    61 loss: 0.454\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.2462, -0.3404]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 3 Minibatch:    62 loss: 0.442\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.2271, -0.3082]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 3 Minibatch:    63 loss: 0.461\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.2527, -0.3338]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 3 Minibatch:    64 loss: 0.442\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.2610, -0.3426]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 3 Minibatch:    65 loss: 1.040\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.2666, -0.3480]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 3 Minibatch:    66 loss: 0.432\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.2632, -0.3460]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 3 Minibatch:    67 loss: 0.434\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.2624, -0.3450]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 3 Minibatch:    68 loss: 0.435\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.2568, -0.3371]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 3 Minibatch:    69 loss: 0.440\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.2814, -0.3689]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 3 Minibatch:    70 loss: 0.420\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.2582, -0.3323]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 3 Minibatch:    71 loss: 0.441\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.2664, -0.3491]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 3 Minibatch:    72 loss: 0.432\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.2714, -0.3542]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 3 Minibatch:    73 loss: 0.428\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.2820, -0.3685]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 3 Minibatch:    74 loss: 0.420\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.2661, -0.3574]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 3 Minibatch:    75 loss: 0.429\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.2768, -0.3732]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 3 Minibatch:    76 loss: 0.420\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.2824, -0.3726]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 3 Minibatch:    77 loss: 0.418\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.2945, -0.3904]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 3 Minibatch:    78 loss: 0.408\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.2532, -0.3286]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 3 Minibatch:    79 loss: 0.444\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.2799, -0.3697]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 3 Minibatch:    80 loss: 0.420\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.2989, -0.3925]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 3 Minibatch:    81 loss: 1.097\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.2718, -0.3513]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 3 Minibatch:    82 loss: 1.052\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.2855, -0.3818]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 3 Minibatch:    83 loss: 0.414\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.2936, -0.3831]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 3 Minibatch:    84 loss: 0.411\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.2753, -0.3651]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 3 Minibatch:    85 loss: 0.423\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.2619, -0.3445]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 3 Minibatch:    86 loss: 0.435\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.2616, -0.3362]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 3 Minibatch:    87 loss: 0.438\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.3079, -0.3962]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 3 Minibatch:    88 loss: 1.106\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.2786, -0.3516]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 3 Minibatch:    89 loss: 0.427\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.3000, -0.3814]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 3 Minibatch:    90 loss: 0.409\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.3038, -0.3893]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 3 Minibatch:    91 loss: 0.405\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.2511, -0.3271]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 3 Minibatch:    92 loss: 1.024\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.2767, -0.3540]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 3 Minibatch:    93 loss: 0.427\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.3061, -0.3840]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 3 Minibatch:    94 loss: 0.406\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.2840, -0.3636]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 3 Minibatch:    95 loss: 0.421\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.3039, -0.3798]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 3 Minibatch:    96 loss: 0.409\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.3157, -0.3950]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 3 Minibatch:    97 loss: 0.400\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.3159, -0.3850]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 3 Minibatch:    98 loss: 0.403\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.3065, -0.3802]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 3 Minibatch:    99 loss: 0.408\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.3028, -0.3693]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 3 Minibatch:   100 loss: 0.413\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.2946, -0.3662]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 3 Minibatch:   101 loss: 0.416\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.3242, -0.4009]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 3 Minibatch:   102 loss: 0.395\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.2772, -0.3429]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 3 Minibatch:   103 loss: 0.430\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.2451, -0.3163]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 3 Minibatch:   104 loss: 1.013\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.3297, -0.4152]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 3 Minibatch:   105 loss: 1.133\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.2960, -0.3678]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 3 Minibatch:   106 loss: 0.415\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.3297, -0.4167]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 3 Minibatch:   107 loss: 0.388\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.3168, -0.3967]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 3 Minibatch:   108 loss: 1.112\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.2629, -0.3280]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 3 Minibatch:   109 loss: 0.441\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.3124, -0.3889]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 3 Minibatch:   110 loss: 1.104\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.3266, -0.4158]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 3 Minibatch:   111 loss: 0.389\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.3029, -0.3774]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 3 Minibatch:   112 loss: 1.090\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.3135, -0.3981]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 3 Minibatch:   113 loss: 0.399\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.2746, -0.3455]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 3 Minibatch:   114 loss: 0.430\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.3080, -0.3900]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 3 Minibatch:   115 loss: 0.404\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.2809, -0.3515]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 3 Minibatch:   116 loss: 1.059\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.2716, -0.3405]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 Minibatch:   117 loss: 0.433\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.3066, -0.3891]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 3 Minibatch:   118 loss: 1.100\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.2898, -0.3690]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 3 Minibatch:   119 loss: 1.076\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.2753, -0.3478]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 3 Minibatch:   120 loss: 0.429\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.2754, -0.3480]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 3 Minibatch:   121 loss: 0.429\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.2565, -0.3224]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 3 Minibatch:   122 loss: 0.445\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.2715, -0.3451]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 3 Minibatch:   123 loss: 0.432\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.2475, -0.3165]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 3 Minibatch:   124 loss: 1.014\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.2557, -0.3217]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 4 Minibatch:     1 loss: 0.446\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.2971, -0.3843]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 4 Minibatch:     2 loss: 0.409\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.2730, -0.3457]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 4 Minibatch:     3 loss: 0.431\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.2915, -0.3729]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 4 Minibatch:     4 loss: 0.415\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.2813, -0.3537]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 4 Minibatch:     5 loss: 0.425\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.2829, -0.3539]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 4 Minibatch:     6 loss: 0.425\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.2977, -0.3757]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 4 Minibatch:     7 loss: 1.085\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.3013, -0.3796]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 4 Minibatch:     8 loss: 0.410\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.2986, -0.3740]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 4 Minibatch:     9 loss: 0.412\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.2983, -0.3755]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 4 Minibatch:    10 loss: 1.086\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.3207, -0.3996]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 4 Minibatch:    11 loss: 0.397\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.2784, -0.3468]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 4 Minibatch:    12 loss: 0.429\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.2869, -0.3477]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 4 Minibatch:    13 loss: 0.425\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.3013, -0.3660]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 4 Minibatch:    14 loss: 0.414\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.2920, -0.3588]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 4 Minibatch:    15 loss: 0.420\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.3396, -0.4172]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 4 Minibatch:    16 loss: 0.385\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.3440, -0.4217]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 4 Minibatch:    17 loss: 0.382\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.3134, -0.3828]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 4 Minibatch:    18 loss: 0.404\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.3235, -0.3895]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 4 Minibatch:    19 loss: 0.399\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.3273, -0.4004]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 4 Minibatch:    20 loss: 0.394\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.3415, -0.4118]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 4 Minibatch:    21 loss: 0.386\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.3374, -0.4143]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 4 Minibatch:    22 loss: 0.386\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.3134, -0.3832]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 4 Minibatch:    23 loss: 0.404\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.3417, -0.4257]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 4 Minibatch:    24 loss: 0.381\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.3005, -0.3595]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 4 Minibatch:    25 loss: 0.417\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.2654, -0.3347]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 4 Minibatch:    26 loss: 1.038\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.3394, -0.4218]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 4 Minibatch:    27 loss: 0.383\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.3353, -0.3997]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 4 Minibatch:    28 loss: 0.392\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.3498, -0.4246]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 4 Minibatch:    29 loss: 0.379\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.3482, -0.4284]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 4 Minibatch:    30 loss: 0.378\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.3442, -0.4085]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 4 Minibatch:    31 loss: 0.386\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.3614, -0.4328]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 4 Minibatch:    32 loss: 0.373\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.3618, -0.4302]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 4 Minibatch:    33 loss: 0.374\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.3682, -0.4411]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 4 Minibatch:    34 loss: 0.368\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.3479, -0.4129]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 4 Minibatch:    35 loss: 1.144\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.3290, -0.3993]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 4 Minibatch:    36 loss: 1.122\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.3357, -0.4127]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 4 Minibatch:    37 loss: 1.136\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.3530, -0.4448]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 4 Minibatch:    38 loss: 0.372\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.3286, -0.4207]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 4 Minibatch:    39 loss: 0.387\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.3136, -0.4102]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 4 Minibatch:    40 loss: 1.119\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.3080, -0.4066]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 4 Minibatch:    41 loss: 0.398\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.2922, -0.3930]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 4 Minibatch:    42 loss: 0.408\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.3078, -0.4159]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 4 Minibatch:    43 loss: 1.119\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.3043, -0.4152]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 4 Minibatch:    44 loss: 1.116\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.2535, -0.3604]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 4 Minibatch:    45 loss: 0.433\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.2827, -0.3976]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 4 Minibatch:    46 loss: 1.090\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.2582, -0.3713]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 4 Minibatch:    47 loss: 0.427\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.2756, -0.4000]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 4 Minibatch:    48 loss: 1.087\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.2441, -0.3645]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 4 Minibatch:    49 loss: 1.043\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.2269, -0.3505]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 4 Minibatch:    50 loss: 0.446\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.2538, -0.3871]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 4 Minibatch:    51 loss: 0.423\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.2193, -0.3393]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 4 Minibatch:    52 loss: 0.452\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.2484, -0.3847]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 4 Minibatch:    53 loss: 0.426\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.2070, -0.3374]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 4 Minibatch:    54 loss: 0.458\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.2497, -0.3911]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 4 Minibatch:    55 loss: 0.423\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.2329, -0.3705]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 4 Minibatch:    56 loss: 1.040\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.2138, -0.3453]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 4 Minibatch:    57 loss: 0.452\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.1918, -0.3068]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 4 Minibatch:    58 loss: 0.475\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.2487, -0.3879]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 4 Minibatch:    59 loss: 1.061\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.2204, -0.3558]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 4 Minibatch:    60 loss: 1.022\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.2530, -0.3894]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 4 Minibatch:    61 loss: 0.423\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.2741, -0.4237]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 4 Minibatch:    62 loss: 0.404\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.2415, -0.3833]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 4 Minibatch:    63 loss: 0.429\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.1976, -0.3264]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 4 Minibatch:    64 loss: 0.465\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.1794, -0.2982]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 4 Minibatch:    65 loss: 0.483\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.1944, -0.3103]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 4 Minibatch:    66 loss: 0.472\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.2139, -0.3463]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 4 Minibatch:    67 loss: 0.452\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.2457, -0.3780]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 4 Minibatch:    68 loss: 1.053\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.2593, -0.3921]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 4 Minibatch:    69 loss: 0.420\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.2652, -0.4053]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 4 Minibatch:    70 loss: 1.084\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.2195, -0.3432]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 4 Minibatch:    71 loss: 0.451\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.2273, -0.3564]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 4 Minibatch:    72 loss: 0.443\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.2576, -0.3933]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 4 Minibatch:    73 loss: 0.420\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.2403, -0.3689]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4 Minibatch:    74 loss: 0.434\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.2557, -0.3783]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 4 Minibatch:    75 loss: 0.426\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.2208, -0.3347]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 4 Minibatch:    76 loss: 0.453\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.2835, -0.4091]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 4 Minibatch:    77 loss: 0.406\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.3279, -0.4746]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 4 Minibatch:    78 loss: 1.173\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.2460, -0.3534]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 4 Minibatch:    79 loss: 1.037\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.2831, -0.4089]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 4 Minibatch:    80 loss: 0.406\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.2828, -0.4046]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 4 Minibatch:    81 loss: 0.407\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.2557, -0.3723]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 4 Minibatch:    82 loss: 0.428\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.2918, -0.4149]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 4 Minibatch:    83 loss: 0.401\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.3010, -0.4236]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 4 Minibatch:    84 loss: 0.395\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.2918, -0.4133]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 4 Minibatch:    85 loss: 0.402\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.2792, -0.3848]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 4 Minibatch:    86 loss: 0.415\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.2805, -0.3843]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 4 Minibatch:    87 loss: 1.080\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.2902, -0.3954]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 4 Minibatch:    88 loss: 0.408\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.3202, -0.4367]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 4 Minibatch:    89 loss: 0.385\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.3105, -0.4156]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 4 Minibatch:    90 loss: 0.395\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.3308, -0.4419]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 4 Minibatch:    91 loss: 0.380\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.3413, -0.4496]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 4 Minibatch:    92 loss: 0.374\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.3133, -0.4066]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 4 Minibatch:    93 loss: 1.117\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.3343, -0.4322]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 4 Minibatch:    94 loss: 0.382\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.3456, -0.4466]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 4 Minibatch:    95 loss: 1.166\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.3349, -0.4339]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 4 Minibatch:    96 loss: 0.381\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.3547, -0.4582]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 4 Minibatch:    97 loss: 0.367\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.3043, -0.3872]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 4 Minibatch:    98 loss: 0.406\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.3343, -0.4255]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 4 Minibatch:    99 loss: 0.384\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.3429, -0.4333]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 4 Minibatch:   100 loss: 0.379\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.3023, -0.3765]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 4 Minibatch:   101 loss: 0.410\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.3487, -0.4364]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 4 Minibatch:   102 loss: 0.376\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.3570, -0.4415]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 4 Minibatch:   103 loss: 0.372\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.3629, -0.4463]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 4 Minibatch:   104 loss: 1.177\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.3690, -0.4528]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 4 Minibatch:   105 loss: 0.364\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.3169, -0.3868]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 4 Minibatch:   106 loss: 1.106\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.3123, -0.3780]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 4 Minibatch:   107 loss: 0.406\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.3738, -0.4557]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 4 Minibatch:   108 loss: 0.362\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.3703, -0.4486]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 4 Minibatch:   109 loss: 0.365\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.3504, -0.4233]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 4 Minibatch:   110 loss: 1.153\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.3190, -0.3872]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 4 Minibatch:   111 loss: 0.401\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.3339, -0.4031]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 4 Minibatch:   112 loss: 1.128\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.3547, -0.4300]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 4 Minibatch:   113 loss: 0.376\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.3766, -0.4602]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 4 Minibatch:   114 loss: 1.197\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 64])\n",
      "tensor([[ 0.3595, -0.4414]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 4 Minibatch:   115 loss: 1.172\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.3258, -0.4010]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 4 Minibatch:   116 loss: 0.394\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.3513, -0.4369]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 4 Minibatch:   117 loss: 1.163\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.3680, -0.4639]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 4 Minibatch:   118 loss: 0.361\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.3706, -0.4686]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 4 Minibatch:   119 loss: 0.359\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.3437, -0.4356]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 4 Minibatch:   120 loss: 1.157\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.3350, -0.4258]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 4 Minibatch:   121 loss: 0.383\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.3199, -0.4100]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 4 Minibatch:   122 loss: 0.393\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.3015, -0.3896]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 4 Minibatch:   123 loss: 0.406\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.3177, -0.4076]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 4 Minibatch:   124 loss: 0.395\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.3186, -0.4085]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 5 Minibatch:     1 loss: 0.394\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.3527, -0.4542]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 5 Minibatch:     2 loss: 0.369\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.2867, -0.3660]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 5 Minibatch:     3 loss: 0.419\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.3520, -0.4494]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 5 Minibatch:     4 loss: 0.371\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.3274, -0.4132]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 5 Minibatch:     5 loss: 0.390\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.3256, -0.4105]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 5 Minibatch:     6 loss: 1.127\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.3498, -0.4386]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 5 Minibatch:     7 loss: 0.375\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.3571, -0.4541]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 5 Minibatch:     8 loss: 0.368\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.3560, -0.4430]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 5 Minibatch:     9 loss: 0.371\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.3815, -0.4748]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 5 Minibatch:    10 loss: 0.354\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.3122, -0.3891]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 5 Minibatch:    11 loss: 1.104\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.3470, -0.4254]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 5 Minibatch:    12 loss: 0.380\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.3401, -0.4162]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 5 Minibatch:    13 loss: 1.141\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.3628, -0.4471]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 5 Minibatch:    14 loss: 1.178\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.3241, -0.3985]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 5 Minibatch:    15 loss: 0.396\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.3408, -0.4175]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 5 Minibatch:    16 loss: 0.384\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.3463, -0.4242]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 5 Minibatch:    17 loss: 0.380\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.3699, -0.4541]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 5 Minibatch:    18 loss: 0.364\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.3683, -0.4534]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 5 Minibatch:    19 loss: 0.364\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.3437, -0.4192]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 5 Minibatch:    20 loss: 0.383\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.3449, -0.4212]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 5 Minibatch:    21 loss: 1.148\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.3093, -0.3794]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 5 Minibatch:    22 loss: 0.407\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.3496, -0.4252]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 5 Minibatch:    23 loss: 1.154\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.3400, -0.4151]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 5 Minibatch:    24 loss: 0.385\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.3305, -0.4088]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 5 Minibatch:    25 loss: 0.390\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.3290, -0.3997]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 5 Minibatch:    26 loss: 0.394\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.3529, -0.4295]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 5 Minibatch:    27 loss: 0.377\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.3199, -0.3875]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 5 Minibatch:    28 loss: 0.401\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.3776, -0.4617]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 5 Minibatch:    29 loss: 1.198\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.3780, -0.4612]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 5 Minibatch:    30 loss: 0.359\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.3408, -0.4110]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Minibatch:    31 loss: 0.386\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.3812, -0.4717]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 5 Minibatch:    32 loss: 0.355\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.3634, -0.4395]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 5 Minibatch:    33 loss: 0.370\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.4012, -0.4883]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 5 Minibatch:    34 loss: 0.344\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.3680, -0.4472]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 5 Minibatch:    35 loss: 0.366\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.3824, -0.4607]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 5 Minibatch:    36 loss: 0.358\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.3360, -0.4061]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 5 Minibatch:    37 loss: 0.389\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.3822, -0.4560]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 5 Minibatch:    38 loss: 1.198\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.4219, -0.5132]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 5 Minibatch:    39 loss: 0.331\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.3791, -0.4523]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 5 Minibatch:    40 loss: 0.361\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.3254, -0.3921]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 5 Minibatch:    41 loss: 0.397\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.3807, -0.4586]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 5 Minibatch:    42 loss: 0.359\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.3723, -0.4457]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 5 Minibatch:    43 loss: 1.184\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.4327, -0.5301]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 5 Minibatch:    44 loss: 0.323\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.4046, -0.4876]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 5 Minibatch:    45 loss: 0.343\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.4161, -0.5039]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 5 Minibatch:    46 loss: 0.335\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.3989, -0.4801]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 5 Minibatch:    47 loss: 0.347\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.3836, -0.4595]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 5 Minibatch:    48 loss: 1.201\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.3476, -0.4198]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 5 Minibatch:    49 loss: 1.149\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.3995, -0.4816]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 5 Minibatch:    50 loss: 0.347\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.3618, -0.4378]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 5 Minibatch:    51 loss: 0.371\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.3895, -0.4698]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 5 Minibatch:    52 loss: 1.212\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.3832, -0.4637]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 5 Minibatch:    53 loss: 1.204\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.3944, -0.4791]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 5 Minibatch:    54 loss: 0.349\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.3704, -0.4495]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 5 Minibatch:    55 loss: 0.365\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.3731, -0.4523]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 5 Minibatch:    56 loss: 0.363\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.3120, -0.3800]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 5 Minibatch:    57 loss: 0.406\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.3354, -0.4058]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 5 Minibatch:    58 loss: 1.131\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.3703, -0.4499]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 5 Minibatch:    59 loss: 1.185\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.3835, -0.4688]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 5 Minibatch:    60 loss: 0.355\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.3689, -0.4515]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 5 Minibatch:    61 loss: 0.365\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.3729, -0.4549]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 5 Minibatch:    62 loss: 1.190\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.3697, -0.4550]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 5 Minibatch:    63 loss: 0.363\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.3704, -0.4505]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 5 Minibatch:    64 loss: 0.365\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.3608, -0.4421]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 5 Minibatch:    65 loss: 1.173\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.3232, -0.3920]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 5 Minibatch:    66 loss: 0.398\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.3621, -0.4432]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 5 Minibatch:    67 loss: 1.175\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.3622, -0.4446]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 5 Minibatch:    68 loss: 1.176\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.3529, -0.4295]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 5 Minibatch:    69 loss: 0.377\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.3448, -0.4203]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 5 Minibatch:    70 loss: 0.382\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.3430, -0.4200]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 5 Minibatch:    71 loss: 1.146\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 64])\n",
      "tensor([[ 0.3341, -0.4140]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 5 Minibatch:    72 loss: 0.387\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.2725, -0.3467]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 5 Minibatch:    73 loss: 1.050\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.3433, -0.4327]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 5 Minibatch:    74 loss: 0.379\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.3180, -0.3885]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 5 Minibatch:    75 loss: 0.401\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.3011, -0.3720]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 5 Minibatch:    76 loss: 0.412\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.2816, -0.3463]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 5 Minibatch:    77 loss: 0.428\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.3289, -0.4086]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 5 Minibatch:    78 loss: 1.128\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.2649, -0.3254]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 5 Minibatch:    79 loss: 0.441\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.3797, -0.4919]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 5 Minibatch:    80 loss: 1.221\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.3239, -0.4010]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 5 Minibatch:    81 loss: 0.395\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.3044, -0.3793]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 5 Minibatch:    82 loss: 0.409\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.3280, -0.4102]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 5 Minibatch:    83 loss: 0.391\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.2983, -0.3727]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 5 Minibatch:    84 loss: 0.413\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.3393, -0.4221]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 5 Minibatch:    85 loss: 0.383\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.3167, -0.3937]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 5 Minibatch:    86 loss: 0.400\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.3470, -0.4346]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 5 Minibatch:    87 loss: 1.158\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.3426, -0.4260]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 5 Minibatch:    88 loss: 1.149\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.3050, -0.3805]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 5 Minibatch:    89 loss: 0.408\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.3157, -0.3953]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 5 Minibatch:    90 loss: 0.400\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.3267, -0.4047]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 5 Minibatch:    91 loss: 0.393\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.2946, -0.3620]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 5 Minibatch:    92 loss: 0.418\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.3285, -0.4110]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 5 Minibatch:    93 loss: 1.130\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.3217, -0.3961]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 5 Minibatch:    94 loss: 0.397\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.3157, -0.3877]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 5 Minibatch:    95 loss: 1.105\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.3308, -0.4125]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 5 Minibatch:    96 loss: 0.389\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.2989, -0.3647]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 5 Minibatch:    97 loss: 0.415\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.3405, -0.4257]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 5 Minibatch:    98 loss: 0.382\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.3351, -0.4250]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 5 Minibatch:    99 loss: 0.384\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.3120, -0.3806]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 5 Minibatch:   100 loss: 0.406\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.3374, -0.4165]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 5 Minibatch:   101 loss: 0.386\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.3120, -0.3855]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 5 Minibatch:   102 loss: 0.404\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.3504, -0.4348]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 5 Minibatch:   103 loss: 0.376\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.3439, -0.4228]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 5 Minibatch:   104 loss: 0.382\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.3553, -0.4381]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 5 Minibatch:   105 loss: 0.373\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.3186, -0.3893]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 5 Minibatch:   106 loss: 0.401\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.3797, -0.4674]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 5 Minibatch:   107 loss: 0.357\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.3507, -0.4260]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 5 Minibatch:   108 loss: 0.378\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.3988, -0.4885]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 5 Minibatch:   109 loss: 0.345\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.3534, -0.4259]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 5 Minibatch:   110 loss: 0.378\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.3990, -0.4835]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 5 Minibatch:   111 loss: 0.346\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.3750, -0.4484]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Minibatch:   112 loss: 0.364\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.4087, -0.4904]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 5 Minibatch:   113 loss: 1.241\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.4035, -0.4823]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 5 Minibatch:   114 loss: 0.345\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.3742, -0.4497]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 5 Minibatch:   115 loss: 1.188\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.4145, -0.4998]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 5 Minibatch:   116 loss: 0.337\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.4076, -0.4928]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 5 Minibatch:   117 loss: 1.241\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.4078, -0.4957]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 5 Minibatch:   118 loss: 0.340\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.4128, -0.5064]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 5 Minibatch:   119 loss: 0.336\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.3795, -0.4737]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 5 Minibatch:   120 loss: 0.355\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.4031, -0.4963]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 5 Minibatch:   121 loss: 0.341\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.4035, -0.5062]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 5 Minibatch:   122 loss: 0.338\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.3824, -0.4664]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 5 Minibatch:   123 loss: 0.356\n",
      "torch.Size([1, 32, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64, 334, 334])\n",
      "torch.Size([1, 64])\n",
      "tensor([[ 0.3896, -0.4764]], grad_fn=<AddmmBackward0>)\n",
      "Epoch: 5 Minibatch:   124 loss: 0.351\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(5): \n",
    "    for i, data in enumerate(train_loader_cnn, 0):\n",
    "        model.train()\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        print(outputs)\n",
    "        loss = criterion(outputs, labels.type(torch.LongTensor))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "#         if i % 10 == 0:   \n",
    "        print('Epoch: %d Minibatch: %5d loss: %.3f' %(epoch + 1, i + 1, loss.item()))\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    epoch_test_losses = []\n",
    "    for i, data in enumerate(test_loader_cnn, 0):\n",
    "        model.eval()\n",
    "    \n",
    "        inputs, labels = data\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        loss = criterion(outputs, labels.type(torch.LongTensor))\n",
    "\n",
    "    if epoch % 10 == 0:   \n",
    "        print('Epoch: %d Minibatch: %5d loss: %.3f' %(epoch + 1, i + 1, loss.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, num_classes, input_size, hidden_size, fc_size, num_layers):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.num_layers = num_layers\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.fc_size = fc_size\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size,\n",
    "                          num_layers=num_layers, batch_first=True)\n",
    "        self.fc_1 =  nn.Linear(hidden_size, fc_size)\n",
    "        self.fc = nn.Linear(fc_size, num_classes)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        batch_size = x.shape[0]\n",
    "        \n",
    "        # Hidden state\n",
    "        h_0 = Variable(torch.zeros(self.num_layers, batch_size, self.hidden_size))\n",
    "        \n",
    "        # Internal state\n",
    "        c_0 = Variable(torch.zeros(self.num_layers, batch_size, self.hidden_size))\n",
    "        \n",
    "        # Propagate input through LSTM\n",
    "        output, (hn, cn) = self.lstm(x, (h_0, c_0))\n",
    "        hn = hn.view(-1, self.hidden_size)\n",
    "        out = self.relu(hn)\n",
    "        out = self.fc_1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the parameters, loss function, and optimizer used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 124\n",
    "epochs = 5\n",
    "learning_rate = 0.0001\n",
    "\n",
    "num_classes = 1\n",
    "input_size = x_train.shape[2]\n",
    "hidden_size = 64\n",
    "fc_size = 128\n",
    "num_layers = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = LSTM(num_classes, input_size, hidden_size, fc_size, num_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.L1Loss()  # Mean Absolute Error\n",
    "optimizer = torch.optim.Adam(lstm.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | Train Loss: 0.38160 | Test Loss: 0.35061\n",
      "Epoch: 9 | Train Loss: 0.06534 | Test Loss: 0.08318\n"
     ]
    }
   ],
   "source": [
    "train_losses = []\n",
    "test_losses = []\n",
    "\n",
    "train_rows = x_train.shape[0]\n",
    "for epoch in range(epochs):\n",
    "    epoch_train_losses = []\n",
    "    \n",
    "    lstm.train()\n",
    "    for x, y in train_loader_lstm:\n",
    "        # Forward pass\n",
    "        outputs = lstm(x) \n",
    "        \n",
    "        # Calculate the gradient\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Obtain the loss function\n",
    "        loss = criterion(outputs, y)\n",
    "        \n",
    "        # Calculates the loss of the loss function\n",
    "        loss.backward() \n",
    "        \n",
    "        # Improve from loss, i.e backprop\n",
    "        optimizer.step() \n",
    "        \n",
    "        item_loss = loss.item()\n",
    "        epoch_train_losses.append(item_loss)\n",
    "    train_loss = np.mean(epoch_train_losses)\n",
    "    train_losses.append(train_loss)\n",
    "        \n",
    "    with torch.no_grad():\n",
    "        epoch_test_losses = []\n",
    "        for x, y in test_loader_lstm:\n",
    "            lstm.eval()\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = lstm(x) \n",
    "            \n",
    "            item_loss = criterion(outputs, y).item()\n",
    "            epoch_test_losses.append(item_loss)\n",
    "        test_loss = np.mean(epoch_test_losses)\n",
    "        test_losses.append(test_loss)\n",
    "        \n",
    "        if epoch % 10 == 0 or epoch == (epochs-1):\n",
    "            print(\"Epoch: %d | Train Loss: %1.5f | Test Loss: %1.5f\" % (epoch, train_loss, test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(lstm.state_dict(), \"lstm_outputs.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyEnsemble(nn.Module):\n",
    "    def __init__(self, modelA, modelB):\n",
    "        super(MyEnsemble, self).__init__()\n",
    "        self.modelA = modelA\n",
    "        self.modelB = modelB\n",
    "        self.classifier = nn.Linear(3, 1)\n",
    "        \n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.modelA(x1)\n",
    "        print(x1.shape)\n",
    "        x2 = self.modelB(x2)\n",
    "        print(x2.shape)\n",
    "        x = torch.cat((x1, x2), dim=1)\n",
    "        print(x.shape)\n",
    "        x = self.classifier(F.relu(x))\n",
    "        print(x.shape)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for LSTM:\n\tsize mismatch for lstm.weight_ih_l0: copying a param with shape torch.Size([256, 20]) from checkpoint, the shape in current model is torch.Size([256, 21]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [175]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Load state dicts\u001b[39;00m\n\u001b[1;32m      2\u001b[0m model\u001b[38;5;241m.\u001b[39mload_state_dict(torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcnn_outputs.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m----> 3\u001b[0m \u001b[43mlstm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlstm_outputs.pt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1497\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m   1492\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[1;32m   1493\u001b[0m             \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   1494\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(k) \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)))\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 1497\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   1498\u001b[0m                        \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)))\n\u001b[1;32m   1499\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for LSTM:\n\tsize mismatch for lstm.weight_ih_l0: copying a param with shape torch.Size([256, 20]) from checkpoint, the shape in current model is torch.Size([256, 21])."
     ]
    }
   ],
   "source": [
    "# Load state dicts\n",
    "model.load_state_dict(torch.load(\"cnn_outputs.pt\"))\n",
    "lstm.load_state_dict(torch.load(\"lstm_outputs.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "forward() got an unexpected keyword argument 'require_grad'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [72]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m ensb \u001b[38;5;241m=\u001b[39m \u001b[43mMyEnsemble\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlstm\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m x1, x2 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;241m124\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m334\u001b[39m, \u001b[38;5;241m334\u001b[39m), torch\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;241m124\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m20\u001b[39m)\n\u001b[1;32m      3\u001b[0m output \u001b[38;5;241m=\u001b[39m ensb(x1, x2)\n",
      "Input \u001b[0;32mIn [70]\u001b[0m, in \u001b[0;36mMyEnsemble.__init__\u001b[0;34m(self, modelA, modelB)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, modelA, modelB):\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28msuper\u001b[39m(MyEnsemble, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n\u001b[0;32m----> 4\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodelA \u001b[38;5;241m=\u001b[39m \u001b[43mmodelA\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequire_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodelB \u001b[38;5;241m=\u001b[39m modelB(require_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclassifier \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mLinear(\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "\u001b[0;31mTypeError\u001b[0m: forward() got an unexpected keyword argument 'require_grad'"
     ]
    }
   ],
   "source": [
    "ensb = MyEnsemble(model, lstm)\n",
    "x1, x2 = torch.randn(124, 1, 334, 334), torch.randn(124, 1, 20)\n",
    "output = ensb(x1, x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.5420],\n",
       "        [1.3453],\n",
       "        [1.3985],\n",
       "        [1.3935],\n",
       "        [1.3946],\n",
       "        [1.3846],\n",
       "        [1.4154],\n",
       "        [1.4249],\n",
       "        [1.4022],\n",
       "        [1.4619],\n",
       "        [1.5288],\n",
       "        [1.3898],\n",
       "        [1.3643],\n",
       "        [1.4763],\n",
       "        [1.4582],\n",
       "        [1.5330],\n",
       "        [1.5707],\n",
       "        [1.3217],\n",
       "        [1.3472],\n",
       "        [1.3450],\n",
       "        [1.4342],\n",
       "        [1.4115],\n",
       "        [1.4730],\n",
       "        [1.5661],\n",
       "        [1.4123],\n",
       "        [1.4024],\n",
       "        [1.4759],\n",
       "        [1.5245],\n",
       "        [1.5144],\n",
       "        [1.3927],\n",
       "        [1.3266],\n",
       "        [1.4249],\n",
       "        [1.6510],\n",
       "        [1.4509],\n",
       "        [1.3561],\n",
       "        [1.4627],\n",
       "        [1.3715],\n",
       "        [1.4092],\n",
       "        [1.3128],\n",
       "        [1.3302],\n",
       "        [1.4423],\n",
       "        [1.4176],\n",
       "        [1.4637],\n",
       "        [1.3689],\n",
       "        [1.5164],\n",
       "        [1.5020],\n",
       "        [1.3862],\n",
       "        [1.4880],\n",
       "        [1.3816],\n",
       "        [1.3655],\n",
       "        [1.3781],\n",
       "        [1.3017],\n",
       "        [1.4382],\n",
       "        [1.4604],\n",
       "        [1.4467],\n",
       "        [1.4084],\n",
       "        [1.3783],\n",
       "        [1.4047],\n",
       "        [1.3842],\n",
       "        [1.3682],\n",
       "        [1.4587],\n",
       "        [1.5508],\n",
       "        [1.4362],\n",
       "        [1.4676],\n",
       "        [1.4785],\n",
       "        [1.4441],\n",
       "        [1.5424],\n",
       "        [1.3045],\n",
       "        [1.4438],\n",
       "        [1.3334],\n",
       "        [1.3445],\n",
       "        [1.3934],\n",
       "        [1.4193],\n",
       "        [1.4140],\n",
       "        [1.4478],\n",
       "        [1.3890],\n",
       "        [1.4304],\n",
       "        [1.3284],\n",
       "        [1.3671],\n",
       "        [1.4324],\n",
       "        [1.5104],\n",
       "        [1.3581],\n",
       "        [1.4091],\n",
       "        [1.3020],\n",
       "        [1.3303],\n",
       "        [1.4077],\n",
       "        [1.3057],\n",
       "        [1.3607],\n",
       "        [1.3868],\n",
       "        [1.3366],\n",
       "        [1.4190],\n",
       "        [1.4420],\n",
       "        [1.5004],\n",
       "        [1.3574],\n",
       "        [1.4061],\n",
       "        [1.3832],\n",
       "        [1.3387],\n",
       "        [1.4226],\n",
       "        [1.3891],\n",
       "        [1.3947],\n",
       "        [1.4425],\n",
       "        [1.5655],\n",
       "        [1.5085],\n",
       "        [1.4948],\n",
       "        [1.3865],\n",
       "        [1.5232],\n",
       "        [1.3818],\n",
       "        [1.5407],\n",
       "        [1.4163],\n",
       "        [1.3767],\n",
       "        [1.4057],\n",
       "        [1.3407],\n",
       "        [1.4999],\n",
       "        [1.4664],\n",
       "        [1.4402],\n",
       "        [1.4216],\n",
       "        [1.3303],\n",
       "        [1.4876],\n",
       "        [1.4281],\n",
       "        [1.3984],\n",
       "        [1.5092],\n",
       "        [1.4466],\n",
       "        [1.4281],\n",
       "        [1.5045]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "one of the variables needed for gradient computation has been modified by an inplace operation: [torch.FloatTensor [128, 1]], which is output 0 of AsStridedBackward0, is at version 5462; expected version 2732 instead. Hint: enable anomaly detection to find the operation that failed to compute its gradient, with torch.autograd.set_detect_anomaly(True).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [69]\u001b[0m, in \u001b[0;36m<cell line: 20>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(output, y)\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Calculates the loss of the loss function\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Improve from loss, i.e backprop\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# optimizer.step() \u001b[39;00m\n\u001b[1;32m     25\u001b[0m item_loss \u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/_tensor.py:363\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    355\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    356\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    357\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    361\u001b[0m         create_graph\u001b[38;5;241m=\u001b[39mcreate_graph,\n\u001b[1;32m    362\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs)\n\u001b[0;32m--> 363\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/autograd/__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    168\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    170\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 173\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: one of the variables needed for gradient computation has been modified by an inplace operation: [torch.FloatTensor [128, 1]], which is output 0 of AsStridedBackward0, is at version 5462; expected version 2732 instead. Hint: enable anomaly detection to find the operation that failed to compute its gradient, with torch.autograd.set_detect_anomaly(True)."
     ]
    }
   ],
   "source": [
    "train_losses = []\n",
    "test_losses = []\n",
    "\n",
    "train_rows = x_train.shape[0]\n",
    "epoch_train_losses = []\n",
    "\n",
    "y = list(train_loader_lstm)[1][1]\n",
    "\n",
    "ensb.train()\n",
    "# Forward pass\n",
    "# outputs = ensb(x1, x2)\n",
    "\n",
    "# Calculate the gradient\n",
    "optimizer.zero_grad()\n",
    "\n",
    "# Obtain the loss function\n",
    "loss = criterion(output, y)\n",
    "\n",
    "# Calculates the loss of the loss function\n",
    "loss.backward() \n",
    "\n",
    "# Improve from loss, i.e backprop\n",
    "# optimizer.step() \n",
    "\n",
    "item_loss = loss.item()\n",
    "epoch_train_losses.append(item_loss)\n",
    "train_loss = np.mean(epoch_train_losses)\n",
    "train_losses.append(train_loss)\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     epoch_test_losses = []\n",
    "#     for x, y in test_loader_lstm:\n",
    "#         lstm.eval()\n",
    "\n",
    "#         # Forward pass\n",
    "#         outputs = lstm(x) \n",
    "\n",
    "#         item_loss = criterion(outputs, y).item()\n",
    "#         epoch_test_losses.append(item_loss)\n",
    "#     test_loss = np.mean(epoch_test_losses)\n",
    "#     test_losses.append(test_loss)\n",
    "\n",
    "# print(\"Epoch: %d | Train Loss: %1.5f | Test Loss: %1.5f\" % (epoch, train_loss, test_loss))\n",
    "print(\"Epoch: %d | Train Loss: %1.5f\" % (epoch, train_loss))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
